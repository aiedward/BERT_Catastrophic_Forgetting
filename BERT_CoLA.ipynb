{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT CoLA.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOFZG6cb30z/e70Tz2K2tBz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1449b58bca04410585f70cd201812e9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_07fbb70128194d51b6ad753cedd132a2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_263b86a953214ca18c4ce21a81ad9eed",
              "IPY_MODEL_0c655920559f44eabdafc3d222a4a5f0"
            ]
          }
        },
        "07fbb70128194d51b6ad753cedd132a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "263b86a953214ca18c4ce21a81ad9eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ad239af453124469876364528a467f80",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_89a4b8c00de343be8f68766b0dd08612"
          }
        },
        "0c655920559f44eabdafc3d222a4a5f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ae31647f2f604634b6376c09875f3bfa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 343kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5e20b3a1e5dc437ea5f03fd45e348175"
          }
        },
        "ad239af453124469876364528a467f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "89a4b8c00de343be8f68766b0dd08612": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae31647f2f604634b6376c09875f3bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5e20b3a1e5dc437ea5f03fd45e348175": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e606c4d019d44bfa05a1f7656ef2a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_011d4f0211b84cd7856aad4b7738c18f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0ade4a30d9674eb98f126a93eadda353",
              "IPY_MODEL_754562cbfb834426931ab78f8d080615"
            ]
          }
        },
        "011d4f0211b84cd7856aad4b7738c18f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0ade4a30d9674eb98f126a93eadda353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c520127c8f9242bb9450e3e5082b40cb",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_04286df6111c46faad8a10de7d566e35"
          }
        },
        "754562cbfb834426931ab78f8d080615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0bce8b4f883b49bc8225da5698b481e8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:40&lt;00:00, 10.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8cfe9b8dff14cd8a4ac40fada4a3a07"
          }
        },
        "c520127c8f9242bb9450e3e5082b40cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "04286df6111c46faad8a10de7d566e35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0bce8b4f883b49bc8225da5698b481e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8cfe9b8dff14cd8a4ac40fada4a3a07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "363fd7b3e607451f828ccfc64852aab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_15163f3437cf4d959ca0b2b70ace2962",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1ec15f12e9714acd8303d8b789c2abae",
              "IPY_MODEL_5c1871fe58664fb2a247d4ed80e92ca4"
            ]
          }
        },
        "15163f3437cf4d959ca0b2b70ace2962": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ec15f12e9714acd8303d8b789c2abae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_08e5bbfad21c4ea7be11529632b356f2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e2ac257b0ec340d5a9b6ffb9fc7123bf"
          }
        },
        "5c1871fe58664fb2a247d4ed80e92ca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4306db75e767411e99e0805b0740a2be",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 361/361 [00:03&lt;00:00, 106B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dec58feca26147468ae375cc837786c2"
          }
        },
        "08e5bbfad21c4ea7be11529632b356f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e2ac257b0ec340d5a9b6ffb9fc7123bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4306db75e767411e99e0805b0740a2be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dec58feca26147468ae375cc837786c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JingYannn/BERT_Catastrophic_Forgetting/blob/master/BERT_CoLA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4C37AZxzX2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !python download_glue_data.py --data_dir='glue_data' --tasks='MRPC' --test_labels=True\n",
        "!pwd\n",
        "!ls\n",
        "!wget https://gist.githubusercontent.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e/raw/17b8dd0d724281ed7c3b2aeeda662b92809aadd5/download_glue_data.py\n",
        "!python download_glue_data.py --data_dir='glue_data' --tasks='MRPC'\n",
        "!ls glue_data/MRPC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXz2zE82zaLf",
        "colab_type": "code",
        "outputId": "bcc94c52-2a02-4ce0-ebbb-62b94d9d488f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "GLUE_DIR=\"glue_data/\"\n",
        "mrpc_output = \"mrpc_output\"\n",
        "\n",
        "!python run_glue.py \\\n",
        "  --model_type bert \\\n",
        "  --model_name_or_path bert-base-uncased \\\n",
        "  --task_name MRPC \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --do_lower_case \\\n",
        "  --data_dir $GLUE_DIR/MRPC/ \\\n",
        "  --max_seq_length 128 \\\n",
        "  --per_gpu_train_batch_size 32 \\\n",
        "  --learning_rate 2e-5 \\\n",
        "  --num_train_epochs 8 \\\n",
        "  --output_dir mrpc_output \\\n",
        "  --overwrite_output_dir"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "03/07/2020 12:45:54 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "03/07/2020 12:45:54 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.8f56353af4a709bf5ff0fbc915d8f5b42bfff892cbb6ac98c3c45f481a03c685\n",
            "03/07/2020 12:45:54 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": null,\n",
            "  \"finetuning_task\": \"mrpc\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "03/07/2020 12:45:54 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "03/07/2020 12:45:55 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "03/07/2020 12:45:58 - INFO - transformers.modeling_utils -   Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "03/07/2020 12:45:58 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "03/07/2020 12:46:02 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='glue_data//MRPC/', device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=8.0, output_dir='mrpc_output', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=32, save_steps=500, seed=42, server_ip='', server_port='', task_name='mrpc', tokenizer_name='', warmup_steps=0, weight_decay=0.0)\n",
            "03/07/2020 12:46:02 - INFO - __main__ -   Loading features from cached file glue_data//MRPC/cached_train_bert-base-uncased_128_mrpc\n",
            "03/07/2020 12:46:02 - INFO - __main__ -   ***** Running training *****\n",
            "03/07/2020 12:46:02 - INFO - __main__ -     Num examples = 3668\n",
            "03/07/2020 12:46:02 - INFO - __main__ -     Num Epochs = 8\n",
            "03/07/2020 12:46:02 - INFO - __main__ -     Instantaneous batch size per GPU = 32\n",
            "03/07/2020 12:46:02 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "03/07/2020 12:46:02 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "03/07/2020 12:46:02 - INFO - __main__ -     Total optimization steps = 920\n",
            "Epoch:   0% 0/8 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/115 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/115 [00:00<01:24,  1.35it/s]\u001b[A\n",
            "Iteration:   2% 2/115 [00:01<01:22,  1.38it/s]\u001b[A\n",
            "Iteration:   3% 3/115 [00:02<01:20,  1.40it/s]\u001b[A\n",
            "Iteration:   3% 4/115 [00:02<01:18,  1.41it/s]\u001b[A\n",
            "Iteration:   4% 5/115 [00:03<01:17,  1.42it/s]\u001b[A\n",
            "Iteration:   5% 6/115 [00:04<01:16,  1.42it/s]\u001b[A\n",
            "Iteration:   6% 7/115 [00:04<01:15,  1.42it/s]\u001b[A\n",
            "Iteration:   7% 8/115 [00:05<01:15,  1.43it/s]\u001b[A\n",
            "Iteration:   8% 9/115 [00:06<01:14,  1.42it/s]\u001b[A\n",
            "Iteration:   9% 10/115 [00:07<01:13,  1.43it/s]\u001b[A\n",
            "Iteration:  10% 11/115 [00:07<01:13,  1.42it/s]\u001b[A\n",
            "Iteration:  10% 12/115 [00:08<01:12,  1.42it/s]\u001b[A\n",
            "Iteration:  11% 13/115 [00:09<01:11,  1.42it/s]\u001b[A\n",
            "Iteration:  12% 14/115 [00:09<01:11,  1.42it/s]\u001b[A\n",
            "Iteration:  13% 15/115 [00:10<01:10,  1.41it/s]\u001b[A\n",
            "Iteration:  14% 16/115 [00:11<01:10,  1.41it/s]\u001b[A\n",
            "Iteration:  15% 17/115 [00:11<01:09,  1.40it/s]\u001b[A\n",
            "Iteration:  16% 18/115 [00:12<01:09,  1.40it/s]\u001b[A\n",
            "Iteration:  17% 19/115 [00:13<01:08,  1.40it/s]\u001b[A\n",
            "Iteration:  17% 20/115 [00:14<01:08,  1.40it/s]\u001b[A\n",
            "Iteration:  18% 21/115 [00:14<01:07,  1.39it/s]\u001b[A\n",
            "Iteration:  19% 22/115 [00:15<01:06,  1.39it/s]\u001b[A\n",
            "Iteration:  20% 23/115 [00:16<01:06,  1.39it/s]\u001b[A\n",
            "Iteration:  21% 24/115 [00:17<01:05,  1.38it/s]\u001b[A\n",
            "Iteration:  22% 25/115 [00:17<01:04,  1.39it/s]\u001b[A\n",
            "Iteration:  23% 26/115 [00:18<01:04,  1.38it/s]\u001b[A\n",
            "Iteration:  23% 27/115 [00:19<01:04,  1.37it/s]\u001b[A\n",
            "Iteration:  24% 28/115 [00:19<01:03,  1.37it/s]\u001b[A\n",
            "Iteration:  25% 29/115 [00:20<01:02,  1.37it/s]\u001b[A\n",
            "Iteration:  26% 30/115 [00:21<01:02,  1.37it/s]\u001b[A\n",
            "Iteration:  27% 31/115 [00:22<01:01,  1.36it/s]\u001b[A\n",
            "Iteration:  28% 32/115 [00:22<01:01,  1.36it/s]\u001b[A\n",
            "Iteration:  29% 33/115 [00:23<01:00,  1.36it/s]\u001b[A\n",
            "Iteration:  30% 34/115 [00:24<00:59,  1.35it/s]\u001b[A\n",
            "Iteration:  30% 35/115 [00:25<00:59,  1.35it/s]\u001b[A\n",
            "Iteration:  31% 36/115 [00:25<00:58,  1.35it/s]\u001b[A\n",
            "Iteration:  32% 37/115 [00:26<00:58,  1.34it/s]\u001b[A\n",
            "Iteration:  33% 38/115 [00:27<00:57,  1.34it/s]\u001b[A\n",
            "Iteration:  34% 39/115 [00:28<00:56,  1.34it/s]\u001b[A\n",
            "Iteration:  35% 40/115 [00:28<00:56,  1.33it/s]\u001b[A\n",
            "Iteration:  36% 41/115 [00:29<00:55,  1.33it/s]\u001b[A\n",
            "Iteration:  37% 42/115 [00:30<00:54,  1.33it/s]\u001b[A\n",
            "Iteration:  37% 43/115 [00:31<00:54,  1.33it/s]\u001b[A\n",
            "Iteration:  38% 44/115 [00:31<00:53,  1.32it/s]\u001b[A\n",
            "Iteration:  39% 45/115 [00:32<00:52,  1.33it/s]\u001b[A\n",
            "Iteration:  40% 46/115 [00:33<00:52,  1.32it/s]\u001b[A\n",
            "Iteration:  41% 47/115 [00:34<00:51,  1.32it/s]\u001b[A\n",
            "Iteration:  42% 48/115 [00:34<00:51,  1.31it/s]\u001b[A\n",
            "Iteration:  43% 49/115 [00:35<00:50,  1.31it/s]\u001b[A\n",
            "Iteration:  43% 50/115 [00:36<00:49,  1.31it/s]\u001b[A\n",
            "Iteration:  44% 51/115 [00:37<00:49,  1.30it/s]\u001b[A\n",
            "Iteration:  45% 52/115 [00:38<00:48,  1.30it/s]\u001b[A\n",
            "Iteration:  46% 53/115 [00:38<00:47,  1.30it/s]\u001b[A\n",
            "Iteration:  47% 54/115 [00:39<00:47,  1.30it/s]\u001b[A\n",
            "Iteration:  48% 55/115 [00:40<00:46,  1.30it/s]\u001b[A\n",
            "Iteration:  49% 56/115 [00:41<00:45,  1.30it/s]\u001b[A\n",
            "Iteration:  50% 57/115 [00:41<00:44,  1.30it/s]\u001b[A\n",
            "Iteration:  50% 58/115 [00:42<00:43,  1.30it/s]\u001b[A\n",
            "Iteration:  51% 59/115 [00:43<00:43,  1.30it/s]\u001b[A\n",
            "Iteration:  52% 60/115 [00:44<00:42,  1.29it/s]\u001b[A\n",
            "Iteration:  53% 61/115 [00:44<00:41,  1.29it/s]\u001b[A\n",
            "Iteration:  54% 62/115 [00:45<00:41,  1.29it/s]\u001b[A\n",
            "Iteration:  55% 63/115 [00:46<00:40,  1.29it/s]\u001b[A\n",
            "Iteration:  56% 64/115 [00:47<00:39,  1.29it/s]\u001b[A\n",
            "Iteration:  57% 65/115 [00:48<00:38,  1.30it/s]\u001b[A\n",
            "Iteration:  57% 66/115 [00:48<00:37,  1.30it/s]\u001b[A\n",
            "Iteration:  58% 67/115 [00:49<00:36,  1.30it/s]\u001b[A\n",
            "Iteration:  59% 68/115 [00:50<00:35,  1.31it/s]\u001b[A\n",
            "Iteration:  60% 69/115 [00:51<00:35,  1.31it/s]\u001b[A\n",
            "Iteration:  61% 70/115 [00:51<00:34,  1.31it/s]\u001b[A\n",
            "Iteration:  62% 71/115 [00:52<00:33,  1.31it/s]\u001b[A\n",
            "Iteration:  63% 72/115 [00:53<00:32,  1.32it/s]\u001b[A\n",
            "Iteration:  63% 73/115 [00:54<00:31,  1.32it/s]\u001b[A\n",
            "Iteration:  64% 74/115 [00:54<00:30,  1.32it/s]\u001b[A\n",
            "Iteration:  65% 75/115 [00:55<00:30,  1.33it/s]\u001b[A\n",
            "Iteration:  66% 76/115 [00:56<00:29,  1.34it/s]\u001b[A\n",
            "Iteration:  67% 77/115 [00:57<00:28,  1.34it/s]\u001b[A\n",
            "Iteration:  68% 78/115 [00:57<00:27,  1.33it/s]\u001b[A\n",
            "Iteration:  69% 79/115 [00:58<00:26,  1.33it/s]\u001b[A\n",
            "Iteration:  70% 80/115 [00:59<00:26,  1.34it/s]\u001b[A\n",
            "Iteration:  70% 81/115 [01:00<00:25,  1.34it/s]\u001b[A\n",
            "Iteration:  71% 82/115 [01:00<00:24,  1.34it/s]\u001b[A\n",
            "Iteration:  72% 83/115 [01:01<00:23,  1.35it/s]\u001b[A\n",
            "Iteration:  73% 84/115 [01:02<00:23,  1.35it/s]\u001b[A\n",
            "Iteration:  74% 85/115 [01:03<00:22,  1.35it/s]\u001b[A\n",
            "Iteration:  75% 86/115 [01:03<00:21,  1.35it/s]\u001b[A\n",
            "Iteration:  76% 87/115 [01:04<00:20,  1.35it/s]\u001b[A\n",
            "Iteration:  77% 88/115 [01:05<00:19,  1.35it/s]\u001b[A\n",
            "Iteration:  77% 89/115 [01:06<00:19,  1.35it/s]\u001b[A\n",
            "Iteration:  78% 90/115 [01:06<00:18,  1.36it/s]\u001b[A\n",
            "Iteration:  79% 91/115 [01:07<00:17,  1.36it/s]\u001b[A\n",
            "Iteration:  80% 92/115 [01:08<00:16,  1.36it/s]\u001b[A\n",
            "Iteration:  81% 93/115 [01:08<00:16,  1.36it/s]\u001b[A\n",
            "Iteration:  82% 94/115 [01:09<00:15,  1.36it/s]\u001b[A\n",
            "Iteration:  83% 95/115 [01:10<00:14,  1.36it/s]\u001b[A\n",
            "Iteration:  83% 96/115 [01:11<00:13,  1.37it/s]\u001b[A\n",
            "Iteration:  84% 97/115 [01:11<00:13,  1.37it/s]\u001b[A\n",
            "Iteration:  85% 98/115 [01:12<00:12,  1.37it/s]\u001b[A\n",
            "Iteration:  86% 99/115 [01:13<00:11,  1.37it/s]\u001b[A\n",
            "Iteration:  87% 100/115 [01:14<00:10,  1.37it/s]\u001b[A\n",
            "Iteration:  88% 101/115 [01:14<00:10,  1.37it/s]\u001b[A\n",
            "Iteration:  89% 102/115 [01:15<00:09,  1.37it/s]\u001b[A\n",
            "Iteration:  90% 103/115 [01:16<00:08,  1.37it/s]\u001b[A\n",
            "Iteration:  90% 104/115 [01:16<00:08,  1.37it/s]\u001b[A\n",
            "Iteration:  91% 105/115 [01:17<00:07,  1.37it/s]\u001b[A\n",
            "Iteration:  92% 106/115 [01:18<00:06,  1.37it/s]\u001b[A\n",
            "Iteration:  93% 107/115 [01:19<00:05,  1.37it/s]\u001b[A\n",
            "Iteration:  94% 108/115 [01:19<00:05,  1.37it/s]\u001b[A\n",
            "Iteration:  95% 109/115 [01:20<00:04,  1.37it/s]\u001b[A\n",
            "Iteration:  96% 110/115 [01:21<00:03,  1.37it/s]\u001b[A\n",
            "Iteration:  97% 111/115 [01:22<00:02,  1.37it/s]\u001b[A\n",
            "Iteration:  97% 112/115 [01:22<00:02,  1.37it/s]\u001b[A\n",
            "Iteration:  98% 113/115 [01:23<00:01,  1.38it/s]\u001b[A\n",
            "Iteration:  99% 114/115 [01:24<00:00,  1.38it/s]\u001b[A\n",
            "Iteration: 100% 115/115 [01:24<00:00,  1.53it/s]\u001b[A\n",
            "Epoch:  12% 1/8 [01:24<09:53, 84.76s/it]\n",
            "Iteration:   0% 0/115 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/115 [00:00<01:22,  1.38it/s]\u001b[A\n",
            "Iteration:   2% 2/115 [00:01<01:21,  1.38it/s]\u001b[A\n",
            "Iteration:   3% 3/115 [00:02<01:21,  1.38it/s]\u001b[A\n",
            "Iteration:   3% 4/115 [00:02<01:20,  1.38it/s]\u001b[A\n",
            "Iteration:   4% 5/115 [00:03<01:19,  1.38it/s]\u001b[A\n",
            "Iteration:   5% 6/115 [00:04<01:19,  1.38it/s]\u001b[A\n",
            "Iteration:   6% 7/115 [00:05<01:18,  1.38it/s]\u001b[A\n",
            "Iteration:   7% 8/115 [00:05<01:17,  1.38it/s]\u001b[A\n",
            "Iteration:   8% 9/115 [00:06<01:16,  1.38it/s]\u001b[A\n",
            "Iteration:   9% 10/115 [00:07<01:16,  1.38it/s]\u001b[A\n",
            "Iteration:  10% 11/115 [00:07<01:15,  1.38it/s]\u001b[A\n",
            "Iteration:  10% 12/115 [00:08<01:14,  1.38it/s]\u001b[A\n",
            "Iteration:  11% 13/115 [00:09<01:14,  1.38it/s]\u001b[A\n",
            "Iteration:  12% 14/115 [00:10<01:13,  1.37it/s]\u001b[A\n",
            "Iteration:  13% 15/115 [00:10<01:12,  1.37it/s]\u001b[A\n",
            "Iteration:  14% 16/115 [00:11<01:12,  1.37it/s]\u001b[A\n",
            "Iteration:  15% 17/115 [00:12<01:11,  1.37it/s]\u001b[A\n",
            "Iteration:  16% 18/115 [00:13<01:10,  1.37it/s]\u001b[A\n",
            "Iteration:  17% 19/115 [00:13<01:09,  1.38it/s]\u001b[A\n",
            "Iteration:  17% 20/115 [00:14<01:09,  1.37it/s]\u001b[A\n",
            "Iteration:  18% 21/115 [00:15<01:08,  1.37it/s]\u001b[A\n",
            "Iteration:  19% 22/115 [00:16<01:07,  1.37it/s]\u001b[A\n",
            "Iteration:  20% 23/115 [00:16<01:07,  1.37it/s]\u001b[A\n",
            "Iteration:  21% 24/115 [00:17<01:06,  1.37it/s]\u001b[A\n",
            "Iteration:  22% 25/115 [00:18<01:05,  1.37it/s]\u001b[A\n",
            "Iteration:  23% 26/115 [00:18<01:05,  1.36it/s]\u001b[A\n",
            "Iteration:  23% 27/115 [00:19<01:04,  1.36it/s]\u001b[A\n",
            "Iteration:  24% 28/115 [00:20<01:03,  1.36it/s]\u001b[A\n",
            "Iteration:  25% 29/115 [00:21<01:03,  1.36it/s]\u001b[A\n",
            "Iteration:  26% 30/115 [00:21<01:02,  1.36it/s]\u001b[A\n",
            "Iteration:  27% 31/115 [00:22<01:01,  1.36it/s]\u001b[A\n",
            "Iteration:  28% 32/115 [00:23<01:01,  1.36it/s]\u001b[A\n",
            "Iteration:  29% 33/115 [00:24<01:00,  1.36it/s]\u001b[A\n",
            "Iteration:  30% 34/115 [00:24<00:59,  1.36it/s]\u001b[A\n",
            "Iteration:  30% 35/115 [00:25<00:58,  1.36it/s]\u001b[A\n",
            "Iteration:  31% 36/115 [00:26<00:58,  1.36it/s]\u001b[A\n",
            "Iteration:  32% 37/115 [00:27<00:57,  1.35it/s]\u001b[A\n",
            "Iteration:  33% 38/115 [00:27<00:56,  1.35it/s]\u001b[A\n",
            "Iteration:  34% 39/115 [00:28<00:56,  1.35it/s]\u001b[A\n",
            "Iteration:  35% 40/115 [00:29<00:55,  1.35it/s]\u001b[A\n",
            "Iteration:  36% 41/115 [00:30<00:54,  1.35it/s]\u001b[A\n",
            "Iteration:  37% 42/115 [00:30<00:54,  1.35it/s]\u001b[A\n",
            "Iteration:  37% 43/115 [00:31<00:53,  1.35it/s]\u001b[A\n",
            "Iteration:  38% 44/115 [00:32<00:52,  1.35it/s]\u001b[A\n",
            "Iteration:  39% 45/115 [00:33<00:52,  1.34it/s]\u001b[A\n",
            "Iteration:  40% 46/115 [00:33<00:51,  1.34it/s]\u001b[A\n",
            "Iteration:  41% 47/115 [00:34<00:50,  1.34it/s]\u001b[A\n",
            "Iteration:  42% 48/115 [00:35<00:50,  1.34it/s]\u001b[A\n",
            "Iteration:  43% 49/115 [00:36<00:49,  1.34it/s]\u001b[A\n",
            "Iteration:  43% 50/115 [00:36<00:48,  1.34it/s]\u001b[A\n",
            "Iteration:  44% 51/115 [00:37<00:47,  1.33it/s]\u001b[A\n",
            "Iteration:  45% 52/115 [00:38<00:47,  1.34it/s]\u001b[A\n",
            "Iteration:  46% 53/115 [00:39<00:46,  1.34it/s]\u001b[A\n",
            "Iteration:  47% 54/115 [00:39<00:45,  1.34it/s]\u001b[A\n",
            "Iteration:  48% 55/115 [00:40<00:44,  1.33it/s]\u001b[A\n",
            "Iteration:  49% 56/115 [00:41<00:44,  1.34it/s]\u001b[A\n",
            "Iteration:  50% 57/115 [00:41<00:43,  1.34it/s]\u001b[A\n",
            "Iteration:  50% 58/115 [00:42<00:42,  1.34it/s]\u001b[A\n",
            "Iteration:  51% 59/115 [00:43<00:41,  1.34it/s]\u001b[A\n",
            "Iteration:  52% 60/115 [00:44<00:41,  1.34it/s]\u001b[A\n",
            "Iteration:  53% 61/115 [00:44<00:40,  1.34it/s]\u001b[A\n",
            "Iteration:  54% 62/115 [00:45<00:39,  1.34it/s]\u001b[A\n",
            "Iteration:  55% 63/115 [00:46<00:38,  1.34it/s]\u001b[A\n",
            "Iteration:  56% 64/115 [00:47<00:38,  1.34it/s]\u001b[A\n",
            "Iteration:  57% 65/115 [00:47<00:37,  1.34it/s]\u001b[A\n",
            "Iteration:  57% 66/115 [00:48<00:36,  1.34it/s]\u001b[A\n",
            "Iteration:  58% 67/115 [00:49<00:35,  1.34it/s]\u001b[A\n",
            "Iteration:  59% 68/115 [00:50<00:34,  1.34it/s]\u001b[A\n",
            "Iteration:  60% 69/115 [00:50<00:34,  1.35it/s]\u001b[A\n",
            "Iteration:  61% 70/115 [00:51<00:33,  1.35it/s]\u001b[A\n",
            "Iteration:  62% 71/115 [00:52<00:32,  1.34it/s]\u001b[A\n",
            "Iteration:  63% 72/115 [00:53<00:31,  1.35it/s]\u001b[A\n",
            "Iteration:  63% 73/115 [00:53<00:31,  1.35it/s]\u001b[A\n",
            "Iteration:  64% 74/115 [00:54<00:30,  1.35it/s]\u001b[A\n",
            "Iteration:  65% 75/115 [00:55<00:29,  1.35it/s]\u001b[A\n",
            "Iteration:  66% 76/115 [00:56<00:28,  1.35it/s]\u001b[A\n",
            "Iteration:  67% 77/115 [00:56<00:28,  1.35it/s]\u001b[A\n",
            "Iteration:  68% 78/115 [00:57<00:27,  1.35it/s]\u001b[A\n",
            "Iteration:  69% 79/115 [00:58<00:26,  1.35it/s]\u001b[A\n",
            "Iteration:  70% 80/115 [00:59<00:25,  1.35it/s]\u001b[A\n",
            "Iteration:  70% 81/115 [00:59<00:25,  1.35it/s]\u001b[A\n",
            "Iteration:  71% 82/115 [01:00<00:24,  1.35it/s]\u001b[A\n",
            "Iteration:  72% 83/115 [01:01<00:23,  1.35it/s]\u001b[A\n",
            "Iteration:  73% 84/115 [01:02<00:22,  1.35it/s]\u001b[A\n",
            "Iteration:  74% 85/115 [01:02<00:22,  1.35it/s]\u001b[A\n",
            "Iteration:  75% 86/115 [01:03<00:21,  1.35it/s]\u001b[A\n",
            "Iteration:  76% 87/115 [01:04<00:20,  1.35it/s]\u001b[A\n",
            "Iteration:  77% 88/115 [01:05<00:19,  1.35it/s]\u001b[A\n",
            "Iteration:  77% 89/115 [01:05<00:19,  1.35it/s]\u001b[A\n",
            "Iteration:  78% 90/115 [01:06<00:18,  1.35it/s]\u001b[A\n",
            "Iteration:  79% 91/115 [01:07<00:17,  1.35it/s]\u001b[A\n",
            "Iteration:  80% 92/115 [01:07<00:17,  1.35it/s]\u001b[A\n",
            "Iteration:  81% 93/115 [01:08<00:16,  1.35it/s]\u001b[A\n",
            "Iteration:  82% 94/115 [01:09<00:15,  1.35it/s]\u001b[A\n",
            "Iteration:  83% 95/115 [01:10<00:14,  1.35it/s]\u001b[A\n",
            "Iteration:  83% 96/115 [01:10<00:14,  1.35it/s]\u001b[A\n",
            "Iteration:  84% 97/115 [01:11<00:13,  1.35it/s]\u001b[A\n",
            "Iteration:  85% 98/115 [01:12<00:12,  1.35it/s]\u001b[A\n",
            "Iteration:  86% 99/115 [01:13<00:11,  1.35it/s]\u001b[A\n",
            "Iteration:  87% 100/115 [01:13<00:11,  1.35it/s]\u001b[A\n",
            "Iteration:  88% 101/115 [01:14<00:10,  1.35it/s]\u001b[A\n",
            "Iteration:  89% 102/115 [01:15<00:09,  1.35it/s]\u001b[A\n",
            "Iteration:  90% 103/115 [01:16<00:08,  1.35it/s]\u001b[A\n",
            "Iteration:  90% 104/115 [01:16<00:08,  1.35it/s]\u001b[A\n",
            "Iteration:  91% 105/115 [01:17<00:07,  1.35it/s]\u001b[A\n",
            "Iteration:  92% 106/115 [01:18<00:06,  1.35it/s]\u001b[A\n",
            "Iteration:  93% 107/115 [01:19<00:05,  1.35it/s]\u001b[A\n",
            "Iteration:  94% 108/115 [01:19<00:05,  1.35it/s]\u001b[A\n",
            "Iteration:  95% 109/115 [01:20<00:04,  1.35it/s]\u001b[A\n",
            "Iteration:  96% 110/115 [01:21<00:03,  1.35it/s]\u001b[A\n",
            "Iteration:  97% 111/115 [01:22<00:02,  1.35it/s]\u001b[A\n",
            "Iteration:  97% 112/115 [01:22<00:02,  1.35it/s]\u001b[A\n",
            "Iteration:  98% 113/115 [01:23<00:01,  1.35it/s]\u001b[A\n",
            "Iteration:  99% 114/115 [01:24<00:00,  1.35it/s]\u001b[A\n",
            "Iteration: 100% 115/115 [01:24<00:00,  1.51it/s]\u001b[A\n",
            "Epoch:  25% 2/8 [02:49<08:28, 84.75s/it]\n",
            "Iteration:   0% 0/115 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/115 [00:00<01:24,  1.35it/s]\u001b[A\n",
            "Iteration:   2% 2/115 [00:01<01:23,  1.35it/s]\u001b[A\n",
            "Iteration:   3% 3/115 [00:02<01:22,  1.35it/s]\u001b[A\n",
            "Iteration:   3% 4/115 [00:02<01:22,  1.35it/s]\u001b[A\n",
            "Iteration:   4% 5/115 [00:03<01:21,  1.35it/s]\u001b[A\n",
            "Iteration:   5% 6/115 [00:04<01:20,  1.35it/s]\u001b[A\n",
            "Iteration:   6% 7/115 [00:05<01:19,  1.35it/s]\u001b[A\n",
            "Iteration:   7% 8/115 [00:05<01:19,  1.35it/s]\u001b[A\n",
            "Iteration:   8% 9/115 [00:06<01:18,  1.36it/s]\u001b[A\n",
            "Iteration:   9% 10/115 [00:07<01:17,  1.36it/s]\u001b[A\n",
            "Iteration:  10% 11/115 [00:08<01:16,  1.36it/s]\u001b[A\n",
            "Iteration:  10% 12/115 [00:08<01:15,  1.36it/s]\u001b[A\n",
            "Iteration:  11% 13/115 [00:09<01:14,  1.36it/s]\u001b[A\n",
            "Iteration:  12% 14/115 [00:10<01:14,  1.36it/s]\u001b[A\n",
            "Iteration:  13% 15/115 [00:11<01:13,  1.36it/s]\u001b[A\n",
            "Iteration:  14% 16/115 [00:11<01:12,  1.36it/s]\u001b[A\n",
            "Iteration:  15% 17/115 [00:12<01:12,  1.35it/s]\u001b[A\n",
            "Iteration:  16% 18/115 [00:13<01:11,  1.36it/s]\u001b[A\n",
            "Iteration:  17% 19/115 [00:14<01:10,  1.36it/s]\u001b[A\n",
            "Iteration:  17% 20/115 [00:14<01:10,  1.36it/s]\u001b[A\n",
            "Iteration:  18% 21/115 [00:15<01:09,  1.36it/s]\u001b[A\n",
            "Iteration:  19% 22/115 [00:16<01:08,  1.36it/s]\u001b[A\n",
            "Iteration:  20% 23/115 [00:16<01:07,  1.36it/s]\u001b[A\n",
            "Iteration:  21% 24/115 [00:17<01:07,  1.35it/s]\u001b[A\n",
            "Iteration:  22% 25/115 [00:18<01:06,  1.36it/s]\u001b[A\n",
            "Iteration:  23% 26/115 [00:19<01:05,  1.36it/s]\u001b[A\n",
            "Iteration:  23% 27/115 [00:19<01:04,  1.36it/s]\u001b[A\n",
            "Iteration:  24% 28/115 [00:20<01:04,  1.36it/s]\u001b[A\n",
            "Iteration:  25% 29/115 [00:21<01:03,  1.35it/s]\u001b[A\n",
            "Iteration:  26% 30/115 [00:22<01:02,  1.35it/s]\u001b[A\n",
            "Iteration:  27% 31/115 [00:22<01:02,  1.35it/s]\u001b[A\n",
            "Iteration:  28% 32/115 [00:23<01:01,  1.35it/s]\u001b[A\n",
            "Iteration:  29% 33/115 [00:24<01:00,  1.36it/s]\u001b[A\n",
            "Iteration:  30% 34/115 [00:25<00:59,  1.35it/s]\u001b[A\n",
            "Iteration:  30% 35/115 [00:25<00:59,  1.36it/s]\u001b[A\n",
            "Iteration:  31% 36/115 [00:26<00:58,  1.35it/s]\u001b[A\n",
            "Iteration:  32% 37/115 [00:27<00:57,  1.36it/s]\u001b[A\n",
            "Iteration:  33% 38/115 [00:28<00:56,  1.36it/s]\u001b[A\n",
            "Iteration:  34% 39/115 [00:28<00:55,  1.36it/s]\u001b[A\n",
            "Iteration:  35% 40/115 [00:29<00:55,  1.36it/s]\u001b[A\n",
            "Iteration:  36% 41/115 [00:30<00:54,  1.36it/s]\u001b[A\n",
            "Iteration:  37% 42/115 [00:30<00:53,  1.36it/s]\u001b[A\n",
            "Iteration:  37% 43/115 [00:31<00:53,  1.35it/s]\u001b[A\n",
            "Iteration:  38% 44/115 [00:32<00:52,  1.35it/s]\u001b[A\n",
            "Iteration:  39% 45/115 [00:33<00:51,  1.35it/s]\u001b[A\n",
            "Iteration:  40% 46/115 [00:33<00:50,  1.36it/s]\u001b[A\n",
            "Iteration:  41% 47/115 [00:34<00:50,  1.35it/s]\u001b[A\n",
            "Iteration:  42% 48/115 [00:35<00:49,  1.36it/s]\u001b[A\n",
            "Iteration:  43% 49/115 [00:36<00:48,  1.36it/s]\u001b[A\n",
            "Iteration:  43% 50/115 [00:36<00:48,  1.35it/s]\u001b[A\n",
            "Iteration:  44% 51/115 [00:37<00:47,  1.35it/s]\u001b[A\n",
            "Iteration:  45% 52/115 [00:38<00:46,  1.35it/s]\u001b[A\n",
            "Iteration:  46% 53/115 [00:39<00:45,  1.35it/s]\u001b[A\n",
            "Iteration:  47% 54/115 [00:39<00:45,  1.36it/s]\u001b[A\n",
            "Iteration:  48% 55/115 [00:40<00:44,  1.35it/s]\u001b[A\n",
            "Iteration:  49% 56/115 [00:41<00:43,  1.36it/s]\u001b[A\n",
            "Iteration:  50% 57/115 [00:42<00:42,  1.36it/s]\u001b[A\n",
            "Iteration:  50% 58/115 [00:42<00:42,  1.35it/s]\u001b[A\n",
            "Iteration:  51% 59/115 [00:43<00:41,  1.35it/s]\u001b[A\n",
            "Iteration:  52% 60/115 [00:44<00:40,  1.36it/s]\u001b[A\n",
            "Iteration:  53% 61/115 [00:44<00:39,  1.36it/s]\u001b[A\n",
            "Iteration:  54% 62/115 [00:45<00:39,  1.35it/s]\u001b[A\n",
            "Iteration:  55% 63/115 [00:46<00:38,  1.35it/s]\u001b[A\n",
            "Iteration:  56% 64/115 [00:47<00:37,  1.35it/s]\u001b[A\n",
            "Iteration:  57% 65/115 [00:47<00:37,  1.35it/s]\u001b[A\n",
            "Iteration:  57% 66/115 [00:48<00:36,  1.35it/s]\u001b[A\n",
            "Iteration:  58% 67/115 [00:49<00:35,  1.35it/s]\u001b[A\n",
            "Iteration:  59% 68/115 [00:50<00:34,  1.35it/s]\u001b[A\n",
            "Iteration:  60% 69/115 [00:50<00:34,  1.35it/s]\u001b[A\n",
            "Iteration:  61% 70/115 [00:51<00:33,  1.35it/s]\u001b[A\n",
            "Iteration:  62% 71/115 [00:52<00:32,  1.35it/s]\u001b[A\n",
            "Iteration:  63% 72/115 [00:53<00:31,  1.35it/s]\u001b[A\n",
            "Iteration:  63% 73/115 [00:53<00:30,  1.36it/s]\u001b[A\n",
            "Iteration:  64% 74/115 [00:54<00:30,  1.36it/s]\u001b[A\n",
            "Iteration:  65% 75/115 [00:55<00:29,  1.36it/s]\u001b[A\n",
            "Iteration:  66% 76/115 [00:56<00:28,  1.36it/s]\u001b[A\n",
            "Iteration:  67% 77/115 [00:56<00:27,  1.36it/s]\u001b[A\n",
            "Iteration:  68% 78/115 [00:57<00:27,  1.35it/s]\u001b[A\n",
            "Iteration:  69% 79/115 [00:58<00:26,  1.35it/s]\u001b[A\n",
            "Iteration:  70% 80/115 [00:59<00:25,  1.35it/s]\u001b[A\n",
            "Iteration:  70% 81/115 [00:59<00:25,  1.35it/s]\u001b[A\n",
            "Iteration:  71% 82/115 [01:00<00:24,  1.35it/s]\u001b[A\n",
            "Iteration:  72% 83/115 [01:01<00:23,  1.35it/s]\u001b[A\n",
            "Iteration:  73% 84/115 [01:01<00:22,  1.35it/s]\u001b[A\n",
            "Iteration:  74% 85/115 [01:02<00:22,  1.35it/s]\u001b[A\n",
            "Iteration:  75% 86/115 [01:03<00:21,  1.35it/s]\u001b[A\n",
            "Iteration:  76% 87/115 [01:04<00:20,  1.35it/s]\u001b[A\n",
            "Iteration:  77% 88/115 [01:04<00:19,  1.35it/s]\u001b[A\n",
            "Iteration:  77% 89/115 [01:05<00:19,  1.35it/s]\u001b[A\n",
            "Iteration:  78% 90/115 [01:06<00:18,  1.35it/s]\u001b[A\n",
            "Iteration:  79% 91/115 [01:07<00:17,  1.35it/s]\u001b[A\n",
            "Iteration:  80% 92/115 [01:07<00:16,  1.35it/s]\u001b[A\n",
            "Iteration:  81% 93/115 [01:08<00:16,  1.35it/s]\u001b[A\n",
            "Iteration:  82% 94/115 [01:09<00:15,  1.35it/s]\u001b[A\n",
            "Iteration:  83% 95/115 [01:10<00:14,  1.35it/s]\u001b[A\n",
            "Iteration:  83% 96/115 [01:10<00:14,  1.36it/s]\u001b[A\n",
            "Iteration:  84% 97/115 [01:11<00:13,  1.36it/s]\u001b[A\n",
            "Iteration:  85% 98/115 [01:12<00:12,  1.35it/s]\u001b[A\n",
            "Iteration:  86% 99/115 [01:13<00:11,  1.35it/s]\u001b[A\n",
            "Iteration:  87% 100/115 [01:13<00:11,  1.35it/s]\u001b[A\n",
            "Iteration:  88% 101/115 [01:14<00:10,  1.36it/s]\u001b[A\n",
            "Iteration:  89% 102/115 [01:15<00:09,  1.36it/s]\u001b[A\n",
            "Iteration:  90% 103/115 [01:16<00:08,  1.35it/s]\u001b[A\n",
            "Iteration:  90% 104/115 [01:16<00:08,  1.35it/s]\u001b[A\n",
            "Iteration:  91% 105/115 [01:17<00:07,  1.35it/s]\u001b[A\n",
            "Iteration:  92% 106/115 [01:18<00:06,  1.35it/s]\u001b[A\n",
            "Iteration:  93% 107/115 [01:18<00:05,  1.35it/s]\u001b[A\n",
            "Iteration:  94% 108/115 [01:19<00:05,  1.35it/s]\u001b[A\n",
            "Iteration:  95% 109/115 [01:20<00:04,  1.36it/s]\u001b[A\n",
            "Iteration:  96% 110/115 [01:21<00:03,  1.35it/s]\u001b[A\n",
            "Iteration:  97% 111/115 [01:21<00:02,  1.35it/s]\u001b[A\n",
            "Iteration:  97% 112/115 [01:22<00:02,  1.35it/s]\u001b[A\n",
            "Iteration:  98% 113/115 [01:23<00:01,  1.35it/s]\u001b[A\n",
            "Iteration:  99% 114/115 [01:24<00:00,  1.35it/s]\u001b[A\n",
            "Iteration: 100% 115/115 [01:24<00:00,  1.50it/s]\u001b[A\n",
            "Epoch:  38% 3/8 [04:14<07:03, 84.72s/it]\n",
            "Iteration:   0% 0/115 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/115 [00:00<01:24,  1.35it/s]\u001b[A\n",
            "Iteration:   2% 2/115 [00:01<01:23,  1.35it/s]\u001b[A\n",
            "Iteration:   3% 3/115 [00:02<01:22,  1.35it/s]\u001b[A\n",
            "Iteration:   3% 4/115 [00:02<01:22,  1.35it/s]\u001b[A\n",
            "Iteration:   4% 5/115 [00:03<01:21,  1.35it/s]\u001b[A\n",
            "Iteration:   5% 6/115 [00:04<01:20,  1.35it/s]\u001b[A\n",
            "Iteration:   6% 7/115 [00:05<01:19,  1.36it/s]\u001b[A\n",
            "Iteration:   7% 8/115 [00:05<01:19,  1.35it/s]\u001b[A\n",
            "Iteration:   8% 9/115 [00:06<01:18,  1.35it/s]\u001b[A\n",
            "Iteration:   9% 10/115 [00:07<01:17,  1.35it/s]\u001b[A\n",
            "Iteration:  10% 11/115 [00:08<01:17,  1.35it/s]\u001b[A\n",
            "Iteration:  10% 12/115 [00:08<01:16,  1.35it/s]\u001b[A\n",
            "Iteration:  11% 13/115 [00:09<01:15,  1.35it/s]\u001b[A\n",
            "Iteration:  12% 14/115 [00:10<01:14,  1.35it/s]\u001b[A\n",
            "Iteration:  13% 15/115 [00:11<01:14,  1.35it/s]\u001b[A\n",
            "Iteration:  14% 16/115 [00:11<01:13,  1.35it/s]\u001b[A\n",
            "Iteration:  15% 17/115 [00:12<01:12,  1.35it/s]\u001b[A\n",
            "Iteration:  16% 18/115 [00:13<01:11,  1.35it/s]\u001b[A\n",
            "Iteration:  17% 19/115 [00:14<01:11,  1.35it/s]\u001b[A\n",
            "Iteration:  17% 20/115 [00:14<01:10,  1.35it/s]\u001b[A\n",
            "Iteration:  18% 21/115 [00:15<01:09,  1.35it/s]\u001b[A\n",
            "Iteration:  19% 22/115 [00:16<01:08,  1.35it/s]\u001b[A\n",
            "Iteration:  20% 23/115 [00:17<01:08,  1.35it/s]\u001b[A\n",
            "Iteration:  21% 24/115 [00:17<01:07,  1.35it/s]\u001b[A\n",
            "Iteration:  22% 25/115 [00:18<01:06,  1.35it/s]\u001b[A\n",
            "Iteration:  23% 26/115 [00:19<01:05,  1.35it/s]\u001b[A\n",
            "Iteration:  23% 27/115 [00:19<01:05,  1.35it/s]\u001b[A\n",
            "Iteration:  24% 28/115 [00:20<01:04,  1.35it/s]\u001b[A\n",
            "Iteration:  25% 29/115 [00:21<01:03,  1.35it/s]\u001b[A\n",
            "Iteration:  26% 30/115 [00:22<01:02,  1.35it/s]\u001b[A\n",
            "Iteration:  27% 31/115 [00:22<01:02,  1.35it/s]\u001b[A\n",
            "Iteration:  28% 32/115 [00:23<01:01,  1.35it/s]\u001b[A\n",
            "Iteration:  29% 33/115 [00:24<01:00,  1.35it/s]\u001b[A\n",
            "Iteration:  30% 34/115 [00:25<01:00,  1.35it/s]\u001b[A\n",
            "Iteration:  30% 35/115 [00:25<00:59,  1.35it/s]\u001b[A\n",
            "Iteration:  31% 36/115 [00:26<00:58,  1.35it/s]\u001b[A\n",
            "Iteration:  32% 37/115 [00:27<00:57,  1.35it/s]\u001b[A\n",
            "Iteration:  33% 38/115 [00:28<00:57,  1.35it/s]\u001b[A\n",
            "Iteration:  34% 39/115 [00:28<00:56,  1.35it/s]\u001b[A\n",
            "Iteration:  35% 40/115 [00:29<00:55,  1.34it/s]\u001b[A\n",
            "Iteration:  36% 41/115 [00:30<00:55,  1.34it/s]\u001b[A\n",
            "Iteration:  37% 42/115 [00:31<00:54,  1.34it/s]\u001b[A\n",
            "Iteration:  37% 43/115 [00:31<00:53,  1.35it/s]\u001b[A\n",
            "Iteration:  38% 44/115 [00:32<00:52,  1.35it/s]\u001b[A\n",
            "Iteration:  39% 45/115 [00:33<00:51,  1.35it/s]\u001b[A\n",
            "Iteration:  40% 46/115 [00:34<00:51,  1.35it/s]\u001b[A\n",
            "Iteration:  41% 47/115 [00:34<00:50,  1.35it/s]\u001b[A\n",
            "Iteration:  42% 48/115 [00:35<00:49,  1.34it/s]\u001b[A\n",
            "Iteration:  43% 49/115 [00:36<00:49,  1.34it/s]\u001b[A\n",
            "Iteration:  43% 50/115 [00:37<00:48,  1.34it/s]\u001b[A\n",
            "Iteration:  44% 51/115 [00:37<00:47,  1.35it/s]\u001b[A\n",
            "Iteration:  45% 52/115 [00:38<00:46,  1.35it/s]\u001b[A\n",
            "Iteration:  46% 53/115 [00:39<00:46,  1.35it/s]\u001b[A\n",
            "Iteration:  47% 54/115 [00:40<00:45,  1.35it/s]\u001b[A\n",
            "Iteration:  48% 55/115 [00:40<00:44,  1.35it/s]\u001b[A\n",
            "Iteration:  49% 56/115 [00:41<00:43,  1.35it/s]\u001b[A\n",
            "Iteration:  50% 57/115 [00:42<00:43,  1.35it/s]\u001b[A\n",
            "Iteration:  50% 58/115 [00:42<00:42,  1.35it/s]\u001b[A\n",
            "Iteration:  51% 59/115 [00:43<00:41,  1.34it/s]\u001b[A\n",
            "Iteration:  52% 60/115 [00:44<00:40,  1.34it/s]\u001b[A\n",
            "Iteration:  53% 61/115 [00:45<00:40,  1.35it/s]\u001b[A\n",
            "Iteration:  54% 62/115 [00:45<00:39,  1.34it/s]\u001b[A\n",
            "Iteration:  55% 63/115 [00:46<00:38,  1.34it/s]\u001b[A\n",
            "Iteration:  56% 64/115 [00:47<00:37,  1.35it/s]\u001b[A\n",
            "Iteration:  57% 65/115 [00:48<00:37,  1.35it/s]\u001b[A\n",
            "Iteration:  57% 66/115 [00:48<00:36,  1.35it/s]\u001b[A\n",
            "Iteration:  58% 67/115 [00:49<00:35,  1.35it/s]\u001b[A\n",
            "Iteration:  59% 68/115 [00:50<00:34,  1.35it/s]\u001b[A\n",
            "Iteration:  60% 69/115 [00:51<00:34,  1.35it/s]\u001b[A\n",
            "Iteration:  61% 70/115 [00:51<00:33,  1.35it/s]\u001b[A\n",
            "Iteration:  62% 71/115 [00:52<00:32,  1.35it/s]\u001b[A\n",
            "Iteration:  63% 72/115 [00:53<00:31,  1.35it/s]\u001b[A\n",
            "Iteration:  63% 73/115 [00:54<00:31,  1.35it/s]\u001b[A\n",
            "Iteration:  64% 74/115 [00:54<00:30,  1.35it/s]\u001b[A\n",
            "Iteration:  65% 75/115 [00:55<00:29,  1.35it/s]\u001b[A\n",
            "Iteration:  66% 76/115 [00:56<00:28,  1.35it/s]\u001b[A\n",
            "Iteration:  67% 77/115 [00:57<00:28,  1.35it/s]\u001b[A\n",
            "Iteration:  68% 78/115 [00:57<00:27,  1.35it/s]\u001b[A\n",
            "Iteration:  69% 79/115 [00:58<00:26,  1.35it/s]\u001b[A\n",
            "Iteration:  70% 80/115 [00:59<00:25,  1.35it/s]\u001b[A\n",
            "Iteration:  70% 81/115 [01:00<00:25,  1.35it/s]\u001b[A\n",
            "Iteration:  71% 82/115 [01:00<00:24,  1.35it/s]\u001b[A\n",
            "Iteration:  72% 83/115 [01:01<00:23,  1.35it/s]\u001b[A\n",
            "Iteration:  73% 84/115 [01:02<00:22,  1.35it/s]\u001b[A\n",
            "Iteration:  74% 85/115 [01:03<00:22,  1.35it/s]\u001b[A\n",
            "Iteration:  75% 86/115 [01:03<00:21,  1.35it/s]\u001b[A\n",
            "Iteration:  76% 87/115 [01:04<00:20,  1.35it/s]\u001b[A\n",
            "Iteration:  77% 88/115 [01:05<00:19,  1.35it/s]\u001b[A\n",
            "Iteration:  77% 89/115 [01:05<00:19,  1.35it/s]\u001b[A\n",
            "Iteration:  78% 90/115 [01:06<00:18,  1.35it/s]\u001b[A\n",
            "Iteration:  79% 91/115 [01:07<00:17,  1.35it/s]\u001b[A\n",
            "Iteration:  80% 92/115 [01:08<00:16,  1.35it/s]\u001b[A\n",
            "Iteration:  81% 93/115 [01:08<00:16,  1.35it/s]\u001b[A\n",
            "Iteration:  82% 94/115 [01:09<00:15,  1.35it/s]\u001b[A\n",
            "Iteration:  83% 95/115 [01:10<00:14,  1.35it/s]\u001b[A\n",
            "Iteration:  83% 96/115 [01:11<00:14,  1.35it/s]\u001b[A\n",
            "Iteration:  84% 97/115 [01:11<00:13,  1.36it/s]\u001b[A\n",
            "Iteration:  85% 98/115 [01:12<00:12,  1.36it/s]\u001b[A\n",
            "Iteration:  86% 99/115 [01:13<00:11,  1.35it/s]\u001b[A\n",
            "Iteration:  87% 100/115 [01:14<00:11,  1.35it/s]\u001b[A\n",
            "Iteration:  88% 101/115 [01:14<00:10,  1.35it/s]\u001b[A\n",
            "Iteration:  89% 102/115 [01:15<00:09,  1.35it/s]\u001b[A\n",
            "Iteration:  90% 103/115 [01:16<00:08,  1.35it/s]\u001b[A\n",
            "Iteration:  90% 104/115 [01:17<00:08,  1.35it/s]\u001b[A\n",
            "Iteration:  91% 105/115 [01:17<00:07,  1.35it/s]\u001b[A\n",
            "Iteration:  92% 106/115 [01:18<00:06,  1.35it/s]\u001b[A\n",
            "Iteration:  93% 107/115 [01:19<00:05,  1.35it/s]\u001b[A\n",
            "Iteration:  94% 108/115 [01:20<00:05,  1.35it/s]\u001b[A\n",
            "Iteration:  95% 109/115 [01:20<00:04,  1.35it/s]\u001b[A\n",
            "Iteration:  96% 110/115 [01:21<00:03,  1.35it/s]\u001b[A\n",
            "Iteration:  97% 111/115 [01:22<00:02,  1.35it/s]\u001b[A\n",
            "Iteration:  97% 112/115 [01:22<00:02,  1.35it/s]\u001b[A\n",
            "Iteration:  98% 113/115 [01:23<00:01,  1.35it/s]\u001b[A\n",
            "Iteration:  99% 114/115 [01:24<00:00,  1.35it/s]\u001b[A\n",
            "Iteration: 100% 115/115 [01:24<00:00,  1.50it/s]\u001b[A\n",
            "Epoch:  50% 4/8 [05:39<05:39, 84.79s/it]\n",
            "Iteration:   0% 0/115 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/115 [00:00<01:24,  1.35it/s]\u001b[A\n",
            "Iteration:   2% 2/115 [00:01<01:23,  1.35it/s]\u001b[A\n",
            "Iteration:   3% 3/115 [00:02<01:22,  1.35it/s]\u001b[A\n",
            "Iteration:   3% 4/115 [00:02<01:22,  1.35it/s]\u001b[A\n",
            "Iteration:   4% 5/115 [00:03<01:21,  1.35it/s]\u001b[A\n",
            "Iteration:   5% 6/115 [00:04<01:20,  1.35it/s]\u001b[A\n",
            "Iteration:   6% 7/115 [00:05<01:20,  1.35it/s]\u001b[A\n",
            "Iteration:   7% 8/115 [00:05<01:19,  1.35it/s]\u001b[A\n",
            "Iteration:   8% 9/115 [00:06<01:18,  1.35it/s]\u001b[A\n",
            "Iteration:   9% 10/115 [00:07<01:17,  1.35it/s]\u001b[A\n",
            "Iteration:  10% 11/115 [00:08<01:16,  1.35it/s]\u001b[A\n",
            "Iteration:  10% 12/115 [00:08<01:16,  1.35it/s]\u001b[A\n",
            "Iteration:  11% 13/115 [00:09<01:15,  1.35it/s]\u001b[A\n",
            "Iteration:  12% 14/115 [00:10<01:14,  1.35it/s]\u001b[A\n",
            "Iteration:  13% 15/115 [00:11<01:14,  1.35it/s]\u001b[A\n",
            "Iteration:  14% 16/115 [00:11<01:13,  1.35it/s]\u001b[A\n",
            "Iteration:  15% 17/115 [00:12<01:12,  1.35it/s]\u001b[A\n",
            "Iteration:  16% 18/115 [00:13<01:11,  1.35it/s]\u001b[A\n",
            "Iteration:  17% 19/115 [00:14<01:11,  1.35it/s]\u001b[A\n",
            "Iteration:  17% 20/115 [00:14<01:10,  1.35it/s]\u001b[A\n",
            "Iteration:  18% 21/115 [00:15<01:09,  1.35it/s]\u001b[A\n",
            "Iteration:  19% 22/115 [00:16<01:08,  1.35it/s]\u001b[A\n",
            "Iteration:  20% 23/115 [00:17<01:08,  1.35it/s]\u001b[A\n",
            "Iteration:  21% 24/115 [00:17<01:07,  1.35it/s]\u001b[A\n",
            "Iteration:  22% 25/115 [00:18<01:06,  1.36it/s]\u001b[A\n",
            "Iteration:  23% 26/115 [00:19<01:05,  1.36it/s]\u001b[A\n",
            "Iteration:  23% 27/115 [00:19<01:04,  1.36it/s]\u001b[A\n",
            "Iteration:  24% 28/115 [00:20<01:04,  1.36it/s]\u001b[A\n",
            "Iteration:  25% 29/115 [00:21<01:03,  1.35it/s]\u001b[A\n",
            "Iteration:  26% 30/115 [00:22<01:02,  1.35it/s]\u001b[A\n",
            "Iteration:  27% 31/115 [00:22<01:01,  1.36it/s]\u001b[A\n",
            "Iteration:  28% 32/115 [00:23<01:01,  1.35it/s]\u001b[A\n",
            "Iteration:  29% 33/115 [00:24<01:00,  1.36it/s]\u001b[A\n",
            "Iteration:  30% 34/115 [00:25<00:59,  1.35it/s]\u001b[A\n",
            "Iteration:  30% 35/115 [00:25<00:59,  1.35it/s]\u001b[A\n",
            "Iteration:  31% 36/115 [00:26<00:58,  1.35it/s]\u001b[A\n",
            "Iteration:  32% 37/115 [00:27<00:57,  1.36it/s]\u001b[A\n",
            "Iteration:  33% 38/115 [00:28<00:56,  1.36it/s]\u001b[A\n",
            "Iteration:  34% 39/115 [00:28<00:56,  1.35it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "{\"learning_rate\": 9.130434782608697e-06, \"loss\": 0.3483793140724301, \"step\": 500}\n",
            "03/07/2020 12:52:11 - INFO - transformers.configuration_utils -   Configuration saved in mrpc_output/checkpoint-500/config.json\n",
            "03/07/2020 12:52:12 - INFO - transformers.modeling_utils -   Model weights saved in mrpc_output/checkpoint-500/pytorch_model.bin\n",
            "03/07/2020 12:52:12 - INFO - __main__ -   Saving model checkpoint to mrpc_output/checkpoint-500\n",
            "03/07/2020 12:52:16 - INFO - __main__ -   Saving optimizer and scheduler states to mrpc_output/checkpoint-500\n",
            "\n",
            "Iteration:  35% 40/115 [00:34<02:39,  2.13s/it]\u001b[A\n",
            "Iteration:  36% 41/115 [00:34<02:07,  1.72s/it]\u001b[A\n",
            "Iteration:  37% 42/115 [00:35<01:43,  1.42s/it]\u001b[A\n",
            "Iteration:  37% 43/115 [00:36<01:27,  1.21s/it]\u001b[A\n",
            "Iteration:  38% 44/115 [00:37<01:15,  1.06s/it]\u001b[A\n",
            "Iteration:  39% 45/115 [00:37<01:07,  1.03it/s]\u001b[A\n",
            "Iteration:  40% 46/115 [00:38<01:01,  1.12it/s]\u001b[A\n",
            "Iteration:  41% 47/115 [00:39<00:57,  1.19it/s]\u001b[A\n",
            "Iteration:  42% 48/115 [00:40<00:54,  1.23it/s]\u001b[A\n",
            "Iteration:  43% 49/115 [00:40<00:51,  1.27it/s]\u001b[A\n",
            "Iteration:  43% 50/115 [00:41<00:50,  1.30it/s]\u001b[A\n",
            "Iteration:  44% 51/115 [00:42<00:48,  1.32it/s]\u001b[A\n",
            "Iteration:  45% 52/115 [00:42<00:47,  1.33it/s]\u001b[A\n",
            "Iteration:  46% 53/115 [00:43<00:46,  1.34it/s]\u001b[A\n",
            "Iteration:  47% 54/115 [00:44<00:45,  1.34it/s]\u001b[A\n",
            "Iteration:  48% 55/115 [00:45<00:44,  1.35it/s]\u001b[A\n",
            "Iteration:  49% 56/115 [00:45<00:43,  1.35it/s]\u001b[A\n",
            "Iteration:  50% 57/115 [00:46<00:42,  1.35it/s]\u001b[A\n",
            "Iteration:  50% 58/115 [00:47<00:42,  1.35it/s]\u001b[A\n",
            "Iteration:  51% 59/115 [00:48<00:41,  1.34it/s]\u001b[A\n",
            "Iteration:  52% 60/115 [00:48<00:40,  1.35it/s]\u001b[A\n",
            "Iteration:  53% 61/115 [00:49<00:40,  1.35it/s]\u001b[A\n",
            "Iteration:  54% 62/115 [00:50<00:39,  1.35it/s]\u001b[A\n",
            "Iteration:  55% 63/115 [00:51<00:38,  1.34it/s]\u001b[A\n",
            "Iteration:  56% 64/115 [00:51<00:37,  1.35it/s]\u001b[A\n",
            "Iteration:  57% 65/115 [00:52<00:37,  1.34it/s]\u001b[A\n",
            "Iteration:  57% 66/115 [00:53<00:36,  1.34it/s]\u001b[A\n",
            "Iteration:  58% 67/115 [00:54<00:35,  1.34it/s]\u001b[A\n",
            "Iteration:  59% 68/115 [00:54<00:35,  1.33it/s]\u001b[A\n",
            "Iteration:  60% 69/115 [00:55<00:34,  1.33it/s]\u001b[A\n",
            "Iteration:  61% 70/115 [00:56<00:33,  1.33it/s]\u001b[A\n",
            "Iteration:  62% 71/115 [00:57<00:33,  1.32it/s]\u001b[A\n",
            "Iteration:  63% 72/115 [00:57<00:32,  1.32it/s]\u001b[A\n",
            "Iteration:  63% 73/115 [00:58<00:31,  1.32it/s]\u001b[A\n",
            "Iteration:  64% 74/115 [00:59<00:31,  1.31it/s]\u001b[A\n",
            "Iteration:  65% 75/115 [01:00<00:30,  1.31it/s]\u001b[A\n",
            "Iteration:  66% 76/115 [01:00<00:29,  1.31it/s]\u001b[A\n",
            "Iteration:  67% 77/115 [01:01<00:28,  1.31it/s]\u001b[A\n",
            "Iteration:  68% 78/115 [01:02<00:28,  1.31it/s]\u001b[A\n",
            "Iteration:  69% 79/115 [01:03<00:27,  1.31it/s]\u001b[A\n",
            "Iteration:  70% 80/115 [01:04<00:26,  1.31it/s]\u001b[A\n",
            "Iteration:  70% 81/115 [01:04<00:25,  1.31it/s]\u001b[A\n",
            "Iteration:  71% 82/115 [01:05<00:25,  1.31it/s]\u001b[A\n",
            "Iteration:  72% 83/115 [01:06<00:24,  1.32it/s]\u001b[A\n",
            "Iteration:  73% 84/115 [01:07<00:23,  1.32it/s]\u001b[A\n",
            "Iteration:  74% 85/115 [01:07<00:22,  1.33it/s]\u001b[A\n",
            "Iteration:  75% 86/115 [01:08<00:21,  1.33it/s]\u001b[A\n",
            "Iteration:  76% 87/115 [01:09<00:21,  1.33it/s]\u001b[A\n",
            "Iteration:  77% 88/115 [01:10<00:20,  1.33it/s]\u001b[A\n",
            "Iteration:  77% 89/115 [01:10<00:19,  1.33it/s]\u001b[A\n",
            "Iteration:  78% 90/115 [01:11<00:18,  1.34it/s]\u001b[A\n",
            "Iteration:  79% 91/115 [01:12<00:17,  1.34it/s]\u001b[A\n",
            "Iteration:  80% 92/115 [01:13<00:17,  1.34it/s]\u001b[A\n",
            "Iteration:  81% 93/115 [01:13<00:16,  1.34it/s]\u001b[A\n",
            "Iteration:  82% 94/115 [01:14<00:15,  1.34it/s]\u001b[A\n",
            "Iteration:  83% 95/115 [01:15<00:14,  1.34it/s]\u001b[A\n",
            "Iteration:  83% 96/115 [01:15<00:14,  1.35it/s]\u001b[A\n",
            "Iteration:  84% 97/115 [01:16<00:13,  1.35it/s]\u001b[A\n",
            "Iteration:  85% 98/115 [01:17<00:12,  1.35it/s]\u001b[A\n",
            "Iteration:  86% 99/115 [01:18<00:11,  1.35it/s]\u001b[A\n",
            "Iteration:  87% 100/115 [01:18<00:11,  1.35it/s]\u001b[A\n",
            "Iteration:  88% 101/115 [01:19<00:10,  1.35it/s]\u001b[A\n",
            "Iteration:  89% 102/115 [01:20<00:09,  1.35it/s]\u001b[A\n",
            "Iteration:  90% 103/115 [01:21<00:08,  1.35it/s]\u001b[A\n",
            "Iteration:  90% 104/115 [01:21<00:08,  1.35it/s]\u001b[A\n",
            "Iteration:  91% 105/115 [01:22<00:07,  1.36it/s]\u001b[A\n",
            "Iteration:  92% 106/115 [01:23<00:06,  1.36it/s]\u001b[A\n",
            "Iteration:  93% 107/115 [01:24<00:05,  1.36it/s]\u001b[A\n",
            "Iteration:  94% 108/115 [01:24<00:05,  1.36it/s]\u001b[A\n",
            "Iteration:  95% 109/115 [01:25<00:04,  1.36it/s]\u001b[A\n",
            "Iteration:  96% 110/115 [01:26<00:03,  1.36it/s]\u001b[A\n",
            "Iteration:  97% 111/115 [01:27<00:02,  1.36it/s]\u001b[A\n",
            "Iteration:  97% 112/115 [01:27<00:02,  1.36it/s]\u001b[A\n",
            "Iteration:  98% 113/115 [01:28<00:01,  1.36it/s]\u001b[A\n",
            "Iteration:  99% 114/115 [01:29<00:00,  1.36it/s]\u001b[A\n",
            "Iteration: 100% 115/115 [01:29<00:00,  1.51it/s]\u001b[A\n",
            "Epoch:  62% 5/8 [07:08<04:18, 86.28s/it]\n",
            "Iteration:   0% 0/115 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/115 [00:00<01:23,  1.36it/s]\u001b[A\n",
            "Iteration:   2% 2/115 [00:01<01:23,  1.36it/s]\u001b[A\n",
            "Iteration:   3% 3/115 [00:02<01:22,  1.36it/s]\u001b[A\n",
            "Iteration:   3% 4/115 [00:02<01:21,  1.36it/s]\u001b[A\n",
            "Iteration:   4% 5/115 [00:03<01:20,  1.37it/s]\u001b[A\n",
            "Iteration:   5% 6/115 [00:04<01:19,  1.37it/s]\u001b[A\n",
            "Iteration:   6% 7/115 [00:05<01:18,  1.37it/s]\u001b[A\n",
            "Iteration:   7% 8/115 [00:05<01:18,  1.37it/s]\u001b[A\n",
            "Iteration:   8% 9/115 [00:06<01:17,  1.37it/s]\u001b[A\n",
            "Iteration:   9% 10/115 [00:07<01:16,  1.37it/s]\u001b[A\n",
            "Iteration:  10% 11/115 [00:08<01:15,  1.37it/s]\u001b[A\n",
            "Iteration:  10% 12/115 [00:08<01:15,  1.37it/s]\u001b[A\n",
            "Iteration:  11% 13/115 [00:09<01:14,  1.37it/s]\u001b[A\n",
            "Iteration:  12% 14/115 [00:10<01:13,  1.37it/s]\u001b[A\n",
            "Iteration:  13% 15/115 [00:10<01:13,  1.37it/s]\u001b[A\n",
            "Iteration:  14% 16/115 [00:11<01:12,  1.37it/s]\u001b[A\n",
            "Iteration:  15% 17/115 [00:12<01:11,  1.37it/s]\u001b[A\n",
            "Iteration:  16% 18/115 [00:13<01:11,  1.37it/s]\u001b[A\n",
            "Iteration:  17% 19/115 [00:13<01:10,  1.37it/s]\u001b[A\n",
            "Iteration:  17% 20/115 [00:14<01:09,  1.37it/s]\u001b[A\n",
            "Iteration:  18% 21/115 [00:15<01:08,  1.37it/s]\u001b[A\n",
            "Iteration:  19% 22/115 [00:16<01:08,  1.37it/s]\u001b[A\n",
            "Iteration:  20% 23/115 [00:16<01:07,  1.37it/s]\u001b[A\n",
            "Iteration:  21% 24/115 [00:17<01:06,  1.37it/s]\u001b[A\n",
            "Iteration:  22% 25/115 [00:18<01:06,  1.36it/s]\u001b[A\n",
            "Iteration:  23% 26/115 [00:19<01:05,  1.36it/s]\u001b[A\n",
            "Iteration:  23% 27/115 [00:19<01:04,  1.36it/s]\u001b[A\n",
            "Iteration:  24% 28/115 [00:20<01:03,  1.36it/s]\u001b[A\n",
            "Iteration:  25% 29/115 [00:21<01:03,  1.36it/s]\u001b[A\n",
            "Iteration:  26% 30/115 [00:21<01:02,  1.36it/s]\u001b[A\n",
            "Iteration:  27% 31/115 [00:22<01:01,  1.36it/s]\u001b[A\n",
            "Iteration:  28% 32/115 [00:23<01:01,  1.36it/s]\u001b[A\n",
            "Iteration:  29% 33/115 [00:24<01:00,  1.36it/s]\u001b[A\n",
            "Iteration:  30% 34/115 [00:24<00:59,  1.36it/s]\u001b[A\n",
            "Iteration:  30% 35/115 [00:25<00:58,  1.36it/s]\u001b[A\n",
            "Iteration:  31% 36/115 [00:26<00:58,  1.36it/s]\u001b[A\n",
            "Iteration:  32% 37/115 [00:27<00:57,  1.36it/s]\u001b[A\n",
            "Iteration:  33% 38/115 [00:27<00:56,  1.36it/s]\u001b[A\n",
            "Iteration:  34% 39/115 [00:28<00:55,  1.36it/s]\u001b[A\n",
            "Iteration:  35% 40/115 [00:29<00:55,  1.36it/s]\u001b[A\n",
            "Iteration:  36% 41/115 [00:30<00:54,  1.36it/s]\u001b[A\n",
            "Iteration:  37% 42/115 [00:30<00:53,  1.36it/s]\u001b[A\n",
            "Iteration:  37% 43/115 [00:31<00:53,  1.36it/s]\u001b[A\n",
            "Iteration:  38% 44/115 [00:32<00:52,  1.36it/s]\u001b[A\n",
            "Iteration:  39% 45/115 [00:32<00:51,  1.36it/s]\u001b[A\n",
            "Iteration:  40% 46/115 [00:33<00:50,  1.36it/s]\u001b[A\n",
            "Iteration:  41% 47/115 [00:34<00:50,  1.36it/s]\u001b[A\n",
            "Iteration:  42% 48/115 [00:35<00:49,  1.36it/s]\u001b[A\n",
            "Iteration:  43% 49/115 [00:35<00:48,  1.35it/s]\u001b[A\n",
            "Iteration:  43% 50/115 [00:36<00:48,  1.35it/s]\u001b[A\n",
            "Iteration:  44% 51/115 [00:37<00:47,  1.36it/s]\u001b[A\n",
            "Iteration:  45% 52/115 [00:38<00:46,  1.35it/s]\u001b[A\n",
            "Iteration:  46% 53/115 [00:38<00:45,  1.36it/s]\u001b[A\n",
            "Iteration:  47% 54/115 [00:39<00:45,  1.36it/s]\u001b[A\n",
            "Iteration:  48% 55/115 [00:40<00:44,  1.35it/s]\u001b[A\n",
            "Iteration:  49% 56/115 [00:41<00:43,  1.36it/s]\u001b[A\n",
            "Iteration:  50% 57/115 [00:41<00:42,  1.35it/s]\u001b[A\n",
            "Iteration:  50% 58/115 [00:42<00:42,  1.35it/s]\u001b[A\n",
            "Iteration:  51% 59/115 [00:43<00:41,  1.35it/s]\u001b[A\n",
            "Iteration:  52% 60/115 [00:44<00:40,  1.35it/s]\u001b[A\n",
            "Iteration:  53% 61/115 [00:44<00:40,  1.35it/s]\u001b[A\n",
            "Iteration:  54% 62/115 [00:45<00:39,  1.35it/s]\u001b[A\n",
            "Iteration:  55% 63/115 [00:46<00:38,  1.35it/s]\u001b[A\n",
            "Iteration:  56% 64/115 [00:47<00:37,  1.35it/s]\u001b[A\n",
            "Iteration:  57% 65/115 [00:47<00:37,  1.35it/s]\u001b[A\n",
            "Iteration:  57% 66/115 [00:48<00:36,  1.35it/s]\u001b[A\n",
            "Iteration:  58% 67/115 [00:49<00:35,  1.35it/s]\u001b[A\n",
            "Iteration:  59% 68/115 [00:49<00:34,  1.35it/s]\u001b[A\n",
            "Iteration:  60% 69/115 [00:50<00:34,  1.35it/s]\u001b[A\n",
            "Iteration:  61% 70/115 [00:51<00:33,  1.35it/s]\u001b[A\n",
            "Iteration:  62% 71/115 [00:52<00:32,  1.35it/s]\u001b[A\n",
            "Iteration:  63% 72/115 [00:52<00:31,  1.35it/s]\u001b[A\n",
            "Iteration:  63% 73/115 [00:53<00:31,  1.35it/s]\u001b[A\n",
            "Iteration:  64% 74/115 [00:54<00:30,  1.35it/s]\u001b[A\n",
            "Iteration:  65% 75/115 [00:55<00:29,  1.35it/s]\u001b[A\n",
            "Iteration:  66% 76/115 [00:55<00:29,  1.34it/s]\u001b[A\n",
            "Iteration:  67% 77/115 [00:56<00:28,  1.34it/s]\u001b[A\n",
            "Iteration:  68% 78/115 [00:57<00:27,  1.34it/s]\u001b[A\n",
            "Iteration:  69% 79/115 [00:58<00:26,  1.34it/s]\u001b[A\n",
            "Iteration:  70% 80/115 [00:58<00:25,  1.35it/s]\u001b[A\n",
            "Iteration:  70% 81/115 [00:59<00:25,  1.35it/s]\u001b[A\n",
            "Iteration:  71% 82/115 [01:00<00:24,  1.35it/s]\u001b[A\n",
            "Iteration:  72% 83/115 [01:01<00:23,  1.35it/s]\u001b[A\n",
            "Iteration:  73% 84/115 [01:01<00:23,  1.34it/s]\u001b[A\n",
            "Iteration:  74% 85/115 [01:02<00:22,  1.35it/s]\u001b[A\n",
            "Iteration:  75% 86/115 [01:03<00:21,  1.35it/s]\u001b[A\n",
            "Iteration:  76% 87/115 [01:04<00:20,  1.35it/s]\u001b[A\n",
            "Iteration:  77% 88/115 [01:04<00:19,  1.35it/s]\u001b[A\n",
            "Iteration:  77% 89/115 [01:05<00:19,  1.35it/s]\u001b[A\n",
            "Iteration:  78% 90/115 [01:06<00:18,  1.35it/s]\u001b[A\n",
            "Iteration:  79% 91/115 [01:07<00:17,  1.35it/s]\u001b[A\n",
            "Iteration:  80% 92/115 [01:07<00:17,  1.35it/s]\u001b[A\n",
            "Iteration:  81% 93/115 [01:08<00:16,  1.35it/s]\u001b[A\n",
            "Iteration:  82% 94/115 [01:09<00:15,  1.34it/s]\u001b[A\n",
            "Iteration:  83% 95/115 [01:10<00:14,  1.35it/s]\u001b[A\n",
            "Iteration:  83% 96/115 [01:10<00:14,  1.34it/s]\u001b[A\n",
            "Iteration:  84% 97/115 [01:11<00:13,  1.34it/s]\u001b[A\n",
            "Iteration:  85% 98/115 [01:12<00:12,  1.35it/s]\u001b[A\n",
            "Iteration:  86% 99/115 [01:13<00:11,  1.35it/s]\u001b[A\n",
            "Iteration:  87% 100/115 [01:13<00:11,  1.34it/s]\u001b[A\n",
            "Iteration:  88% 101/115 [01:14<00:10,  1.35it/s]\u001b[A\n",
            "Iteration:  89% 102/115 [01:15<00:09,  1.35it/s]\u001b[A\n",
            "Iteration:  90% 103/115 [01:15<00:08,  1.34it/s]\u001b[A\n",
            "Iteration:  90% 104/115 [01:16<00:08,  1.34it/s]\u001b[A\n",
            "Iteration:  91% 105/115 [01:17<00:07,  1.35it/s]\u001b[A\n",
            "Iteration:  92% 106/115 [01:18<00:06,  1.35it/s]\u001b[A\n",
            "Iteration:  93% 107/115 [01:18<00:05,  1.35it/s]\u001b[A\n",
            "Iteration:  94% 108/115 [01:19<00:05,  1.35it/s]\u001b[A\n",
            "Iteration:  95% 109/115 [01:20<00:04,  1.35it/s]\u001b[A\n",
            "Iteration:  96% 110/115 [01:21<00:03,  1.35it/s]\u001b[A\n",
            "Iteration:  97% 111/115 [01:21<00:02,  1.35it/s]\u001b[A\n",
            "Iteration:  97% 112/115 [01:22<00:02,  1.35it/s]\u001b[A\n",
            "Iteration:  98% 113/115 [01:23<00:01,  1.35it/s]\u001b[A\n",
            "Iteration:  99% 114/115 [01:24<00:00,  1.35it/s]\u001b[A\n",
            "Iteration: 100% 115/115 [01:24<00:00,  1.51it/s]\u001b[A\n",
            "Epoch:  75% 6/8 [08:33<02:51, 85.79s/it]\n",
            "Iteration:   0% 0/115 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/115 [00:00<01:24,  1.35it/s]\u001b[A\n",
            "Iteration:   2% 2/115 [00:01<01:23,  1.35it/s]\u001b[A\n",
            "Iteration:   3% 3/115 [00:02<01:22,  1.35it/s]\u001b[A\n",
            "Iteration:   3% 4/115 [00:02<01:22,  1.35it/s]\u001b[A\n",
            "Iteration:   4% 5/115 [00:03<01:21,  1.35it/s]\u001b[A\n",
            "Iteration:   5% 6/115 [00:04<01:20,  1.36it/s]\u001b[A\n",
            "Iteration:   6% 7/115 [00:05<01:19,  1.36it/s]\u001b[A\n",
            "Iteration:   7% 8/115 [00:05<01:18,  1.36it/s]\u001b[A\n",
            "Iteration:   8% 9/115 [00:06<01:18,  1.36it/s]\u001b[A\n",
            "Iteration:   9% 10/115 [00:07<01:17,  1.35it/s]\u001b[A\n",
            "Iteration:  10% 11/115 [00:08<01:16,  1.35it/s]\u001b[A\n",
            "Iteration:  10% 12/115 [00:08<01:16,  1.35it/s]\u001b[A\n",
            "Iteration:  11% 13/115 [00:09<01:15,  1.35it/s]\u001b[A\n",
            "Iteration:  12% 14/115 [00:10<01:15,  1.34it/s]\u001b[A\n",
            "Iteration:  13% 15/115 [00:11<01:14,  1.35it/s]\u001b[A\n",
            "Iteration:  14% 16/115 [00:11<01:13,  1.35it/s]\u001b[A\n",
            "Iteration:  15% 17/115 [00:12<01:12,  1.35it/s]\u001b[A\n",
            "Iteration:  16% 18/115 [00:13<01:11,  1.35it/s]\u001b[A\n",
            "Iteration:  17% 19/115 [00:14<01:11,  1.35it/s]\u001b[A\n",
            "Iteration:  17% 20/115 [00:14<01:10,  1.36it/s]\u001b[A\n",
            "Iteration:  18% 21/115 [00:15<01:09,  1.35it/s]\u001b[A\n",
            "Iteration:  19% 22/115 [00:16<01:08,  1.36it/s]\u001b[A\n",
            "Iteration:  20% 23/115 [00:16<01:07,  1.35it/s]\u001b[A\n",
            "Iteration:  21% 24/115 [00:17<01:07,  1.36it/s]\u001b[A\n",
            "Iteration:  22% 25/115 [00:18<01:06,  1.36it/s]\u001b[A\n",
            "Iteration:  23% 26/115 [00:19<01:05,  1.36it/s]\u001b[A\n",
            "Iteration:  23% 27/115 [00:19<01:04,  1.36it/s]\u001b[A\n",
            "Iteration:  24% 28/115 [00:20<01:03,  1.36it/s]\u001b[A\n",
            "Iteration:  25% 29/115 [00:21<01:03,  1.36it/s]\u001b[A\n",
            "Iteration:  26% 30/115 [00:22<01:02,  1.36it/s]\u001b[A\n",
            "Iteration:  27% 31/115 [00:22<01:01,  1.36it/s]\u001b[A\n",
            "Iteration:  28% 32/115 [00:23<01:01,  1.36it/s]\u001b[A\n",
            "Iteration:  29% 33/115 [00:24<01:00,  1.36it/s]\u001b[A\n",
            "Iteration:  30% 34/115 [00:25<00:59,  1.36it/s]\u001b[A\n",
            "Iteration:  30% 35/115 [00:25<00:58,  1.36it/s]\u001b[A\n",
            "Iteration:  31% 36/115 [00:26<00:58,  1.36it/s]\u001b[A\n",
            "Iteration:  32% 37/115 [00:27<00:57,  1.36it/s]\u001b[A\n",
            "Iteration:  33% 38/115 [00:28<00:56,  1.36it/s]\u001b[A\n",
            "Iteration:  34% 39/115 [00:28<00:55,  1.36it/s]\u001b[A\n",
            "Iteration:  35% 40/115 [00:29<00:55,  1.36it/s]\u001b[A\n",
            "Iteration:  36% 41/115 [00:30<00:54,  1.36it/s]\u001b[A\n",
            "Iteration:  37% 42/115 [00:30<00:53,  1.36it/s]\u001b[A\n",
            "Iteration:  37% 43/115 [00:31<00:52,  1.36it/s]\u001b[A\n",
            "Iteration:  38% 44/115 [00:32<00:52,  1.36it/s]\u001b[A\n",
            "Iteration:  39% 45/115 [00:33<00:51,  1.36it/s]\u001b[A\n",
            "Iteration:  40% 46/115 [00:33<00:50,  1.36it/s]\u001b[A\n",
            "Iteration:  41% 47/115 [00:34<00:50,  1.36it/s]\u001b[A\n",
            "Iteration:  42% 48/115 [00:35<00:49,  1.36it/s]\u001b[A\n",
            "Iteration:  43% 49/115 [00:36<00:48,  1.36it/s]\u001b[A\n",
            "Iteration:  43% 50/115 [00:36<00:47,  1.36it/s]\u001b[A\n",
            "Iteration:  44% 51/115 [00:37<00:47,  1.36it/s]\u001b[A\n",
            "Iteration:  45% 52/115 [00:38<00:46,  1.36it/s]\u001b[A\n",
            "Iteration:  46% 53/115 [00:39<00:45,  1.36it/s]\u001b[A\n",
            "Iteration:  47% 54/115 [00:39<00:44,  1.36it/s]\u001b[A\n",
            "Iteration:  48% 55/115 [00:40<00:44,  1.36it/s]\u001b[A\n",
            "Iteration:  49% 56/115 [00:41<00:43,  1.36it/s]\u001b[A\n",
            "Iteration:  50% 57/115 [00:42<00:42,  1.36it/s]\u001b[A\n",
            "Iteration:  50% 58/115 [00:42<00:42,  1.36it/s]\u001b[A\n",
            "Iteration:  51% 59/115 [00:43<00:41,  1.35it/s]\u001b[A\n",
            "Iteration:  52% 60/115 [00:44<00:40,  1.36it/s]\u001b[A\n",
            "Iteration:  53% 61/115 [00:44<00:39,  1.36it/s]\u001b[A\n",
            "Iteration:  54% 62/115 [00:45<00:39,  1.35it/s]\u001b[A\n",
            "Iteration:  55% 63/115 [00:46<00:38,  1.36it/s]\u001b[A\n",
            "Iteration:  56% 64/115 [00:47<00:37,  1.36it/s]\u001b[A\n",
            "Iteration:  57% 65/115 [00:47<00:36,  1.36it/s]\u001b[A\n",
            "Iteration:  57% 66/115 [00:48<00:36,  1.35it/s]\u001b[A\n",
            "Iteration:  58% 67/115 [00:49<00:35,  1.36it/s]\u001b[A\n",
            "Iteration:  59% 68/115 [00:50<00:34,  1.36it/s]\u001b[A\n",
            "Iteration:  60% 69/115 [00:50<00:33,  1.36it/s]\u001b[A\n",
            "Iteration:  61% 70/115 [00:51<00:33,  1.36it/s]\u001b[A\n",
            "Iteration:  62% 71/115 [00:52<00:32,  1.36it/s]\u001b[A\n",
            "Iteration:  63% 72/115 [00:53<00:31,  1.36it/s]\u001b[A\n",
            "Iteration:  63% 73/115 [00:53<00:30,  1.36it/s]\u001b[A\n",
            "Iteration:  64% 74/115 [00:54<00:30,  1.36it/s]\u001b[A\n",
            "Iteration:  65% 75/115 [00:55<00:29,  1.36it/s]\u001b[A\n",
            "Iteration:  66% 76/115 [00:56<00:28,  1.36it/s]\u001b[A\n",
            "Iteration:  67% 77/115 [00:56<00:27,  1.36it/s]\u001b[A\n",
            "Iteration:  68% 78/115 [00:57<00:27,  1.36it/s]\u001b[A\n",
            "Iteration:  69% 79/115 [00:58<00:26,  1.36it/s]\u001b[A\n",
            "Iteration:  70% 80/115 [00:58<00:25,  1.36it/s]\u001b[A\n",
            "Iteration:  70% 81/115 [00:59<00:25,  1.36it/s]\u001b[A\n",
            "Iteration:  71% 82/115 [01:00<00:24,  1.36it/s]\u001b[A\n",
            "Iteration:  72% 83/115 [01:01<00:23,  1.36it/s]\u001b[A\n",
            "Iteration:  73% 84/115 [01:01<00:22,  1.36it/s]\u001b[A\n",
            "Iteration:  74% 85/115 [01:02<00:22,  1.36it/s]\u001b[A\n",
            "Iteration:  75% 86/115 [01:03<00:21,  1.36it/s]\u001b[A\n",
            "Iteration:  76% 87/115 [01:04<00:20,  1.36it/s]\u001b[A\n",
            "Iteration:  77% 88/115 [01:04<00:19,  1.37it/s]\u001b[A\n",
            "Iteration:  77% 89/115 [01:05<00:19,  1.37it/s]\u001b[A\n",
            "Iteration:  78% 90/115 [01:06<00:18,  1.36it/s]\u001b[A\n",
            "Iteration:  79% 91/115 [01:07<00:17,  1.36it/s]\u001b[A\n",
            "Iteration:  80% 92/115 [01:07<00:16,  1.36it/s]\u001b[A\n",
            "Iteration:  81% 93/115 [01:08<00:16,  1.36it/s]\u001b[A\n",
            "Iteration:  82% 94/115 [01:09<00:15,  1.36it/s]\u001b[A\n",
            "Iteration:  83% 95/115 [01:10<00:14,  1.36it/s]\u001b[A\n",
            "Iteration:  83% 96/115 [01:10<00:14,  1.35it/s]\u001b[A\n",
            "Iteration:  84% 97/115 [01:11<00:13,  1.36it/s]\u001b[A\n",
            "Iteration:  85% 98/115 [01:12<00:12,  1.36it/s]\u001b[A\n",
            "Iteration:  86% 99/115 [01:12<00:11,  1.36it/s]\u001b[A\n",
            "Iteration:  87% 100/115 [01:13<00:11,  1.36it/s]\u001b[A\n",
            "Iteration:  88% 101/115 [01:14<00:10,  1.36it/s]\u001b[A\n",
            "Iteration:  89% 102/115 [01:15<00:09,  1.36it/s]\u001b[A\n",
            "Iteration:  90% 103/115 [01:15<00:08,  1.36it/s]\u001b[A\n",
            "Iteration:  90% 104/115 [01:16<00:08,  1.36it/s]\u001b[A\n",
            "Iteration:  91% 105/115 [01:17<00:07,  1.36it/s]\u001b[A\n",
            "Iteration:  92% 106/115 [01:18<00:06,  1.36it/s]\u001b[A\n",
            "Iteration:  93% 107/115 [01:18<00:05,  1.36it/s]\u001b[A\n",
            "Iteration:  94% 108/115 [01:19<00:05,  1.36it/s]\u001b[A\n",
            "Iteration:  95% 109/115 [01:20<00:04,  1.36it/s]\u001b[A\n",
            "Iteration:  96% 110/115 [01:21<00:03,  1.36it/s]\u001b[A\n",
            "Iteration:  97% 111/115 [01:21<00:02,  1.36it/s]\u001b[A\n",
            "Iteration:  97% 112/115 [01:22<00:02,  1.36it/s]\u001b[A\n",
            "Iteration:  98% 113/115 [01:23<00:01,  1.35it/s]\u001b[A\n",
            "Iteration:  99% 114/115 [01:23<00:00,  1.36it/s]\u001b[A\n",
            "Iteration: 100% 115/115 [01:24<00:00,  1.51it/s]\u001b[A\n",
            "Epoch:  88% 7/8 [09:57<01:25, 85.39s/it]\n",
            "Iteration:   0% 0/115 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/115 [00:00<01:23,  1.36it/s]\u001b[A\n",
            "Iteration:   2% 2/115 [00:01<01:22,  1.37it/s]\u001b[A\n",
            "Iteration:   3% 3/115 [00:02<01:22,  1.36it/s]\u001b[A\n",
            "Iteration:   3% 4/115 [00:02<01:21,  1.36it/s]\u001b[A\n",
            "Iteration:   4% 5/115 [00:03<01:20,  1.36it/s]\u001b[A\n",
            "Iteration:   5% 6/115 [00:04<01:20,  1.36it/s]\u001b[A\n",
            "Iteration:   6% 7/115 [00:05<01:19,  1.36it/s]\u001b[A\n",
            "Iteration:   7% 8/115 [00:05<01:18,  1.36it/s]\u001b[A\n",
            "Iteration:   8% 9/115 [00:06<01:18,  1.36it/s]\u001b[A\n",
            "Iteration:   9% 10/115 [00:07<01:17,  1.36it/s]\u001b[A\n",
            "Iteration:  10% 11/115 [00:08<01:16,  1.35it/s]\u001b[A\n",
            "Iteration:  10% 12/115 [00:08<01:16,  1.35it/s]\u001b[A\n",
            "Iteration:  11% 13/115 [00:09<01:15,  1.35it/s]\u001b[A\n",
            "Iteration:  12% 14/115 [00:10<01:14,  1.35it/s]\u001b[A\n",
            "Iteration:  13% 15/115 [00:11<01:13,  1.35it/s]\u001b[A\n",
            "Iteration:  14% 16/115 [00:11<01:13,  1.35it/s]\u001b[A\n",
            "Iteration:  15% 17/115 [00:12<01:12,  1.36it/s]\u001b[A\n",
            "Iteration:  16% 18/115 [00:13<01:11,  1.35it/s]\u001b[A\n",
            "Iteration:  17% 19/115 [00:14<01:11,  1.35it/s]\u001b[A\n",
            "Iteration:  17% 20/115 [00:14<01:10,  1.35it/s]\u001b[A\n",
            "Iteration:  18% 21/115 [00:15<01:09,  1.35it/s]\u001b[A\n",
            "Iteration:  19% 22/115 [00:16<01:08,  1.35it/s]\u001b[A\n",
            "Iteration:  20% 23/115 [00:16<01:08,  1.35it/s]\u001b[A\n",
            "Iteration:  21% 24/115 [00:17<01:07,  1.35it/s]\u001b[A\n",
            "Iteration:  22% 25/115 [00:18<01:06,  1.35it/s]\u001b[A\n",
            "Iteration:  23% 26/115 [00:19<01:05,  1.35it/s]\u001b[A\n",
            "Iteration:  23% 27/115 [00:19<01:04,  1.36it/s]\u001b[A\n",
            "Iteration:  24% 28/115 [00:20<01:04,  1.36it/s]\u001b[A\n",
            "Iteration:  25% 29/115 [00:21<01:03,  1.36it/s]\u001b[A\n",
            "Iteration:  26% 30/115 [00:22<01:02,  1.36it/s]\u001b[A\n",
            "Iteration:  27% 31/115 [00:22<01:01,  1.36it/s]\u001b[A\n",
            "Iteration:  28% 32/115 [00:23<01:01,  1.36it/s]\u001b[A\n",
            "Iteration:  29% 33/115 [00:24<01:00,  1.36it/s]\u001b[A\n",
            "Iteration:  30% 34/115 [00:25<00:59,  1.36it/s]\u001b[A\n",
            "Iteration:  30% 35/115 [00:25<00:59,  1.36it/s]\u001b[A\n",
            "Iteration:  31% 36/115 [00:26<00:58,  1.36it/s]\u001b[A\n",
            "Iteration:  32% 37/115 [00:27<00:57,  1.35it/s]\u001b[A\n",
            "Iteration:  33% 38/115 [00:28<00:56,  1.36it/s]\u001b[A\n",
            "Iteration:  34% 39/115 [00:28<00:56,  1.35it/s]\u001b[A\n",
            "Iteration:  35% 40/115 [00:29<00:55,  1.35it/s]\u001b[A\n",
            "Iteration:  36% 41/115 [00:30<00:54,  1.35it/s]\u001b[A\n",
            "Iteration:  37% 42/115 [00:30<00:53,  1.36it/s]\u001b[A\n",
            "Iteration:  37% 43/115 [00:31<00:53,  1.35it/s]\u001b[A\n",
            "Iteration:  38% 44/115 [00:32<00:52,  1.35it/s]\u001b[A\n",
            "Iteration:  39% 45/115 [00:33<00:51,  1.35it/s]\u001b[A\n",
            "Iteration:  40% 46/115 [00:33<00:50,  1.35it/s]\u001b[A\n",
            "Iteration:  41% 47/115 [00:34<00:50,  1.35it/s]\u001b[A\n",
            "Iteration:  42% 48/115 [00:35<00:49,  1.35it/s]\u001b[A\n",
            "Iteration:  43% 49/115 [00:36<00:48,  1.35it/s]\u001b[A\n",
            "Iteration:  43% 50/115 [00:36<00:48,  1.35it/s]\u001b[A\n",
            "Iteration:  44% 51/115 [00:37<00:47,  1.35it/s]\u001b[A\n",
            "Iteration:  45% 52/115 [00:38<00:46,  1.35it/s]\u001b[A\n",
            "Iteration:  46% 53/115 [00:39<00:45,  1.35it/s]\u001b[A\n",
            "Iteration:  47% 54/115 [00:39<00:45,  1.35it/s]\u001b[A\n",
            "Iteration:  48% 55/115 [00:40<00:44,  1.35it/s]\u001b[A\n",
            "Iteration:  49% 56/115 [00:41<00:43,  1.35it/s]\u001b[A\n",
            "Iteration:  50% 57/115 [00:42<00:42,  1.35it/s]\u001b[A\n",
            "Iteration:  50% 58/115 [00:42<00:42,  1.35it/s]\u001b[A\n",
            "Iteration:  51% 59/115 [00:43<00:41,  1.35it/s]\u001b[A\n",
            "Iteration:  52% 60/115 [00:44<00:40,  1.35it/s]\u001b[A\n",
            "Iteration:  53% 61/115 [00:45<00:39,  1.35it/s]\u001b[A\n",
            "Iteration:  54% 62/115 [00:45<00:39,  1.35it/s]\u001b[A\n",
            "Iteration:  55% 63/115 [00:46<00:38,  1.35it/s]\u001b[A\n",
            "Iteration:  56% 64/115 [00:47<00:37,  1.35it/s]\u001b[A\n",
            "Iteration:  57% 65/115 [00:48<00:37,  1.35it/s]\u001b[A\n",
            "Iteration:  57% 66/115 [00:48<00:36,  1.35it/s]\u001b[A\n",
            "Iteration:  58% 67/115 [00:49<00:35,  1.35it/s]\u001b[A\n",
            "Iteration:  59% 68/115 [00:50<00:34,  1.35it/s]\u001b[A\n",
            "Iteration:  60% 69/115 [00:50<00:34,  1.35it/s]\u001b[A\n",
            "Iteration:  61% 70/115 [00:51<00:33,  1.35it/s]\u001b[A\n",
            "Iteration:  62% 71/115 [00:52<00:32,  1.35it/s]\u001b[A\n",
            "Iteration:  63% 72/115 [00:53<00:31,  1.35it/s]\u001b[A\n",
            "Iteration:  63% 73/115 [00:53<00:30,  1.35it/s]\u001b[A\n",
            "Iteration:  64% 74/115 [00:54<00:30,  1.36it/s]\u001b[A\n",
            "Iteration:  65% 75/115 [00:55<00:29,  1.36it/s]\u001b[A\n",
            "Iteration:  66% 76/115 [00:56<00:28,  1.35it/s]\u001b[A\n",
            "Iteration:  67% 77/115 [00:56<00:28,  1.36it/s]\u001b[A\n",
            "Iteration:  68% 78/115 [00:57<00:27,  1.35it/s]\u001b[A\n",
            "Iteration:  69% 79/115 [00:58<00:26,  1.35it/s]\u001b[A\n",
            "Iteration:  70% 80/115 [00:59<00:25,  1.35it/s]\u001b[A\n",
            "Iteration:  70% 81/115 [00:59<00:25,  1.35it/s]\u001b[A\n",
            "Iteration:  71% 82/115 [01:00<00:24,  1.35it/s]\u001b[A\n",
            "Iteration:  72% 83/115 [01:01<00:23,  1.35it/s]\u001b[A\n",
            "Iteration:  73% 84/115 [01:02<00:22,  1.35it/s]\u001b[A\n",
            "Iteration:  74% 85/115 [01:02<00:22,  1.35it/s]\u001b[A\n",
            "Iteration:  75% 86/115 [01:03<00:21,  1.35it/s]\u001b[A\n",
            "Iteration:  76% 87/115 [01:04<00:20,  1.35it/s]\u001b[A\n",
            "Iteration:  77% 88/115 [01:05<00:19,  1.36it/s]\u001b[A\n",
            "Iteration:  77% 89/115 [01:05<00:19,  1.35it/s]\u001b[A\n",
            "Iteration:  78% 90/115 [01:06<00:18,  1.35it/s]\u001b[A\n",
            "Iteration:  79% 91/115 [01:07<00:17,  1.35it/s]\u001b[A\n",
            "Iteration:  80% 92/115 [01:07<00:17,  1.35it/s]\u001b[A\n",
            "Iteration:  81% 93/115 [01:08<00:16,  1.35it/s]\u001b[A\n",
            "Iteration:  82% 94/115 [01:09<00:15,  1.35it/s]\u001b[A\n",
            "Iteration:  83% 95/115 [01:10<00:14,  1.35it/s]\u001b[A\n",
            "Iteration:  83% 96/115 [01:10<00:14,  1.35it/s]\u001b[A\n",
            "Iteration:  84% 97/115 [01:11<00:13,  1.35it/s]\u001b[A\n",
            "Iteration:  85% 98/115 [01:12<00:12,  1.35it/s]\u001b[A\n",
            "Iteration:  86% 99/115 [01:13<00:11,  1.35it/s]\u001b[A\n",
            "Iteration:  87% 100/115 [01:13<00:11,  1.35it/s]\u001b[A\n",
            "Iteration:  88% 101/115 [01:14<00:10,  1.36it/s]\u001b[A\n",
            "Iteration:  89% 102/115 [01:15<00:09,  1.36it/s]\u001b[A\n",
            "Iteration:  90% 103/115 [01:16<00:08,  1.36it/s]\u001b[A\n",
            "Iteration:  90% 104/115 [01:16<00:08,  1.35it/s]\u001b[A\n",
            "Iteration:  91% 105/115 [01:17<00:07,  1.35it/s]\u001b[A\n",
            "Iteration:  92% 106/115 [01:18<00:06,  1.35it/s]\u001b[A\n",
            "Iteration:  93% 107/115 [01:19<00:05,  1.35it/s]\u001b[A\n",
            "Iteration:  94% 108/115 [01:19<00:05,  1.35it/s]\u001b[A\n",
            "Iteration:  95% 109/115 [01:20<00:04,  1.36it/s]\u001b[A\n",
            "Iteration:  96% 110/115 [01:21<00:03,  1.35it/s]\u001b[A\n",
            "Iteration:  97% 111/115 [01:22<00:02,  1.35it/s]\u001b[A\n",
            "Iteration:  97% 112/115 [01:22<00:02,  1.36it/s]\u001b[A\n",
            "Iteration:  98% 113/115 [01:23<00:01,  1.36it/s]\u001b[A\n",
            "Iteration:  99% 114/115 [01:24<00:00,  1.36it/s]\u001b[A\n",
            "Iteration: 100% 115/115 [01:24<00:00,  1.51it/s]\u001b[A\n",
            "Epoch: 100% 8/8 [11:22<00:00, 85.19s/it]\n",
            "03/07/2020 12:57:25 - INFO - __main__ -    global_step = 920, average loss = 0.21014756948165797\n",
            "03/07/2020 12:57:25 - INFO - __main__ -   Saving model checkpoint to mrpc_output\n",
            "03/07/2020 12:57:25 - INFO - transformers.configuration_utils -   Configuration saved in mrpc_output/config.json\n",
            "03/07/2020 12:57:26 - INFO - transformers.modeling_utils -   Model weights saved in mrpc_output/pytorch_model.bin\n",
            "03/07/2020 12:57:26 - INFO - transformers.configuration_utils -   loading configuration file mrpc_output/config.json\n",
            "03/07/2020 12:57:26 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": null,\n",
            "  \"finetuning_task\": \"mrpc\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "03/07/2020 12:57:26 - INFO - transformers.modeling_utils -   loading weights file mrpc_output/pytorch_model.bin\n",
            "03/07/2020 12:57:29 - INFO - transformers.tokenization_utils -   Model name 'mrpc_output' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'mrpc_output' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "03/07/2020 12:57:29 - INFO - transformers.tokenization_utils -   Didn't find file mrpc_output/added_tokens.json. We won't load it.\n",
            "03/07/2020 12:57:29 - INFO - transformers.tokenization_utils -   loading file mrpc_output/vocab.txt\n",
            "03/07/2020 12:57:29 - INFO - transformers.tokenization_utils -   loading file None\n",
            "03/07/2020 12:57:29 - INFO - transformers.tokenization_utils -   loading file mrpc_output/special_tokens_map.json\n",
            "03/07/2020 12:57:29 - INFO - transformers.tokenization_utils -   loading file mrpc_output/tokenizer_config.json\n",
            "03/07/2020 12:57:29 - INFO - transformers.tokenization_utils -   Model name 'mrpc_output' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'mrpc_output' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "03/07/2020 12:57:29 - INFO - transformers.tokenization_utils -   Didn't find file mrpc_output/added_tokens.json. We won't load it.\n",
            "03/07/2020 12:57:29 - INFO - transformers.tokenization_utils -   loading file mrpc_output/vocab.txt\n",
            "03/07/2020 12:57:29 - INFO - transformers.tokenization_utils -   loading file None\n",
            "03/07/2020 12:57:29 - INFO - transformers.tokenization_utils -   loading file mrpc_output/special_tokens_map.json\n",
            "03/07/2020 12:57:29 - INFO - transformers.tokenization_utils -   loading file mrpc_output/tokenizer_config.json\n",
            "03/07/2020 12:57:29 - INFO - __main__ -   Evaluate the following checkpoints: ['mrpc_output']\n",
            "03/07/2020 12:57:29 - INFO - transformers.configuration_utils -   loading configuration file mrpc_output/config.json\n",
            "03/07/2020 12:57:29 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": null,\n",
            "  \"finetuning_task\": \"mrpc\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "03/07/2020 12:57:29 - INFO - transformers.modeling_utils -   loading weights file mrpc_output/pytorch_model.bin\n",
            "03/07/2020 12:57:32 - INFO - __main__ -   Loading features from cached file glue_data//MRPC/cached_dev_bert-base-uncased_128_mrpc\n",
            "03/07/2020 12:57:32 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "03/07/2020 12:57:32 - INFO - __main__ -     Num examples = 408\n",
            "03/07/2020 12:57:32 - INFO - __main__ -     Batch size = 8\n",
            "Evaluating: 100% 51/51 [00:03<00:00, 14.15it/s]\n",
            "03/07/2020 12:57:36 - INFO - __main__ -   ***** Eval results  *****\n",
            "03/07/2020 12:57:36 - INFO - __main__ -     acc = 0.8406862745098039\n",
            "03/07/2020 12:57:36 - INFO - __main__ -     acc_and_f1 = 0.8647875816993464\n",
            "03/07/2020 12:57:36 - INFO - __main__ -     f1 = 0.888888888888889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLt8oJgeiuNU",
        "colab_type": "text"
      },
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Foy1BMnPi1lV",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Using Colab GPU for Training\n",
        "\n",
        "修改->笔记本设置->硬件加速器->GPU\n",
        "\n",
        "Run the following cell to confirm that the GPU is detected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y2gM--OAszS",
        "colab_type": "code",
        "outputId": "1fb4df00-25d0-49c4-cf61-b74d2b4e0f70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device names.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "  print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "  raise SystemError('GPU device not found')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNUG99KGilWG",
        "colab_type": "text"
      },
      "source": [
        "In order for torch to use the GPU, we need to identify and specify the GPU as the device. In the training loop, we will load data onto the device."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsbX-zyqCCDv",
        "colab_type": "code",
        "outputId": "0dbaf54b-8516-4d53-d2f7-88a2c0785a48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import torch\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "  # Tell PyTorch to use the GPU.\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "  print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "  print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "  print('No GPU available, using the CPU instead.')\n",
        "  device = torch.device(\"cpu\")\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_AaHb_tDKjd",
        "colab_type": "code",
        "outputId": "24a5e848-3ddb-4415-86be-48fd08f659f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 12.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.23)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 56.9MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 55.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 62.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: botocore<1.16.0,>=1.15.23 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.23)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.23->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.23->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=28658bf6f90b3792e53606b26469d528528466a9c664d0b9ab6196a61622b000\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nc0CSFLjlvWJ",
        "colab_type": "text"
      },
      "source": [
        "# 2. Loading CoLA Dataset\n",
        "\n",
        "Single sentence classification. It's a set of sentences labeled as grammatically correct or incorrect.\n",
        "\n",
        "We'll use the wget package to download the dataset to the Colab instances' file system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLnawTkrEQci",
        "colab_type": "code",
        "outputId": "b7daf66c-a9b8-4dc8-9832-aeb5f7ccfdcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=e06fced0a1c327a4b299f4ae8807cbef4de2b61ea5c11ef4d636470fcf586990\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdUXfpvmoOhR",
        "colab_type": "text"
      },
      "source": [
        "The dataset is hosted on Github in this repo: https://nyu-mll.github.io/CoLA/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixeIAzm-FFAG",
        "colab_type": "code",
        "outputId": "b72ad8d4-c14a-453b-c557-8460db04f886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import wget\n",
        "import os\n",
        "\n",
        "print('Downloading dataset...')\n",
        "\n",
        "# The URL for the dataset zip file.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "# Download the file (if we haven't already)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "  wget.download(url, './cola_public_1.1.zip')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading dataset...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOHagJxCoVMx",
        "colab_type": "text"
      },
      "source": [
        "Unzip the dataset to the file system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daw010xpIe2l",
        "colab_type": "code",
        "outputId": "eb65d9ae-1b8f-4c33-fec7-1d8fe417542e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# Unzip the dataset (if we haven't already)\n",
        "if not os.path.exists('./cola_public'):\n",
        "  !unzip cola_public_1.1.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cola_public_1.1.zip\n",
            "   creating: cola_public/\n",
            "  inflating: cola_public/README      \n",
            "   creating: cola_public/tokenized/\n",
            "  inflating: cola_public/tokenized/in_domain_dev.tsv  \n",
            "  inflating: cola_public/tokenized/in_domain_train.tsv  \n",
            "  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n",
            "   creating: cola_public/raw/\n",
            "  inflating: cola_public/raw/in_domain_dev.tsv  \n",
            "  inflating: cola_public/raw/in_domain_train.tsv  \n",
            "  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPoXicU4ooG0",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 Parse\n",
        "\n",
        "Both tokenized and raw versions of the data are available.\n",
        "\n",
        "We can't use the pre-tokenized version because, in order to apply the pre-trained BERT, we must use the tokenizer provided by the model.\n",
        "\n",
        "We'll use pandas to parse the \"in-domain\" training set and look at a few of its properties and data points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMVn0KQXK2qB",
        "colab_type": "code",
        "outputId": "9c55e4e2-3a8a-426c-d6be-1a565cb6982d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 8,551\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4882</th>\n",
              "      <td>ks08</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>We will invite volunteers on whom to work.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1130</th>\n",
              "      <td>r-67</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>What the thing which I ate cost almost broke me.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4348</th>\n",
              "      <td>ks08</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>It said that Kim was happy.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>661</th>\n",
              "      <td>bc01</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>John is very fond of Mary.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2711</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Nora pushed the chair.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8291</th>\n",
              "      <td>ad03</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>We wanted to ate cake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4385</th>\n",
              "      <td>ks08</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>Our team played all well.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2733</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Brown equipped Jones with a camera.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3748</th>\n",
              "      <td>ks08</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>Have in our class the kids arrived safely?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8191</th>\n",
              "      <td>ad03</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>There seemed to be three men in the garden.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentence_source  ...                                          sentence\n",
              "4882            ks08  ...        We will invite volunteers on whom to work.\n",
              "1130            r-67  ...  What the thing which I ate cost almost broke me.\n",
              "4348            ks08  ...                       It said that Kim was happy.\n",
              "661             bc01  ...                        John is very fond of Mary.\n",
              "2711            l-93  ...                            Nora pushed the chair.\n",
              "8291            ad03  ...                             We wanted to ate cake\n",
              "4385            ks08  ...                         Our team played all well.\n",
              "2733            l-93  ...               Brown equipped Jones with a camera.\n",
              "3748            ks08  ...        Have in our class the kids arrived safely?\n",
              "8191            ad03  ...       There seemed to be three men in the garden.\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FuSn3CvqD4Q",
        "colab_type": "text"
      },
      "source": [
        "The two properties we actually care about are the sentence and its label, which is referred to as the \"acceptibility judgement\" (0=unaccaptable, 1=acceptable).\n",
        "\n",
        "Here are five sentences which are labeled as not grammatically acceptible.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPdGx0OqMWLK",
        "colab_type": "code",
        "outputId": "3d9cd910-a9a1-49e9-abf9-e6d3e92f1693",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df.loc[df.label == 0].sample(5)[['sentence', 'label']]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7898</th>\n",
              "      <td>I intoned fruit</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2354</th>\n",
              "      <td>We rummaged the desk for papers.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3759</th>\n",
              "      <td>A good friend is remained to me.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6098</th>\n",
              "      <td>I want Bradley that left.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3495</th>\n",
              "      <td>The recent strike by pilots have cost the coun...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  label\n",
              "7898                                    I intoned fruit      0\n",
              "2354                   We rummaged the desk for papers.      0\n",
              "3759                   A good friend is remained to me.      0\n",
              "6098                          I want Bradley that left.      0\n",
              "3495  The recent strike by pilots have cost the coun...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgP-mtoBqleE",
        "colab_type": "text"
      },
      "source": [
        "Extract the sentences and labels of our training set as numpy ndarrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSpvAMFQSbNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1zoOE95sSVD",
        "colab_type": "text"
      },
      "source": [
        "# 3. Tokenization & Input Formatting\n",
        "\n",
        "In this section, we'll transform our dataset into the format that BERT can be trained on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z14VJBILseS6",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 BERT Tokenizer\n",
        "\n",
        "To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary.\n",
        "\n",
        "The tokenization must be performed by the tokenizer included with BERT. The below cell will download this for us. We'll be using the \"uncased\" version here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfsvtXVNYmhK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "1449b58bca04410585f70cd201812e9f",
            "07fbb70128194d51b6ad753cedd132a2",
            "263b86a953214ca18c4ce21a81ad9eed",
            "0c655920559f44eabdafc3d222a4a5f0",
            "ad239af453124469876364528a467f80",
            "89a4b8c00de343be8f68766b0dd08612",
            "ae31647f2f604634b6376c09875f3bfa",
            "5e20b3a1e5dc437ea5f03fd45e348175"
          ]
        },
        "outputId": "f7112446-083e-40f5-efb5-450627955ca1"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1449b58bca04410585f70cd201812e9f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYbSdW78zR6q",
        "colab_type": "code",
        "outputId": "ca4d48f4-7603-417a-cad2-05933eef71e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "# from transformers import BertTokenizer\n",
        "\n",
        "# # Load the BERT tokenizer.\n",
        "# print('Loading BERT tokenizer...')\n",
        "# tokenizer = BertTokenizer.from_pretrained(mrpc_output)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f430ec1b1d5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the BERT tokenizer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading BERT tokenizer...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmrpc_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'mrpc_output' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfTaapNztSwt",
        "colab_type": "text"
      },
      "source": [
        "Let's apply the tokenizer to one sentence just to see the output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtGnuWMPY668",
        "colab_type": "code",
        "outputId": "1a04713d-ffe8-450c-f2be-b9a1b3dab260",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "# Print the original sentence.\n",
        "print('Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
            "Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON20NhQwt4KN",
        "colab_type": "text"
      },
      "source": [
        "When we actually convert all of our sentences, we'll use the tokenize.encode function to handle both steps, rather than calling tokenize and convert_tokens_to_ids separately."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYbumk8ItfbF",
        "colab_type": "text"
      },
      "source": [
        "## 3.2 Sentences to IDs\n",
        "\n",
        "The tokenizer.encode function combines multiple steps for us:\n",
        "1. Split the sentence into tokens.\n",
        "2. Add the special [CLS] and [SEP] tokens.\n",
        "3. Map the tokens to their IDs.\n",
        "\n",
        "PS: This function can perform truncating for us, but doesn't handle padding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAjwRR51bzk3",
        "colab_type": "code",
        "outputId": "f4de52f9-02ce-4fdd-e603-df8ebf896ea0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: [101, 2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXS31VicuPIb",
        "colab_type": "text"
      },
      "source": [
        "## 3.3 Padding & Truncating\n",
        "\n",
        "Pad and truncate our sentences so that they all have the same length, MAX_LEN.\n",
        "\n",
        "The maximum sentence length in our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgugRDXtchHx",
        "colab_type": "code",
        "outputId": "76be8e0e-be02-4357-cc6e-6afb164cfc5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jy19KYHnwReV",
        "colab_type": "text"
      },
      "source": [
        "Given that, let's choose MAX_LEN = 64 and apply the padding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF9QJcJAcjil",
        "colab_type": "code",
        "outputId": "a33866c7-a206-42f5-c488-81a757abc811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 64\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 64 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TzGFxGAw6a3",
        "colab_type": "text"
      },
      "source": [
        "## 3.4 Attention Masks\n",
        "\n",
        "The attention mask simply makes it explicit which tokens are actual words versus which are padding.\n",
        "\n",
        "The BERT vocabulary does not use the ID 0, so if a token ID is 0, then it's padding, and otherwise it's a real token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCtiGxv8cl5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9Ywavwqxle8",
        "colab_type": "text"
      },
      "source": [
        "## 3.5 Training & Validation Split\n",
        "\n",
        "Divide up our training set to use 90% for training and 10% for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSQ-9x7bcoMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels, random_state=2018, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWoJc-Faxvu2",
        "colab_type": "text"
      },
      "source": [
        "## Converting to PyTorch Data Types\n",
        "\n",
        "Our model expects PyTorch tensors rather than numpy.ndarrays, so convert all of our dataset variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9BfLXU_cqWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqhphGydx8vk",
        "colab_type": "text"
      },
      "source": [
        "We'll also create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaRfCJbecsID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b0YWX_ryPUq",
        "colab_type": "text"
      },
      "source": [
        "# 4. Train Our Classification Model\n",
        "\n",
        "Now that our input data is properly formatted, it's time to fine tune the BERT model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8inZRrtayY60",
        "colab_type": "text"
      },
      "source": [
        "## 4.1 BertForSequenceClassification\n",
        "\n",
        "For this task, we first want to modify the pre-trained BERT model to give outptus for classification, and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well-suited for our task.\n",
        "\n",
        "The huggingface pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Though these interfaces are all built on top of a trained BERT model, each has different top layers and output types designed to accomodate their specific NLP task.\n",
        "\n",
        "We'll be using BertForSequenceClassification. This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task.\n",
        "\n",
        "Let's load BERT. There are a few different pre-trained BERT models available. \"bert-base-uncased\" means the version that has only lowercase letters (\"uncased\") and is the smaller version of the two (\"base\" vs \"large\")."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7tfSsuxcuga",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8e606c4d019d44bfa05a1f7656ef2a8c",
            "011d4f0211b84cd7856aad4b7738c18f",
            "0ade4a30d9674eb98f126a93eadda353",
            "754562cbfb834426931ab78f8d080615",
            "c520127c8f9242bb9450e3e5082b40cb",
            "04286df6111c46faad8a10de7d566e35",
            "0bce8b4f883b49bc8225da5698b481e8",
            "e8cfe9b8dff14cd8a4ac40fada4a3a07"
          ]
        },
        "outputId": "c99f680c-c296-4494-ff08-0ca09a561644"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e606c4d019d44bfa05a1f7656ef2a8c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zObo_bNvBa2",
        "colab_type": "code",
        "outputId": "2b75cc5e-70cb-4bc4-b5f1-c28a17b82f5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577,
          "referenced_widgets": [
            "363fd7b3e607451f828ccfc64852aab9",
            "15163f3437cf4d959ca0b2b70ace2962",
            "1ec15f12e9714acd8303d8b789c2abae",
            "5c1871fe58664fb2a247d4ed80e92ca4",
            "08e5bbfad21c4ea7be11529632b356f2",
            "e2ac257b0ec340d5a9b6ffb9fc7123bf",
            "4306db75e767411e99e0805b0740a2be",
            "dec58feca26147468ae375cc837786c2"
          ]
        }
      },
      "source": [
        "# from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# # Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# # linear classification layer on top. \n",
        "# # model = BertForSequenceClassification.from_pretrained(\n",
        "# #     \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "# #     num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "# #                     # You can increase this for multi-class tasks.   \n",
        "# #     output_attentions = False, # Whether the model returns attentions weights.\n",
        "# #     output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "# # )\n",
        "\n",
        "# #model = BertForSequenceClassification.from_pretrained(mrpc_output)\n",
        "# config = BertConfig.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "# model = BertForSequenceClassification.from_pretrained(\"mrpc_output/pytorch_model.bin\", config=config)\n",
        "# #tokenizer = BertTokenizer.from_pretrained(mrpc_output)\n",
        "\n",
        "# # Tell pytorch to run this model on the GPU.\n",
        "# model.cuda()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "363fd7b3e607451f828ccfc64852aab9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_check_seekable\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'seek'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m                 \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;34m'r'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_open_buffer_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, buffer)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_buffer_reader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0m_check_seekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_check_seekable\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mraise_err_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"seek\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mraise_err_msg\u001b[0;34m(patterns, e)\u001b[0m\n\u001b[1;32m    284\u001b[0m                                 \" try to load from it instead.\")\n\u001b[0;32m--> 285\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'seek'. You can only torch.load from a file that is seekable. Please pre-load the data into a buffer like io.BytesIO and try to load from it instead.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-c724fe7019a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#model = BertForSequenceClassification.from_pretrained(mrpc_output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-uncased\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mrpc_output/pytorch_model.bin\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;31m#tokenizer = BertTokenizer.from_pretrained(mrpc_output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m                 raise OSError(\n\u001b[0;32m--> 473\u001b[0;31m                     \u001b[0;34m\"Unable to load weights from pytorch checkpoint file. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m                     \u001b[0;34m\"If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m                 )\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to load weights from pytorch checkpoint file. If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True. "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VFM-Jqf0qId",
        "colab_type": "text"
      },
      "source": [
        "We can browse all of the model's parameters by name here.\n",
        "\n",
        "In the below cell, I've printed out the names and dimensions of the weights for:\n",
        "\n",
        "1. The embedding layer.\n",
        "2. The first of the twelve transformers.\n",
        "3. The output layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyHMzwgxcxAY",
        "colab_type": "code",
        "outputId": "5e167b6d-120d-428f-9349-4625d2b64c9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxgbMVwM-9e6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JNkuMUE_HYM",
        "colab_type": "code",
        "outputId": "e6747448-f44d-472b-ba4a-ec430ff70222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if model != model2:\n",
        "  print(\"different\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "different\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr3uD1Qg04qB",
        "colab_type": "text"
      },
      "source": [
        "## 4.2 Optimizer & Learning Rate Scheduler\n",
        "\n",
        "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
        "\n",
        "For the purposes of fine-tuing, the author s recommend choosing from the following values:\n",
        "- Batch size: 16, 32 (We chose 32 when creating our DataLoaders).\n",
        "- Learning rate (Adam): 5e-5, 3e-5, 2e-5 (We'll use 2e-5).\n",
        "- Number of epochs: 2,3,4 (We'll use 4)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZj1A3eudApl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZpYTVZXdD4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcrqOqJR1q4z",
        "colab_type": "text"
      },
      "source": [
        "## 4.3 Training Loop\n",
        "\n",
        "Below is our training loop. Fundamentally for each pass in our loop we have a training phas and a validation phase. At each pass we need to:\n",
        "\n",
        "Training loop:\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Clear out the gradients calculated in the previous pass. (In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.\n",
        "- Forward pass (feed input data through the network)\n",
        "- Backward pass (backpropagation)\n",
        "- Tell the network to update parameters with optimizer.step()\n",
        "- Track variables for monitoring progress\n",
        "\n",
        "Evaluation loop:\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Forward pass (feed input data through the network)\n",
        "- Compute loss on our validation data and track variables for monitoring progress\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmYAeNGn2vFm",
        "colab_type": "text"
      },
      "source": [
        "Define a helper function for calculating accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuKDkBO1dF5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cOAYj_G4drE",
        "colab_type": "text"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPU92vW6dIKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL3HGj-XdJkO",
        "colab_type": "code",
        "outputId": "cd8bce47-00fd-4968-8529-97ad58fdd4da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:16.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:32.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:47.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:02.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:17.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:33.\n",
            "\n",
            "  Average training loss: 0.49\n",
            "  Training epcoh took: 0:01:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:31.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:46.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:01.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:16.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:32.\n",
            "\n",
            "  Average training loss: 0.30\n",
            "  Training epcoh took: 0:01:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:04\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:31.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:46.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:01.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:16.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:32.\n",
            "\n",
            "  Average training loss: 0.19\n",
            "  Training epcoh took: 0:01:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    241.    Elapsed: 0:00:15.\n",
            "  Batch    80  of    241.    Elapsed: 0:00:30.\n",
            "  Batch   120  of    241.    Elapsed: 0:00:46.\n",
            "  Batch   160  of    241.    Elapsed: 0:01:01.\n",
            "  Batch   200  of    241.    Elapsed: 0:01:16.\n",
            "  Batch   240  of    241.    Elapsed: 0:01:31.\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Training epcoh took: 0:01:32\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.82\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGgNsALy4lYP",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at our training loss over all batches:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xl7uw8pKdMZT",
        "colab_type": "code",
        "outputId": "87ce1f79-5f66-43ef-cc2f-22c57a963a2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvAAAAGaCAYAAABpIXfbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsiIM8EREREREVoQBnoiIiIjIivx/Ca55zk8COt4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwQmJeE24rf4",
        "colab_type": "text"
      },
      "source": [
        "# 5. Performance On Test Set\n",
        "\n",
        "Now we'll load the holdout dataset and prepare inputs just as we did with the training set. Then we'll evaluate predictions using Matthew's correlation coefficient because this is the metric used by the wider NLP community to evaluate performance on CoLA. With this metric, +1 is the best score, and -1 is the worst score. This way, we can see how well we perform against the state of the art models for this specific task. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BShH6rE86h0U",
        "colab_type": "text"
      },
      "source": [
        "## 5.1 Data Preparation\n",
        "\n",
        "We'll need to apply all of the same steps that we did for the training data to prepare our test data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdtuChaqejP7",
        "colab_type": "code",
        "outputId": "e8b2962d-2f10-4167-9b71-626080d23065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 516\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vZivNFG6rOS",
        "colab_type": "text"
      },
      "source": [
        "## 5.2 Evaluate on Test Set\n",
        "\n",
        "With the test set prepared, we can apply our fine-tuned model to generate predictions on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFc-2WdI-3a2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d7ca4b24-3c1d-410a-e931-f0141af6b935"
      },
      "source": [
        "## 先不运行\n",
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "model = BertForSequenceClassification.from_pretrained('mrpc_output')\n",
        "tokenizer = BertTokenizer.from_pretrained('mrpc_output')\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8naF99hem-P",
        "colab_type": "code",
        "outputId": "05f969e9-d324-4768-beb2-29ebef2d8d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 516 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryagJ1ed60Q0",
        "colab_type": "text"
      },
      "source": [
        "Accuracy on the CoLA benchmark is measured using the Matthews correlation coefficient (MCC).\n",
        "\n",
        "We use MCC here because the classes are imbalanced:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBJXqXPsepbk",
        "colab_type": "code",
        "outputId": "39ba4151-ac54-4467-9331-70ea4a5b12e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive samples: 354 of 516 (68.60%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTEnsCCkesKO",
        "colab_type": "code",
        "outputId": "60a4b340-ce43-4fa3-923f-313a43cac779",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVm65ueT6_Ut",
        "colab_type": "text"
      },
      "source": [
        "The final score will be based on the entire test set, but let's take a look at the scores on the individual batches to get a sense of the variability in the metric between batches.\n",
        "\n",
        "Each batch has 32 sentences in it, except the last batch which has only (516 % 32) = 4 test sentences in it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdpTkAKqeu7A",
        "colab_type": "code",
        "outputId": "b0030523-152c-4f50-87f3-49e226e3eb1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "matthews_set"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.14856415213808927,\n",
              " 0.1210898699241207,\n",
              " 0.14856415213808927,\n",
              " 0.0,\n",
              " 0.12998877418150556,\n",
              " 0.26604585934392433,\n",
              " 0.34097520463683817,\n",
              " 0.2364331218717302,\n",
              " 0.5423261445466404,\n",
              " 0.5423261445466404,\n",
              " 0.36115755925730764,\n",
              " 0.26590801173915524,\n",
              " 0.5576780295914437,\n",
              " 0.2773500981126145,\n",
              " 0.3721042037676254,\n",
              " 0.007053982594841415,\n",
              " -1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xlaobzjeyJx",
        "colab_type": "code",
        "outputId": "8c85d6a2-d7d6-4584-ebda-5298ad663c16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('MCC: %.3f' % mcc)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MCC: 0.292\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNpQvRape0R-",
        "colab_type": "code",
        "outputId": "47278861-5aad-4b4d-9abd-edec5deab1e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Good practice: save your training arguments together with the trained model\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/vocab.txt',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKcv5ofDe3zr",
        "colab_type": "code",
        "outputId": "e7ae1104-eb2d-4e6e-90ee-bc49ed2ed46a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "!ls -l --block-size=K ./model_save/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 427960K\n",
            "-rw-r--r-- 1 root root      2K Mar  1 23:43 config.json\n",
            "-rw-r--r-- 1 root root 427719K Mar  1 23:43 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root      1K Mar  1 23:43 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root      1K Mar  1 23:43 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root    227K Mar  1 23:43 vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2zfPiige6sJ",
        "colab_type": "code",
        "outputId": "d31a6ff9-2109-4320-b0f8-2a7474cddd6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls -l --block-size=M ./model_save/pytorch_model.bin"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 418M Mar  1 23:43 ./model_save/pytorch_model.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqWhVkTMe8IN",
        "colab_type": "code",
        "outputId": "b7dbf0a4-0f88-4bfe-c311-22106a13cb7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Mount Google Drive to this Notebook instance.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDQC3IJ7fAZk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy the model files to a directory in your Google Drive.\n",
        "!cp -r ./model_save/ \"./drive/My Drive/BERT/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzblWezrgU7v",
        "colab_type": "code",
        "outputId": "0710bcd4-6715-45dc-81c3-ea2d7c91bfe2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Load a trained model and vocabulary that you have fine-tuned\n",
        "model = BertForSequenceClassification.from_pretrained(output_dir)\n",
        "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
        "\n",
        "# Copy the model to the GPU.\n",
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwE3ZCcThUwJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "69be0fc4-57b6-429d-a96d-eebcb88a9250"
      },
      "source": [
        "# !python download_glue_data.py --data_dir='glue_data' --tasks='MRPC' --test_labels=True\n",
        "!pwd\n",
        "!ls\n",
        "!wget https://gist.githubusercontent.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e/raw/17b8dd0d724281ed7c3b2aeeda662b92809aadd5/download_glue_data.py\n",
        "!python download_glue_data.py --data_dir='glue_data' --tasks='MRPC'\n",
        "# !python download_glue_data.py --data_dir='glue_data' --tasks='CoLA'\n",
        "!ls glue_data/MRPC\n",
        "# !ls glue_data/CoLA"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "cola_public  cola_public_1.1.zip  sample_data\n",
            "--2020-03-24 00:30:14--  https://gist.githubusercontent.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e/raw/17b8dd0d724281ed7c3b2aeeda662b92809aadd5/download_glue_data.py\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8225 (8.0K) [text/plain]\n",
            "Saving to: ‘download_glue_data.py’\n",
            "\n",
            "download_glue_data. 100%[===================>]   8.03K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-03-24 00:30:14 (130 MB/s) - ‘download_glue_data.py’ saved [8225/8225]\n",
            "\n",
            "Processing MRPC...\n",
            "Local MRPC data not specified, downloading data from https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt\n",
            "\tCompleted!\n",
            "dev_ids.tsv  msr_paraphrase_test.txt   test.tsv\n",
            "dev.tsv      msr_paraphrase_train.txt  train.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zku55IfZ8kZd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eca3e821-3f33-4c07-f623-265a64e4d351"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/run_glue.py\n",
        "\n",
        "GLUE_DIR=\"glue_data/\"\n",
        "\n",
        "!python run_glue.py \\\n",
        "  --model_type bert \\\n",
        "  --model_name_or_path 'model_save' \\\n",
        "  --task_name MRPC \\\n",
        "  --do_train \\\n",
        "  --do_eval \\\n",
        "  --do_lower_case \\\n",
        "  --data_dir $GLUE_DIR/MRPC/ \\\n",
        "  --max_seq_length 128 \\\n",
        "  --per_gpu_train_batch_size 32 \\\n",
        "  --learning_rate 2e-5 \\\n",
        "  --num_train_epochs 2 \\\n",
        "  --output_dir 'mrpc_output' \\\n",
        "  --overwrite_output_dir"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-24 00:34:43--  https://raw.githubusercontent.com/huggingface/transformers/master/examples/run_glue.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29165 (28K) [text/plain]\n",
            "Saving to: ‘run_glue.py.1’\n",
            "\n",
            "\rrun_glue.py.1         0%[                    ]       0  --.-KB/s               \rrun_glue.py.1       100%[===================>]  28.48K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2020-03-24 00:34:44 (42.4 MB/s) - ‘run_glue.py.1’ saved [29165/29165]\n",
            "\n",
            "03/24/2020 00:34:49 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "03/24/2020 00:34:49 - INFO - transformers.configuration_utils -   loading configuration file model_save/config.json\n",
            "03/24/2020 00:34:49 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": null,\n",
            "  \"finetuning_task\": \"mrpc\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "03/24/2020 00:34:49 - INFO - transformers.tokenization_utils -   Model name 'model_save' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'model_save' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "03/24/2020 00:34:49 - INFO - transformers.tokenization_utils -   Didn't find file model_save/added_tokens.json. We won't load it.\n",
            "03/24/2020 00:34:49 - INFO - transformers.tokenization_utils -   loading file model_save/vocab.txt\n",
            "03/24/2020 00:34:49 - INFO - transformers.tokenization_utils -   loading file None\n",
            "03/24/2020 00:34:49 - INFO - transformers.tokenization_utils -   loading file model_save/special_tokens_map.json\n",
            "03/24/2020 00:34:49 - INFO - transformers.tokenization_utils -   loading file model_save/tokenizer_config.json\n",
            "03/24/2020 00:34:49 - INFO - transformers.modeling_utils -   loading weights file model_save/pytorch_model.bin\n",
            "03/24/2020 00:34:56 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, cache_dir='', config_name='', data_dir='glue_data//MRPC/', device=device(type='cuda'), do_eval=True, do_lower_case=True, do_train=True, eval_all_checkpoints=False, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='model_save', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=2.0, output_dir='mrpc_output', output_mode='classification', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=32, save_steps=500, seed=42, server_ip='', server_port='', task_name='mrpc', tokenizer_name='', warmup_steps=0, weight_decay=0.0)\n",
            "03/24/2020 00:34:56 - INFO - __main__ -   Creating features from dataset file at glue_data//MRPC/\n",
            "03/24/2020 00:34:56 - INFO - transformers.data.processors.glue -   LOOKING AT glue_data//MRPC/train.tsv\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   Writing example 0/3668\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   guid: train-1\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   input_ids: 101 2572 3217 5831 5496 2010 2567 1010 3183 2002 2170 1000 1996 7409 1000 1010 1997 9969 4487 23809 3436 2010 3350 1012 102 7727 2000 2032 2004 2069 1000 1996 7409 1000 1010 2572 3217 5831 5496 2010 2567 1997 9969 4487 23809 3436 2010 3350 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   guid: train-2\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   input_ids: 101 9805 3540 11514 2050 3079 11282 2243 1005 1055 2077 4855 1996 4677 2000 3647 4576 1999 2687 2005 1002 1016 1012 1019 4551 1012 102 9805 3540 11514 2050 4149 11282 2243 1005 1055 1999 2786 2005 1002 6353 2509 2454 1998 2853 2009 2000 3647 4576 2005 1002 1015 1012 1022 4551 1999 2687 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   guid: train-3\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   input_ids: 101 2027 2018 2405 2019 15147 2006 1996 4274 2006 2238 2184 1010 5378 1996 6636 2005 5096 1010 2002 2794 1012 102 2006 2238 2184 1010 1996 2911 1005 1055 5608 2018 2405 2019 15147 2006 1996 4274 1010 5378 1996 14792 2005 5096 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   guid: train-4\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   input_ids: 101 2105 6021 19481 13938 2102 1010 21628 6661 2020 2039 2539 16653 1010 2030 1018 1012 1018 1003 1010 2012 1037 1002 1018 1012 5179 1010 2383 3041 2275 1037 2501 2152 1997 1037 1002 1018 1012 5401 1012 102 21628 6661 5598 2322 16653 1010 2030 1018 1012 1020 1003 1010 2000 2275 1037 2501 5494 2152 2012 1037 1002 1018 1012 5401 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   guid: train-5\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   input_ids: 101 1996 4518 3123 1002 1016 1012 2340 1010 2030 2055 2340 3867 1010 2000 2485 5958 2012 1002 2538 1012 4868 2006 1996 2047 2259 4518 3863 1012 102 18720 1004 1041 13058 1012 6661 5598 1002 1015 1012 6191 2030 1022 3867 2000 1002 2538 1012 6021 2006 1996 2047 2259 4518 3863 2006 5958 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:34:57 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "03/24/2020 00:35:00 - INFO - __main__ -   Saving features into cached file glue_data//MRPC/cached_train_model_save_128_mrpc\n",
            "03/24/2020 00:35:01 - INFO - __main__ -   ***** Running training *****\n",
            "03/24/2020 00:35:01 - INFO - __main__ -     Num examples = 3668\n",
            "03/24/2020 00:35:01 - INFO - __main__ -     Num Epochs = 2\n",
            "03/24/2020 00:35:01 - INFO - __main__ -     Instantaneous batch size per GPU = 32\n",
            "03/24/2020 00:35:01 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "03/24/2020 00:35:01 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "03/24/2020 00:35:01 - INFO - __main__ -     Total optimization steps = 230\n",
            "Epoch:   0% 0/2 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/115 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/115 [00:00<01:29,  1.28it/s]\u001b[A\n",
            "Iteration:   2% 2/115 [00:01<01:27,  1.30it/s]\u001b[A\n",
            "Iteration:   3% 3/115 [00:02<01:25,  1.31it/s]\u001b[A\n",
            "Iteration:   3% 4/115 [00:03<01:24,  1.32it/s]\u001b[A\n",
            "Iteration:   4% 5/115 [00:03<01:23,  1.32it/s]\u001b[A\n",
            "Iteration:   5% 6/115 [00:04<01:22,  1.32it/s]\u001b[A\n",
            "Iteration:   6% 7/115 [00:05<01:21,  1.32it/s]\u001b[A\n",
            "Iteration:   7% 8/115 [00:06<01:21,  1.32it/s]\u001b[A\n",
            "Iteration:   8% 9/115 [00:06<01:20,  1.31it/s]\u001b[A\n",
            "Iteration:   9% 10/115 [00:07<01:20,  1.31it/s]\u001b[A\n",
            "Iteration:  10% 11/115 [00:08<01:19,  1.30it/s]\u001b[A\n",
            "Iteration:  10% 12/115 [00:09<01:19,  1.30it/s]\u001b[A\n",
            "Iteration:  11% 13/115 [00:09<01:18,  1.30it/s]\u001b[A\n",
            "Iteration:  12% 14/115 [00:10<01:18,  1.29it/s]\u001b[A\n",
            "Iteration:  13% 15/115 [00:11<01:17,  1.29it/s]\u001b[A\n",
            "Iteration:  14% 16/115 [00:12<01:17,  1.29it/s]\u001b[A\n",
            "Iteration:  15% 17/115 [00:13<01:16,  1.28it/s]\u001b[A\n",
            "Iteration:  16% 18/115 [00:13<01:15,  1.28it/s]\u001b[A\n",
            "Iteration:  17% 19/115 [00:14<01:15,  1.28it/s]\u001b[A\n",
            "Iteration:  17% 20/115 [00:15<01:14,  1.28it/s]\u001b[A\n",
            "Iteration:  18% 21/115 [00:16<01:13,  1.27it/s]\u001b[A\n",
            "Iteration:  19% 22/115 [00:16<01:12,  1.28it/s]\u001b[A\n",
            "Iteration:  20% 23/115 [00:17<01:11,  1.28it/s]\u001b[A\n",
            "Iteration:  21% 24/115 [00:18<01:11,  1.28it/s]\u001b[A\n",
            "Iteration:  22% 25/115 [00:19<01:10,  1.28it/s]\u001b[A\n",
            "Iteration:  23% 26/115 [00:20<01:09,  1.29it/s]\u001b[A\n",
            "Iteration:  23% 27/115 [00:20<01:08,  1.29it/s]\u001b[A\n",
            "Iteration:  24% 28/115 [00:21<01:07,  1.30it/s]\u001b[A\n",
            "Iteration:  25% 29/115 [00:22<01:06,  1.30it/s]\u001b[A\n",
            "Iteration:  26% 30/115 [00:23<01:05,  1.30it/s]\u001b[A\n",
            "Iteration:  27% 31/115 [00:23<01:03,  1.31it/s]\u001b[A\n",
            "Iteration:  28% 32/115 [00:24<01:02,  1.32it/s]\u001b[A\n",
            "Iteration:  29% 33/115 [00:25<01:02,  1.32it/s]\u001b[A\n",
            "Iteration:  30% 34/115 [00:26<01:01,  1.33it/s]\u001b[A\n",
            "Iteration:  30% 35/115 [00:26<01:00,  1.33it/s]\u001b[A\n",
            "Iteration:  31% 36/115 [00:27<00:59,  1.33it/s]\u001b[A\n",
            "Iteration:  32% 37/115 [00:28<00:58,  1.33it/s]\u001b[A\n",
            "Iteration:  33% 38/115 [00:29<00:57,  1.34it/s]\u001b[A\n",
            "Iteration:  34% 39/115 [00:29<00:56,  1.34it/s]\u001b[A\n",
            "Iteration:  35% 40/115 [00:30<00:55,  1.34it/s]\u001b[A\n",
            "Iteration:  36% 41/115 [00:31<00:55,  1.34it/s]\u001b[A\n",
            "Iteration:  37% 42/115 [00:32<00:54,  1.35it/s]\u001b[A\n",
            "Iteration:  37% 43/115 [00:32<00:53,  1.36it/s]\u001b[A\n",
            "Iteration:  38% 44/115 [00:33<00:52,  1.36it/s]\u001b[A\n",
            "Iteration:  39% 45/115 [00:34<00:51,  1.36it/s]\u001b[A\n",
            "Iteration:  40% 46/115 [00:34<00:50,  1.36it/s]\u001b[A\n",
            "Iteration:  41% 47/115 [00:35<00:49,  1.36it/s]\u001b[A\n",
            "Iteration:  42% 48/115 [00:36<00:49,  1.37it/s]\u001b[A\n",
            "Iteration:  43% 49/115 [00:37<00:48,  1.37it/s]\u001b[A\n",
            "Iteration:  43% 50/115 [00:37<00:47,  1.37it/s]\u001b[A\n",
            "Iteration:  44% 51/115 [00:38<00:46,  1.37it/s]\u001b[A\n",
            "Iteration:  45% 52/115 [00:39<00:45,  1.38it/s]\u001b[A\n",
            "Iteration:  46% 53/115 [00:40<00:44,  1.38it/s]\u001b[A\n",
            "Iteration:  47% 54/115 [00:40<00:44,  1.38it/s]\u001b[A\n",
            "Iteration:  48% 55/115 [00:41<00:43,  1.38it/s]\u001b[A\n",
            "Iteration:  49% 56/115 [00:42<00:42,  1.39it/s]\u001b[A\n",
            "Iteration:  50% 57/115 [00:42<00:41,  1.39it/s]\u001b[A\n",
            "Iteration:  50% 58/115 [00:43<00:41,  1.39it/s]\u001b[A\n",
            "Iteration:  51% 59/115 [00:44<00:40,  1.40it/s]\u001b[A\n",
            "Iteration:  52% 60/115 [00:45<00:39,  1.39it/s]\u001b[A\n",
            "Iteration:  53% 61/115 [00:45<00:38,  1.40it/s]\u001b[A\n",
            "Iteration:  54% 62/115 [00:46<00:37,  1.40it/s]\u001b[A\n",
            "Iteration:  55% 63/115 [00:47<00:37,  1.40it/s]\u001b[A\n",
            "Iteration:  56% 64/115 [00:47<00:36,  1.40it/s]\u001b[A\n",
            "Iteration:  57% 65/115 [00:48<00:35,  1.40it/s]\u001b[A\n",
            "Iteration:  57% 66/115 [00:49<00:34,  1.40it/s]\u001b[A\n",
            "Iteration:  58% 67/115 [00:50<00:34,  1.41it/s]\u001b[A\n",
            "Iteration:  59% 68/115 [00:50<00:33,  1.40it/s]\u001b[A\n",
            "Iteration:  60% 69/115 [00:51<00:32,  1.41it/s]\u001b[A\n",
            "Iteration:  61% 70/115 [00:52<00:31,  1.41it/s]\u001b[A\n",
            "Iteration:  62% 71/115 [00:52<00:31,  1.41it/s]\u001b[A\n",
            "Iteration:  63% 72/115 [00:53<00:30,  1.41it/s]\u001b[A\n",
            "Iteration:  63% 73/115 [00:54<00:29,  1.41it/s]\u001b[A\n",
            "Iteration:  64% 74/115 [00:55<00:29,  1.41it/s]\u001b[A\n",
            "Iteration:  65% 75/115 [00:55<00:28,  1.41it/s]\u001b[A\n",
            "Iteration:  66% 76/115 [00:56<00:27,  1.41it/s]\u001b[A\n",
            "Iteration:  67% 77/115 [00:57<00:26,  1.41it/s]\u001b[A\n",
            "Iteration:  68% 78/115 [00:57<00:26,  1.41it/s]\u001b[A\n",
            "Iteration:  69% 79/115 [00:58<00:25,  1.41it/s]\u001b[A\n",
            "Iteration:  70% 80/115 [00:59<00:24,  1.41it/s]\u001b[A\n",
            "Iteration:  70% 81/115 [01:00<00:24,  1.41it/s]\u001b[A\n",
            "Iteration:  71% 82/115 [01:00<00:23,  1.41it/s]\u001b[A\n",
            "Iteration:  72% 83/115 [01:01<00:22,  1.41it/s]\u001b[A\n",
            "Iteration:  73% 84/115 [01:02<00:21,  1.41it/s]\u001b[A\n",
            "Iteration:  74% 85/115 [01:02<00:21,  1.41it/s]\u001b[A\n",
            "Iteration:  75% 86/115 [01:03<00:20,  1.41it/s]\u001b[A\n",
            "Iteration:  76% 87/115 [01:04<00:19,  1.41it/s]\u001b[A\n",
            "Iteration:  77% 88/115 [01:04<00:19,  1.41it/s]\u001b[A\n",
            "Iteration:  77% 89/115 [01:05<00:18,  1.41it/s]\u001b[A\n",
            "Iteration:  78% 90/115 [01:06<00:17,  1.41it/s]\u001b[A\n",
            "Iteration:  79% 91/115 [01:07<00:17,  1.41it/s]\u001b[A\n",
            "Iteration:  80% 92/115 [01:07<00:16,  1.41it/s]\u001b[A\n",
            "Iteration:  81% 93/115 [01:08<00:15,  1.41it/s]\u001b[A\n",
            "Iteration:  82% 94/115 [01:09<00:14,  1.41it/s]\u001b[A\n",
            "Iteration:  83% 95/115 [01:09<00:14,  1.41it/s]\u001b[A\n",
            "Iteration:  83% 96/115 [01:10<00:13,  1.41it/s]\u001b[A\n",
            "Iteration:  84% 97/115 [01:11<00:12,  1.41it/s]\u001b[A\n",
            "Iteration:  85% 98/115 [01:12<00:12,  1.40it/s]\u001b[A\n",
            "Iteration:  86% 99/115 [01:12<00:11,  1.40it/s]\u001b[A\n",
            "Iteration:  87% 100/115 [01:13<00:10,  1.40it/s]\u001b[A\n",
            "Iteration:  88% 101/115 [01:14<00:09,  1.40it/s]\u001b[A\n",
            "Iteration:  89% 102/115 [01:14<00:09,  1.40it/s]\u001b[A\n",
            "Iteration:  90% 103/115 [01:15<00:08,  1.40it/s]\u001b[A\n",
            "Iteration:  90% 104/115 [01:16<00:07,  1.40it/s]\u001b[A\n",
            "Iteration:  91% 105/115 [01:17<00:07,  1.40it/s]\u001b[A\n",
            "Iteration:  92% 106/115 [01:17<00:06,  1.40it/s]\u001b[A\n",
            "Iteration:  93% 107/115 [01:18<00:05,  1.39it/s]\u001b[A\n",
            "Iteration:  94% 108/115 [01:19<00:05,  1.39it/s]\u001b[A\n",
            "Iteration:  95% 109/115 [01:19<00:04,  1.39it/s]\u001b[A\n",
            "Iteration:  96% 110/115 [01:20<00:03,  1.39it/s]\u001b[A\n",
            "Iteration:  97% 111/115 [01:21<00:02,  1.39it/s]\u001b[A\n",
            "Iteration:  97% 112/115 [01:22<00:02,  1.39it/s]\u001b[A\n",
            "Iteration:  98% 113/115 [01:22<00:01,  1.39it/s]\u001b[A\n",
            "Iteration:  99% 114/115 [01:23<00:00,  1.39it/s]\u001b[A\n",
            "Iteration: 100% 115/115 [01:24<00:00,  1.37it/s]\n",
            "Epoch:  50% 1/2 [01:24<01:24, 84.05s/it]\n",
            "Iteration:   0% 0/115 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/115 [00:00<01:22,  1.38it/s]\u001b[A\n",
            "Iteration:   2% 2/115 [00:01<01:21,  1.38it/s]\u001b[A\n",
            "Iteration:   3% 3/115 [00:02<01:21,  1.38it/s]\u001b[A\n",
            "Iteration:   3% 4/115 [00:02<01:20,  1.38it/s]\u001b[A\n",
            "Iteration:   4% 5/115 [00:03<01:19,  1.38it/s]\u001b[A\n",
            "Iteration:   5% 6/115 [00:04<01:19,  1.38it/s]\u001b[A\n",
            "Iteration:   6% 7/115 [00:05<01:18,  1.38it/s]\u001b[A\n",
            "Iteration:   7% 8/115 [00:05<01:17,  1.38it/s]\u001b[A\n",
            "Iteration:   8% 9/115 [00:06<01:17,  1.38it/s]\u001b[A\n",
            "Iteration:   9% 10/115 [00:07<01:16,  1.37it/s]\u001b[A\n",
            "Iteration:  10% 11/115 [00:07<01:15,  1.37it/s]\u001b[A\n",
            "Iteration:  10% 12/115 [00:08<01:15,  1.37it/s]\u001b[A\n",
            "Iteration:  11% 13/115 [00:09<01:14,  1.37it/s]\u001b[A\n",
            "Iteration:  12% 14/115 [00:10<01:13,  1.37it/s]\u001b[A\n",
            "Iteration:  13% 15/115 [00:10<01:12,  1.37it/s]\u001b[A\n",
            "Iteration:  14% 16/115 [00:11<01:12,  1.37it/s]\u001b[A\n",
            "Iteration:  15% 17/115 [00:12<01:11,  1.37it/s]\u001b[A\n",
            "Iteration:  16% 18/115 [00:13<01:10,  1.37it/s]\u001b[A\n",
            "Iteration:  17% 19/115 [00:13<01:09,  1.37it/s]\u001b[A\n",
            "Iteration:  17% 20/115 [00:14<01:09,  1.37it/s]\u001b[A\n",
            "Iteration:  18% 21/115 [00:15<01:08,  1.37it/s]\u001b[A\n",
            "Iteration:  19% 22/115 [00:16<01:07,  1.37it/s]\u001b[A\n",
            "Iteration:  20% 23/115 [00:16<01:07,  1.37it/s]\u001b[A\n",
            "Iteration:  21% 24/115 [00:17<01:06,  1.37it/s]\u001b[A\n",
            "Iteration:  22% 25/115 [00:18<01:05,  1.37it/s]\u001b[A\n",
            "Iteration:  23% 26/115 [00:18<01:05,  1.37it/s]\u001b[A\n",
            "Iteration:  23% 27/115 [00:19<01:04,  1.37it/s]\u001b[A\n",
            "Iteration:  24% 28/115 [00:20<01:03,  1.37it/s]\u001b[A\n",
            "Iteration:  25% 29/115 [00:21<01:02,  1.37it/s]\u001b[A\n",
            "Iteration:  26% 30/115 [00:21<01:02,  1.37it/s]\u001b[A\n",
            "Iteration:  27% 31/115 [00:22<01:01,  1.36it/s]\u001b[A\n",
            "Iteration:  28% 32/115 [00:23<01:00,  1.36it/s]\u001b[A\n",
            "Iteration:  29% 33/115 [00:24<01:00,  1.36it/s]\u001b[A\n",
            "Iteration:  30% 34/115 [00:24<00:59,  1.37it/s]\u001b[A\n",
            "Iteration:  30% 35/115 [00:25<00:58,  1.37it/s]\u001b[A\n",
            "Iteration:  31% 36/115 [00:26<00:57,  1.37it/s]\u001b[A\n",
            "Iteration:  32% 37/115 [00:27<00:56,  1.37it/s]\u001b[A\n",
            "Iteration:  33% 38/115 [00:27<00:56,  1.37it/s]\u001b[A\n",
            "Iteration:  34% 39/115 [00:28<00:55,  1.37it/s]\u001b[A\n",
            "Iteration:  35% 40/115 [00:29<00:54,  1.37it/s]\u001b[A\n",
            "Iteration:  36% 41/115 [00:29<00:54,  1.37it/s]\u001b[A\n",
            "Iteration:  37% 42/115 [00:30<00:53,  1.37it/s]\u001b[A\n",
            "Iteration:  37% 43/115 [00:31<00:52,  1.37it/s]\u001b[A\n",
            "Iteration:  38% 44/115 [00:32<00:51,  1.37it/s]\u001b[A\n",
            "Iteration:  39% 45/115 [00:32<00:51,  1.37it/s]\u001b[A\n",
            "Iteration:  40% 46/115 [00:33<00:50,  1.37it/s]\u001b[A\n",
            "Iteration:  41% 47/115 [00:34<00:49,  1.36it/s]\u001b[A\n",
            "Iteration:  42% 48/115 [00:35<00:49,  1.36it/s]\u001b[A\n",
            "Iteration:  43% 49/115 [00:35<00:48,  1.37it/s]\u001b[A\n",
            "Iteration:  43% 50/115 [00:36<00:47,  1.37it/s]\u001b[A\n",
            "Iteration:  44% 51/115 [00:37<00:46,  1.37it/s]\u001b[A\n",
            "Iteration:  45% 52/115 [00:37<00:45,  1.37it/s]\u001b[A\n",
            "Iteration:  46% 53/115 [00:38<00:45,  1.37it/s]\u001b[A\n",
            "Iteration:  47% 54/115 [00:39<00:44,  1.37it/s]\u001b[A\n",
            "Iteration:  48% 55/115 [00:40<00:43,  1.37it/s]\u001b[A\n",
            "Iteration:  49% 56/115 [00:40<00:42,  1.37it/s]\u001b[A\n",
            "Iteration:  50% 57/115 [00:41<00:42,  1.37it/s]\u001b[A\n",
            "Iteration:  50% 58/115 [00:42<00:41,  1.37it/s]\u001b[A\n",
            "Iteration:  51% 59/115 [00:43<00:40,  1.37it/s]\u001b[A\n",
            "Iteration:  52% 60/115 [00:43<00:39,  1.38it/s]\u001b[A\n",
            "Iteration:  53% 61/115 [00:44<00:39,  1.38it/s]\u001b[A\n",
            "Iteration:  54% 62/115 [00:45<00:38,  1.38it/s]\u001b[A\n",
            "Iteration:  55% 63/115 [00:45<00:37,  1.38it/s]\u001b[A\n",
            "Iteration:  56% 64/115 [00:46<00:36,  1.38it/s]\u001b[A\n",
            "Iteration:  57% 65/115 [00:47<00:36,  1.38it/s]\u001b[A\n",
            "Iteration:  57% 66/115 [00:48<00:35,  1.38it/s]\u001b[A\n",
            "Iteration:  58% 67/115 [00:48<00:34,  1.38it/s]\u001b[A\n",
            "Iteration:  59% 68/115 [00:49<00:34,  1.38it/s]\u001b[A\n",
            "Iteration:  60% 69/115 [00:50<00:33,  1.38it/s]\u001b[A\n",
            "Iteration:  61% 70/115 [00:51<00:32,  1.38it/s]\u001b[A\n",
            "Iteration:  62% 71/115 [00:51<00:31,  1.38it/s]\u001b[A\n",
            "Iteration:  63% 72/115 [00:52<00:31,  1.38it/s]\u001b[A\n",
            "Iteration:  63% 73/115 [00:53<00:30,  1.38it/s]\u001b[A\n",
            "Iteration:  64% 74/115 [00:53<00:29,  1.38it/s]\u001b[A\n",
            "Iteration:  65% 75/115 [00:54<00:28,  1.38it/s]\u001b[A\n",
            "Iteration:  66% 76/115 [00:55<00:28,  1.38it/s]\u001b[A\n",
            "Iteration:  67% 77/115 [00:56<00:27,  1.38it/s]\u001b[A\n",
            "Iteration:  68% 78/115 [00:56<00:26,  1.38it/s]\u001b[A\n",
            "Iteration:  69% 79/115 [00:57<00:26,  1.38it/s]\u001b[A\n",
            "Iteration:  70% 80/115 [00:58<00:25,  1.39it/s]\u001b[A\n",
            "Iteration:  70% 81/115 [00:58<00:24,  1.39it/s]\u001b[A\n",
            "Iteration:  71% 82/115 [00:59<00:23,  1.39it/s]\u001b[A\n",
            "Iteration:  72% 83/115 [01:00<00:23,  1.39it/s]\u001b[A\n",
            "Iteration:  73% 84/115 [01:01<00:22,  1.39it/s]\u001b[A\n",
            "Iteration:  74% 85/115 [01:01<00:21,  1.39it/s]\u001b[A\n",
            "Iteration:  75% 86/115 [01:02<00:20,  1.39it/s]\u001b[A\n",
            "Iteration:  76% 87/115 [01:03<00:20,  1.39it/s]\u001b[A\n",
            "Iteration:  77% 88/115 [01:04<00:19,  1.39it/s]\u001b[A\n",
            "Iteration:  77% 89/115 [01:04<00:18,  1.39it/s]\u001b[A\n",
            "Iteration:  78% 90/115 [01:05<00:18,  1.39it/s]\u001b[A\n",
            "Iteration:  79% 91/115 [01:06<00:17,  1.39it/s]\u001b[A\n",
            "Iteration:  80% 92/115 [01:06<00:16,  1.39it/s]\u001b[A\n",
            "Iteration:  81% 93/115 [01:07<00:15,  1.39it/s]\u001b[A\n",
            "Iteration:  82% 94/115 [01:08<00:15,  1.39it/s]\u001b[A\n",
            "Iteration:  83% 95/115 [01:09<00:14,  1.38it/s]\u001b[A\n",
            "Iteration:  83% 96/115 [01:09<00:13,  1.38it/s]\u001b[A\n",
            "Iteration:  84% 97/115 [01:10<00:12,  1.39it/s]\u001b[A\n",
            "Iteration:  85% 98/115 [01:11<00:12,  1.39it/s]\u001b[A\n",
            "Iteration:  86% 99/115 [01:11<00:11,  1.39it/s]\u001b[A\n",
            "Iteration:  87% 100/115 [01:12<00:10,  1.39it/s]\u001b[A\n",
            "Iteration:  88% 101/115 [01:13<00:10,  1.39it/s]\u001b[A\n",
            "Iteration:  89% 102/115 [01:14<00:09,  1.39it/s]\u001b[A\n",
            "Iteration:  90% 103/115 [01:14<00:08,  1.39it/s]\u001b[A\n",
            "Iteration:  90% 104/115 [01:15<00:07,  1.38it/s]\u001b[A\n",
            "Iteration:  91% 105/115 [01:16<00:07,  1.38it/s]\u001b[A\n",
            "Iteration:  92% 106/115 [01:17<00:06,  1.38it/s]\u001b[A\n",
            "Iteration:  93% 107/115 [01:17<00:05,  1.38it/s]\u001b[A\n",
            "Iteration:  94% 108/115 [01:18<00:05,  1.39it/s]\u001b[A\n",
            "Iteration:  95% 109/115 [01:19<00:04,  1.38it/s]\u001b[A\n",
            "Iteration:  96% 110/115 [01:19<00:03,  1.38it/s]\u001b[A\n",
            "Iteration:  97% 111/115 [01:20<00:02,  1.39it/s]\u001b[A\n",
            "Iteration:  97% 112/115 [01:21<00:02,  1.38it/s]\u001b[A\n",
            "Iteration:  98% 113/115 [01:22<00:01,  1.38it/s]\u001b[A\n",
            "Iteration:  99% 114/115 [01:22<00:00,  1.38it/s]\u001b[A\n",
            "Iteration: 100% 115/115 [01:23<00:00,  1.38it/s]\n",
            "Epoch: 100% 2/2 [02:47<00:00, 83.66s/it]\n",
            "03/24/2020 00:37:48 - INFO - __main__ -    global_step = 230, average loss = 0.47720116370398064\n",
            "03/24/2020 00:37:48 - INFO - __main__ -   Saving model checkpoint to mrpc_output\n",
            "03/24/2020 00:37:48 - INFO - transformers.configuration_utils -   Configuration saved in mrpc_output/config.json\n",
            "03/24/2020 00:37:49 - INFO - transformers.modeling_utils -   Model weights saved in mrpc_output/pytorch_model.bin\n",
            "03/24/2020 00:37:49 - INFO - transformers.configuration_utils -   loading configuration file mrpc_output/config.json\n",
            "03/24/2020 00:37:49 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": null,\n",
            "  \"finetuning_task\": \"mrpc\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "03/24/2020 00:37:49 - INFO - transformers.modeling_utils -   loading weights file mrpc_output/pytorch_model.bin\n",
            "03/24/2020 00:37:52 - INFO - transformers.tokenization_utils -   Model name 'mrpc_output' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'mrpc_output' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "03/24/2020 00:37:52 - INFO - transformers.tokenization_utils -   Didn't find file mrpc_output/added_tokens.json. We won't load it.\n",
            "03/24/2020 00:37:52 - INFO - transformers.tokenization_utils -   loading file mrpc_output/vocab.txt\n",
            "03/24/2020 00:37:52 - INFO - transformers.tokenization_utils -   loading file None\n",
            "03/24/2020 00:37:52 - INFO - transformers.tokenization_utils -   loading file mrpc_output/special_tokens_map.json\n",
            "03/24/2020 00:37:52 - INFO - transformers.tokenization_utils -   loading file mrpc_output/tokenizer_config.json\n",
            "03/24/2020 00:37:52 - INFO - transformers.tokenization_utils -   Model name 'mrpc_output' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'mrpc_output' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "03/24/2020 00:37:52 - INFO - transformers.tokenization_utils -   Didn't find file mrpc_output/added_tokens.json. We won't load it.\n",
            "03/24/2020 00:37:52 - INFO - transformers.tokenization_utils -   loading file mrpc_output/vocab.txt\n",
            "03/24/2020 00:37:52 - INFO - transformers.tokenization_utils -   loading file None\n",
            "03/24/2020 00:37:52 - INFO - transformers.tokenization_utils -   loading file mrpc_output/special_tokens_map.json\n",
            "03/24/2020 00:37:52 - INFO - transformers.tokenization_utils -   loading file mrpc_output/tokenizer_config.json\n",
            "03/24/2020 00:37:52 - INFO - __main__ -   Evaluate the following checkpoints: ['mrpc_output']\n",
            "03/24/2020 00:37:52 - INFO - transformers.configuration_utils -   loading configuration file mrpc_output/config.json\n",
            "03/24/2020 00:37:52 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"eos_token_ids\": null,\n",
            "  \"finetuning_task\": \"mrpc\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "03/24/2020 00:37:52 - INFO - transformers.modeling_utils -   loading weights file mrpc_output/pytorch_model.bin\n",
            "03/24/2020 00:37:55 - INFO - __main__ -   Creating features from dataset file at glue_data//MRPC/\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   Writing example 0/408\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   guid: dev-1\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   input_ids: 101 2002 2056 1996 9440 2121 7903 2063 11345 2449 2987 1005 1056 4906 1996 2194 1005 1055 2146 1011 2744 3930 5656 1012 102 1000 1996 9440 2121 7903 2063 11345 2449 2515 2025 4906 2256 2146 1011 2744 3930 5656 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   guid: dev-2\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   input_ids: 101 20201 22948 2056 10958 19053 4140 6283 1996 8956 6939 1998 2246 2830 2000 2478 2010 2146 2086 1997 2731 1999 1996 2162 1012 102 2010 2564 2056 2002 2001 1000 2531 3867 2369 2577 5747 1000 1998 2246 2830 2000 2478 2010 2086 1997 2731 1999 1996 2162 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   guid: dev-3\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   input_ids: 101 1996 7922 2001 2012 12904 1012 6227 18371 2114 1996 18371 1010 4257 2006 1996 5219 1010 1998 2012 1015 1012 27054 2487 2114 1996 5364 23151 2278 1010 2036 4257 1012 102 1996 7922 2001 2012 12904 1012 6275 18371 16545 2100 1027 1010 8990 4257 2006 1996 5219 1010 1998 2012 1015 1012 23090 2487 2114 1996 5364 23151 2278 10381 2546 1027 1010 2091 1014 1012 1015 3867 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   guid: dev-4\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   input_ids: 101 1996 10028 1011 25022 2080 2003 3403 2127 2255 2000 5630 2065 2009 2097 2203 5668 2063 1037 4018 1012 102 1996 10028 1011 25022 2080 2623 9317 2008 2009 2097 5630 1999 2255 3251 2000 2203 5668 2063 1037 4018 2077 1996 27419 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   label: 1 (id = 1)\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   *** Example ***\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   guid: dev-5\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   input_ids: 101 2053 5246 2031 2042 2275 2005 1996 2942 2030 1996 4735 3979 1012 102 2053 5246 2031 2042 2275 2005 1996 4735 2030 2942 3572 1010 2021 17137 3051 2038 12254 2025 5905 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/24/2020 00:37:55 - INFO - transformers.data.processors.glue -   label: 0 (id = 0)\n",
            "03/24/2020 00:37:55 - INFO - __main__ -   Saving features into cached file glue_data//MRPC/cached_dev_model_save_128_mrpc\n",
            "03/24/2020 00:37:55 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "03/24/2020 00:37:55 - INFO - __main__ -     Num examples = 408\n",
            "03/24/2020 00:37:55 - INFO - __main__ -     Batch size = 8\n",
            "Evaluating: 100% 51/51 [00:03<00:00, 14.52it/s]\n",
            "03/24/2020 00:37:59 - INFO - __main__ -   ***** Eval results  *****\n",
            "03/24/2020 00:37:59 - INFO - __main__ -     acc = 0.8063725490196079\n",
            "03/24/2020 00:37:59 - INFO - __main__ -     acc_and_f1 = 0.8395791891635881\n",
            "03/24/2020 00:37:59 - INFO - __main__ -     f1 = 0.8727858293075683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVFh6LuW9n9P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}