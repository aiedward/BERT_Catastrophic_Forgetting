{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOSr7aDrOrYHc4rppD2W11W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JingYannn/BERT_Catastrophic_Forgetting/blob/master/GPT2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLQYrKed83rl",
        "colab_type": "code",
        "outputId": "d3f0c03b-3829-435d-86ff-a4731f68d954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "# !python download_glue_data.py --data_dir='glue_data' --tasks='MRPC' --test_labels=True\n",
        "!pwd\n",
        "!ls\n",
        "!wget https://gist.githubusercontent.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e/raw/17b8dd0d724281ed7c3b2aeeda662b92809aadd5/download_glue_data.py\n",
        "!python download_glue_data.py --data_dir='glue_data' --tasks='MRPC'\n",
        "!python download_glue_data.py --data_dir='glue_data' --tasks='CoLA'\n",
        "!python download_glue_data.py --data_dir='glue_data' --tasks='SST'\n",
        "!ls glue_data/MRPC\n",
        "!ls glue_data/CoLA\n",
        "!ls glue_data/SST"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "sample_data\n",
            "--2020-03-28 21:18:31--  https://gist.githubusercontent.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e/raw/17b8dd0d724281ed7c3b2aeeda662b92809aadd5/download_glue_data.py\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8225 (8.0K) [text/plain]\n",
            "Saving to: ‘download_glue_data.py’\n",
            "\n",
            "download_glue_data. 100%[===================>]   8.03K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-03-28 21:18:31 (142 MB/s) - ‘download_glue_data.py’ saved [8225/8225]\n",
            "\n",
            "Processing MRPC...\n",
            "Local MRPC data not specified, downloading data from https://dl.fbaipublicfiles.com/senteval/senteval_data/msr_paraphrase_train.txt\n",
            "\tCompleted!\n",
            "Downloading and extracting CoLA...\n",
            "\tCompleted!\n",
            "Downloading and extracting SST...\n",
            "\tCompleted!\n",
            "dev_ids.tsv  msr_paraphrase_test.txt   test.tsv\n",
            "dev.tsv      msr_paraphrase_train.txt  train.tsv\n",
            "dev.tsv  original  test.tsv  train.tsv\n",
            "ls: cannot access 'glue_data/SST': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErtGA39jX66u",
        "colab_type": "code",
        "outputId": "6c4c576c-c912-4466-8489-aa07f362de59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!python download_glue_data.py --data_dir='glue_data' --tasks='STS'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading and extracting STS...\n",
            "\tCompleted!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf6Lhd746abn",
        "colab_type": "code",
        "outputId": "ab946fdf-f5b4-406e-a29b-c259442af21e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!python download_glue_data.py --data_dir='glue_data' --tasks='RTE'\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading and extracting RTE...\n",
            "\tCompleted!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axXdYAnx9AQo",
        "colab_type": "code",
        "outputId": "f8110e6c-e508-47ed-ac82-3039c501d0ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "!pip install pytorch_pretrained_bert"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 33.8MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 1.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 2.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 3.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.38.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.12.27)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.21.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.27 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.15.27)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.8)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.16.0,>=1.15.27->boto3->pytorch_pretrained_bert) (1.12.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz6naU_C9FfH",
        "colab_type": "code",
        "outputId": "a9baa9e4-5592-4e65-8566-c4a2485a51db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tensorboardX\n",
        "!pip freeze"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\r\u001b[K     |█▊                              | 10kB 32.9MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 51kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 61kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 102kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 112kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 122kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 133kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 143kB 3.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 153kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 163kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 174kB 3.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 184kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 194kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 204kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (46.0.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.0\n",
            "absl-py==0.9.0\n",
            "alabaster==0.7.12\n",
            "albumentations==0.1.12\n",
            "altair==4.0.1\n",
            "asgiref==3.2.5\n",
            "astor==0.8.1\n",
            "astropy==4.0\n",
            "astunparse==1.6.3\n",
            "atari-py==0.2.6\n",
            "atomicwrites==1.3.0\n",
            "attrs==19.3.0\n",
            "audioread==2.1.8\n",
            "autograd==1.3\n",
            "Babel==2.8.0\n",
            "backcall==0.1.0\n",
            "beautifulsoup4==4.6.3\n",
            "bleach==3.1.3\n",
            "blis==0.4.1\n",
            "bokeh==1.4.0\n",
            "boto3==1.12.27\n",
            "botocore==1.15.27\n",
            "Bottleneck==1.3.2\n",
            "branca==0.4.0\n",
            "bs4==0.0.1\n",
            "CacheControl==0.12.6\n",
            "cachetools==3.1.1\n",
            "catalogue==1.0.0\n",
            "certifi==2019.11.28\n",
            "cffi==1.14.0\n",
            "chainer==6.5.0\n",
            "chardet==3.0.4\n",
            "click==7.1.1\n",
            "cloudpickle==1.3.0\n",
            "cmake==3.12.0\n",
            "cmdstanpy==0.4.0\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "contextlib2==0.5.5\n",
            "convertdate==2.2.0\n",
            "coverage==3.7.1\n",
            "coveralls==0.5\n",
            "crcmod==1.7\n",
            "cufflinks==0.17.3\n",
            "cupy-cuda101==6.5.0\n",
            "cvxopt==1.2.4\n",
            "cvxpy==1.0.28\n",
            "cycler==0.10.0\n",
            "cymem==2.0.3\n",
            "Cython==0.29.15\n",
            "daft==0.0.4\n",
            "dask==2.12.0\n",
            "dataclasses==0.7\n",
            "datascience==0.10.6\n",
            "decorator==4.4.2\n",
            "defusedxml==0.6.0\n",
            "descartes==1.1.0\n",
            "dill==0.3.1.1\n",
            "distributed==1.25.3\n",
            "Django==3.0.4\n",
            "dlib==19.18.0\n",
            "docopt==0.6.2\n",
            "docutils==0.15.2\n",
            "dopamine-rl==1.0.5\n",
            "earthengine-api==0.1.216\n",
            "easydict==1.9\n",
            "ecos==2.0.7.post1\n",
            "editdistance==0.5.3\n",
            "en-core-web-sm==2.2.5\n",
            "entrypoints==0.3\n",
            "ephem==3.7.7.1\n",
            "et-xmlfile==1.0.1\n",
            "fa2==0.3.5\n",
            "fancyimpute==0.4.3\n",
            "fastai==1.0.60\n",
            "fastdtw==0.3.4\n",
            "fastprogress==0.2.2\n",
            "fastrlock==0.4\n",
            "fbprophet==0.6\n",
            "feather-format==0.4.0\n",
            "featuretools==0.4.1\n",
            "filelock==3.0.12\n",
            "firebase-admin==4.0.0\n",
            "fix-yahoo-finance==0.0.22\n",
            "Flask==1.1.1\n",
            "folium==0.8.3\n",
            "fsspec==0.6.3\n",
            "future==0.16.0\n",
            "gast==0.3.3\n",
            "GDAL==2.2.2\n",
            "gdown==3.6.4\n",
            "gensim==3.6.0\n",
            "geographiclib==1.50\n",
            "geopy==1.17.0\n",
            "gin-config==0.3.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-api-core==1.16.0\n",
            "google-api-python-client==1.7.12\n",
            "google-auth==1.7.2\n",
            "google-auth-httplib2==0.0.3\n",
            "google-auth-oauthlib==0.4.1\n",
            "google-cloud-bigquery==1.21.0\n",
            "google-cloud-core==1.0.3\n",
            "google-cloud-datastore==1.8.0\n",
            "google-cloud-firestore==1.6.2\n",
            "google-cloud-language==1.2.0\n",
            "google-cloud-storage==1.18.1\n",
            "google-cloud-translate==1.5.0\n",
            "google-colab==1.0.0\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==0.4.1\n",
            "googleapis-common-protos==1.51.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.10.1\n",
            "grpcio==1.27.2\n",
            "gspread==3.0.1\n",
            "gspread-dataframe==3.0.4\n",
            "gym==0.17.1\n",
            "h5py==2.10.0\n",
            "HeapDict==1.0.1\n",
            "holidays==0.9.12\n",
            "html5lib==1.0.1\n",
            "httpimport==0.5.18\n",
            "httplib2==0.17.0\n",
            "httplib2shim==0.0.3\n",
            "humanize==0.5.1\n",
            "hyperopt==0.1.2\n",
            "ideep4py==2.0.0.post3\n",
            "idna==2.8\n",
            "image==1.5.28\n",
            "imageio==2.4.1\n",
            "imagesize==1.2.0\n",
            "imbalanced-learn==0.4.3\n",
            "imblearn==0.0\n",
            "imgaug==0.2.9\n",
            "importlib-metadata==1.5.0\n",
            "imutils==0.5.3\n",
            "inflect==2.1.0\n",
            "intel-openmp==2020.0.133\n",
            "intervaltree==2.1.0\n",
            "ipykernel==4.6.1\n",
            "ipython==5.5.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.3.9\n",
            "ipywidgets==7.5.1\n",
            "itsdangerous==1.1.0\n",
            "jax==0.1.62\n",
            "jaxlib==0.1.42\n",
            "jdcal==1.4.1\n",
            "jedi==0.16.0\n",
            "jieba==0.42.1\n",
            "Jinja2==2.11.1\n",
            "jmespath==0.9.5\n",
            "joblib==0.14.1\n",
            "jpeg4py==0.1.4\n",
            "jsonschema==2.6.0\n",
            "jupyter==1.0.0\n",
            "jupyter-client==5.3.4\n",
            "jupyter-console==5.2.0\n",
            "jupyter-core==4.6.3\n",
            "kaggle==1.5.6\n",
            "kapre==0.1.3.1\n",
            "Keras==2.2.5\n",
            "Keras-Applications==1.0.8\n",
            "Keras-Preprocessing==1.1.0\n",
            "keras-vis==0.4.1\n",
            "kiwisolver==1.1.0\n",
            "knnimpute==0.1.0\n",
            "librosa==0.6.3\n",
            "lightgbm==2.2.3\n",
            "llvmlite==0.31.0\n",
            "lmdb==0.98\n",
            "lucid==0.3.8\n",
            "LunarCalendar==0.0.9\n",
            "lxml==4.2.6\n",
            "Markdown==3.2.1\n",
            "MarkupSafe==1.1.1\n",
            "matplotlib==3.2.1\n",
            "matplotlib-venn==0.11.5\n",
            "missingno==0.4.2\n",
            "mistune==0.8.4\n",
            "mizani==0.6.0\n",
            "mkl==2019.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==8.2.0\n",
            "moviepy==0.2.3.5\n",
            "mpmath==1.1.0\n",
            "msgpack==1.0.0\n",
            "multiprocess==0.70.9\n",
            "multitasking==0.0.9\n",
            "murmurhash==1.0.2\n",
            "music21==5.5.0\n",
            "natsort==5.5.0\n",
            "nbconvert==5.6.1\n",
            "nbformat==5.0.4\n",
            "networkx==2.4\n",
            "nibabel==3.0.2\n",
            "nltk==3.2.5\n",
            "notebook==5.2.2\n",
            "np-utils==0.5.12.1\n",
            "numba==0.47.0\n",
            "numexpr==2.7.1\n",
            "numpy==1.18.2\n",
            "nvidia-ml-py3==7.352.0\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.1.0\n",
            "okgrade==0.4.3\n",
            "opencv-contrib-python==4.1.2.30\n",
            "opencv-python==4.1.2.30\n",
            "openpyxl==2.5.9\n",
            "opt-einsum==3.2.0\n",
            "osqp==0.6.1\n",
            "packaging==20.3\n",
            "palettable==3.3.0\n",
            "pandas==0.25.3\n",
            "pandas-datareader==0.7.4\n",
            "pandas-gbq==0.11.0\n",
            "pandas-profiling==1.4.1\n",
            "pandocfilters==1.4.2\n",
            "parso==0.6.2\n",
            "pathlib==1.0.1\n",
            "patsy==0.5.1\n",
            "pexpect==4.8.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==7.0.0\n",
            "pip-tools==4.5.1\n",
            "plac==1.1.3\n",
            "plotly==4.4.1\n",
            "plotnine==0.6.0\n",
            "pluggy==0.7.1\n",
            "portpicker==1.3.1\n",
            "prefetch-generator==1.0.1\n",
            "preshed==3.0.2\n",
            "prettytable==0.7.2\n",
            "progressbar2==3.38.0\n",
            "prometheus-client==0.7.1\n",
            "promise==2.3\n",
            "prompt-toolkit==1.0.18\n",
            "protobuf==3.10.0\n",
            "psutil==5.4.8\n",
            "psycopg2==2.7.6.1\n",
            "ptyprocess==0.6.0\n",
            "py==1.8.1\n",
            "pyarrow==0.14.1\n",
            "pyasn1==0.4.8\n",
            "pyasn1-modules==0.2.8\n",
            "pycocotools==2.0.0\n",
            "pycparser==2.20\n",
            "pydata-google-auth==0.3.0\n",
            "pydot==1.3.0\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "pyemd==0.5.1\n",
            "pyglet==1.5.0\n",
            "Pygments==2.1.3\n",
            "pygobject==3.26.1\n",
            "pymc3==3.7\n",
            "PyMeeus==0.3.7\n",
            "pymongo==3.10.1\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.5\n",
            "pyparsing==2.4.6\n",
            "pyrsistent==0.16.0\n",
            "pysndfile==1.3.8\n",
            "PySocks==1.7.1\n",
            "pystan==2.19.1.1\n",
            "pytest==3.6.4\n",
            "python-apt==1.6.5+ubuntu0.2\n",
            "python-chess==0.23.11\n",
            "python-dateutil==2.8.1\n",
            "python-louvain==0.13\n",
            "python-slugify==4.0.0\n",
            "python-utils==2.4.0\n",
            "pytorch-pretrained-bert==0.6.2\n",
            "pytz==2018.9\n",
            "PyWavelets==1.1.1\n",
            "PyYAML==3.13\n",
            "pyzmq==17.0.0\n",
            "qtconsole==4.7.1\n",
            "QtPy==1.9.0\n",
            "regex==2019.12.20\n",
            "requests==2.21.0\n",
            "requests-oauthlib==1.3.0\n",
            "resampy==0.2.2\n",
            "retrying==1.3.3\n",
            "rpy2==3.2.7\n",
            "rsa==4.0\n",
            "s3fs==0.4.0\n",
            "s3transfer==0.3.3\n",
            "scikit-image==0.16.2\n",
            "scikit-learn==0.22.2.post1\n",
            "scipy==1.4.1\n",
            "screen-resolution-extra==0.0.0\n",
            "scs==2.1.1.post2\n",
            "seaborn==0.10.0\n",
            "Send2Trash==1.5.0\n",
            "setuptools-git==1.2\n",
            "Shapely==1.7.0\n",
            "simplegeneric==0.8.1\n",
            "six==1.12.0\n",
            "sklearn==0.0\n",
            "sklearn-pandas==1.8.0\n",
            "smart-open==1.10.0\n",
            "snowballstemmer==2.0.0\n",
            "sortedcontainers==2.1.0\n",
            "spacy==2.2.4\n",
            "Sphinx==1.8.5\n",
            "sphinxcontrib-websupport==1.2.1\n",
            "SQLAlchemy==1.3.15\n",
            "sqlparse==0.3.1\n",
            "srsly==1.0.2\n",
            "statsmodels==0.10.2\n",
            "sympy==1.1.1\n",
            "tables==3.4.4\n",
            "tabulate==0.8.7\n",
            "tblib==1.6.0\n",
            "tensorboard==2.1.1\n",
            "tensorboardcolab==0.0.22\n",
            "tensorboardX==2.0\n",
            "tensorflow==2.2.0rc1\n",
            "tensorflow-addons==0.8.3\n",
            "tensorflow-datasets==2.1.0\n",
            "tensorflow-estimator==2.2.0rc0\n",
            "tensorflow-gcs-config==2.1.8\n",
            "tensorflow-hub==0.7.0\n",
            "tensorflow-metadata==0.21.1\n",
            "tensorflow-privacy==0.2.2\n",
            "tensorflow-probability==0.9.0\n",
            "termcolor==1.1.0\n",
            "terminado==0.8.3\n",
            "testpath==0.4.4\n",
            "text-unidecode==1.3\n",
            "textblob==0.15.3\n",
            "textgenrnn==1.4.1\n",
            "Theano==1.0.4\n",
            "thinc==7.4.0\n",
            "toolz==0.10.0\n",
            "torch==1.4.0\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.3.1\n",
            "torchvision==0.5.0\n",
            "tornado==4.5.3\n",
            "tqdm==4.38.0\n",
            "traitlets==4.3.3\n",
            "tweepy==3.6.0\n",
            "typeguard==2.7.1\n",
            "typing==3.6.6\n",
            "typing-extensions==3.6.6\n",
            "tzlocal==1.5.1\n",
            "umap-learn==0.3.10\n",
            "uritemplate==3.0.1\n",
            "urllib3==1.24.3\n",
            "vega-datasets==0.8.0\n",
            "wasabi==0.6.0\n",
            "wcwidth==0.1.9\n",
            "webencodings==0.5.1\n",
            "Werkzeug==1.0.0\n",
            "widgetsnbextension==3.5.1\n",
            "wordcloud==1.5.0\n",
            "wrapt==1.12.1\n",
            "xarray==0.15.0\n",
            "xgboost==0.90\n",
            "xkit==0.0.0\n",
            "xlrd==1.1.0\n",
            "xlwt==1.3.0\n",
            "yellowbrick==0.9.1\n",
            "zict==2.0.0\n",
            "zipp==3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkkAMwtVw-Cs",
        "colab_type": "code",
        "outputId": "6df9d7d7-e2c7-49d3-dd69-7c9b2abe698c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python run_classifier.py \\\n",
        "--task_name CoLA \\\n",
        "--do_train \\\n",
        "--do_eval \\\n",
        "--data_dir glue_data/CoLA \\\n",
        "--max_seq_length 128 \\\n",
        "--train_batch_size 32 \\\n",
        "--learning_rate 2e-5 \\\n",
        "--num_train_epochs 2 \\\n",
        "--output_dir experiment/CoLA"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "03/28/2020 21:21:56 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "03/28/2020 21:21:56 - INFO - pytorch_pretrained_bert.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-vocab.json not found in cache, downloading to /tmp/tmpr4xvguap\n",
            "100% 815973/815973 [00:00<00:00, 5610555.44B/s]\n",
            "03/28/2020 21:21:57 - INFO - pytorch_pretrained_bert.file_utils -   copying /tmp/tmpr4xvguap to cache at /root/.pytorch_pretrained_bert/4ab93d0cd78ae80e746c27c9cd34e90b470abdabe0590c9ec742df61625ba310.b9628f6fe5519626534b82ce7ec72b22ce0ae79550325f45c604a25c0ad87fd6\n",
            "03/28/2020 21:21:57 - INFO - pytorch_pretrained_bert.file_utils -   creating metadata file for /root/.pytorch_pretrained_bert/4ab93d0cd78ae80e746c27c9cd34e90b470abdabe0590c9ec742df61625ba310.b9628f6fe5519626534b82ce7ec72b22ce0ae79550325f45c604a25c0ad87fd6\n",
            "03/28/2020 21:21:57 - INFO - pytorch_pretrained_bert.file_utils -   removing temp file /tmp/tmpr4xvguap\n",
            "03/28/2020 21:21:57 - INFO - pytorch_pretrained_bert.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-merges.txt not found in cache, downloading to /tmp/tmpemtaqgrn\n",
            "100% 458495/458495 [00:00<00:00, 3850439.62B/s]\n",
            "03/28/2020 21:21:57 - INFO - pytorch_pretrained_bert.file_utils -   copying /tmp/tmpemtaqgrn to cache at /root/.pytorch_pretrained_bert/0f8de0dbd6a2bb6bde7d758f4c120dd6dd20b46f2bf0a47bc899c89f46532fde.20808570f9a3169212a577f819c845330da870aeb14c40f7319819fce10c3b76\n",
            "03/28/2020 21:21:57 - INFO - pytorch_pretrained_bert.file_utils -   creating metadata file for /root/.pytorch_pretrained_bert/0f8de0dbd6a2bb6bde7d758f4c120dd6dd20b46f2bf0a47bc899c89f46532fde.20808570f9a3169212a577f819c845330da870aeb14c40f7319819fce10c3b76\n",
            "03/28/2020 21:21:57 - INFO - pytorch_pretrained_bert.file_utils -   removing temp file /tmp/tmpemtaqgrn\n",
            "03/28/2020 21:21:57 - INFO - pytorch_pretrained_bert.tokenization_openai -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-vocab.json from cache at /root/.pytorch_pretrained_bert/4ab93d0cd78ae80e746c27c9cd34e90b470abdabe0590c9ec742df61625ba310.b9628f6fe5519626534b82ce7ec72b22ce0ae79550325f45c604a25c0ad87fd6\n",
            "03/28/2020 21:21:57 - INFO - pytorch_pretrained_bert.tokenization_openai -   loading merges file https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-merges.txt from cache at /root/.pytorch_pretrained_bert/0f8de0dbd6a2bb6bde7d758f4c120dd6dd20b46f2bf0a47bc899c89f46532fde.20808570f9a3169212a577f819c845330da870aeb14c40f7319819fce10c3b76\n",
            "03/28/2020 21:21:57 - WARNING - pytorch_pretrained_bert.tokenization_openai -   ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n",
            "03/28/2020 21:21:57 - INFO - pytorch_pretrained_bert.tokenization_openai -   Special tokens {'_start_': 40478, '_delimiter_': 40479, '_classify_': 40480}\n",
            "03/28/2020 21:21:57 - INFO - pytorch_pretrained_bert.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-pytorch_model.bin not found in cache, downloading to /tmp/tmpy7eo1ls6\n",
            "100% 478750579/478750579 [00:09<00:00, 52744559.56B/s]\n",
            "03/28/2020 21:22:07 - INFO - pytorch_pretrained_bert.file_utils -   copying /tmp/tmpy7eo1ls6 to cache at /root/.pytorch_pretrained_bert/e45ee1afb14c5d77c946e66cb0fa70073a77882097a1a2cefd51fd24b172355e.e7ee3fcd07c695a4c9f31ca735502c090230d988de03202f7af9ebe1c3a4054c\n",
            "03/28/2020 21:22:08 - INFO - pytorch_pretrained_bert.file_utils -   creating metadata file for /root/.pytorch_pretrained_bert/e45ee1afb14c5d77c946e66cb0fa70073a77882097a1a2cefd51fd24b172355e.e7ee3fcd07c695a4c9f31ca735502c090230d988de03202f7af9ebe1c3a4054c\n",
            "03/28/2020 21:22:08 - INFO - pytorch_pretrained_bert.file_utils -   removing temp file /tmp/tmpy7eo1ls6\n",
            "03/28/2020 21:22:08 - INFO - pytorch_pretrained_bert.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-config.json not found in cache, downloading to /tmp/tmph8wivrrh\n",
            "100% 326/326 [00:00<00:00, 233893.79B/s]\n",
            "03/28/2020 21:22:08 - INFO - pytorch_pretrained_bert.file_utils -   copying /tmp/tmph8wivrrh to cache at /root/.pytorch_pretrained_bert/a27bb7c70e9002d7558d2682d5a95f3c0a8b31034616309459e0b51ef07ade09.1bb6b73eca45938a31700ee9b8193eee21734d2e12bb8098bd7cf94a82070c71\n",
            "03/28/2020 21:22:08 - INFO - pytorch_pretrained_bert.file_utils -   creating metadata file for /root/.pytorch_pretrained_bert/a27bb7c70e9002d7558d2682d5a95f3c0a8b31034616309459e0b51ef07ade09.1bb6b73eca45938a31700ee9b8193eee21734d2e12bb8098bd7cf94a82070c71\n",
            "03/28/2020 21:22:08 - INFO - pytorch_pretrained_bert.file_utils -   removing temp file /tmp/tmph8wivrrh\n",
            "03/28/2020 21:22:08 - INFO - pytorch_pretrained_bert.modeling_openai -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-pytorch_model.bin from cache at /root/.pytorch_pretrained_bert/e45ee1afb14c5d77c946e66cb0fa70073a77882097a1a2cefd51fd24b172355e.e7ee3fcd07c695a4c9f31ca735502c090230d988de03202f7af9ebe1c3a4054c\n",
            "03/28/2020 21:22:08 - INFO - pytorch_pretrained_bert.modeling_openai -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/openai-gpt-config.json from cache at /root/.pytorch_pretrained_bert/a27bb7c70e9002d7558d2682d5a95f3c0a8b31034616309459e0b51ef07ade09.1bb6b73eca45938a31700ee9b8193eee21734d2e12bb8098bd7cf94a82070c71\n",
            "03/28/2020 21:22:08 - INFO - pytorch_pretrained_bert.modeling_openai -   Model config {\n",
            "  \"afn\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"OpenAIGPTLMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"n_ctx\": 512,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 512,\n",
            "  \"n_special\": 0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"vocab_size\": 40478\n",
            "}\n",
            "\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   Writing example 0 of 8551\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   guid: train-0\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   tokens: _start_ our</w> friends</w> won</w> '</w> t</w> buy</w> this</w> analysis</w> ,</w> let</w> alone</w> the</w> next</w> one</w> we</w> propose</w> .</w> _delimiter_\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   input_ids: 40478 622 1662 5011 256 241 3487 616 13542 240 851 1552 481 1115 566 606 14568 239 40479 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   label: 1 (id = 1)\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   guid: train-1\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   tokens: _start_ one</w> more</w> pseudo</w> gener alization</w> and</w> i</w> '</w> m</w> giving</w> up</w> .</w> _delimiter_\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   input_ids: 40478 566 725 27889 2192 24396 488 249 256 258 2081 609 239 40479 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   label: 1 (id = 1)\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   guid: train-2\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   tokens: _start_ one</w> more</w> pseudo</w> gener alization</w> or</w> i</w> '</w> m</w> giving</w> up</w> .</w> _delimiter_\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   input_ids: 40478 566 725 27889 2192 24396 522 249 256 258 2081 609 239 40479 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   label: 1 (id = 1)\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   guid: train-3\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   tokens: _start_ the</w> more</w> we</w> study</w> ver bs</w> ,</w> the</w> crazier</w> they</w> get</w> .</w> _delimiter_\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   input_ids: 40478 481 725 606 4174 678 2077 240 481 28411 600 727 239 40479 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   label: 1 (id = 1)\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   guid: train-4\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   tokens: _start_ day</w> by</w> day</w> the</w> facts</w> are</w> getting</w> mur kier</w> .</w> _delimiter_\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   input_ids: 40478 850 702 850 481 6831 640 1381 1438 26479 239 40479 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:22:19 - INFO - run_classifier_dataset_utils -   label: 1 (id = 1)\n",
            "03/28/2020 21:22:21 - INFO - __main__ -     Saving train features into cached file glue_data/CoLA/train_openai-gpt_128_cola\n",
            "03/28/2020 21:22:21 - INFO - __main__ -   ***** Running training *****\n",
            "03/28/2020 21:22:21 - INFO - __main__ -     Num examples = 8551\n",
            "03/28/2020 21:22:21 - INFO - __main__ -     Batch size = 32\n",
            "03/28/2020 21:22:21 - INFO - __main__ -     Num steps = 536\n",
            "Iteration: 100% 268/268 [02:07<00:00,  2.11it/s]\n",
            "Iteration: 100% 268/268 [02:06<00:00,  2.11it/s]\n",
            "03/28/2020 21:26:36 - INFO - pytorch_pretrained_bert.modeling_openai -   loading weights file experiment/CoLA/pytorch_model.bin\n",
            "03/28/2020 21:26:36 - INFO - pytorch_pretrained_bert.modeling_openai -   loading configuration file experiment/CoLA/config.json\n",
            "03/28/2020 21:26:36 - INFO - pytorch_pretrained_bert.modeling_openai -   Model config {\n",
            "  \"afn\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"OpenAIGPTLMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"n_ctx\": 512,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 512,\n",
            "  \"n_special\": 3,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"vocab_size\": 40478\n",
            "}\n",
            "\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   Writing example 0 of 1043\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   guid: dev-0\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   tokens: _start_ the</w> sailors</w> rode</w> the</w> breeze</w> clear</w> of</w> the</w> rocks</w> .</w> _delimiter_\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   input_ids: 40478 481 13092 5135 481 4728 1949 498 481 4720 239 40479 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   label: 1 (id = 1)\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   guid: dev-1\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   tokens: _start_ the</w> weights</w> made</w> the</w> rope</w> stretch</w> over</w> the</w> pul ley</w> .</w> _delimiter_\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   input_ids: 40478 481 17422 885 481 4159 6253 715 481 967 1616 239 40479 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   label: 1 (id = 1)\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   guid: dev-2\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   tokens: _start_ the</w> mechanical</w> doll</w> wriggled</w> itself</w> loose</w> .</w> _delimiter_\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   input_ids: 40478 481 11617 7764 16777 2754 3644 239 40479 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   label: 1 (id = 1)\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   guid: dev-3\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   tokens: _start_ if</w> you</w> had</w> eaten</w> more</w> ,</w> you</w> would</w> want</w> less</w> .</w> _delimiter_\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   input_ids: 40478 645 512 558 5783 725 240 512 636 823 1101 239 40479 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   label: 1 (id = 1)\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   guid: dev-4\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   tokens: _start_ as</w> you</w> eat</w> the</w> most</w> ,</w> you</w> want</w> the</w> least</w> .</w> _delimiter_\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   input_ids: 40478 557 512 2425 481 905 240 512 823 481 1423 239 40479 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:26:37 - INFO - run_classifier_dataset_utils -   label: 0 (id = 0)\n",
            "03/28/2020 21:26:38 - INFO - __main__ -     Saving eval features into cached file glue_data/CoLA/dev_openai-gpt_128_cola\n",
            "03/28/2020 21:26:38 - INFO - __main__ -   ***** Running evaluation *****\n",
            "03/28/2020 21:26:38 - INFO - __main__ -     Num examples = 1043\n",
            "03/28/2020 21:26:38 - INFO - __main__ -     Batch size = 8\n",
            "Evaluating: 100% 131/131 [00:05<00:00, 24.70it/s]\n",
            "03/28/2020 21:26:43 - INFO - __main__ -   ***** Eval results *****\n",
            "03/28/2020 21:26:43 - INFO - __main__ -     eval_loss = 0.45229960301222694\n",
            "03/28/2020 21:26:43 - INFO - __main__ -     global_step = 536\n",
            "03/28/2020 21:26:43 - INFO - __main__ -     loss = 0.21654349879653595\n",
            "03/28/2020 21:26:43 - INFO - __main__ -     mcc = 0.5153742778418894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBVijsVu_rcf",
        "colab_type": "code",
        "outputId": "50ad63f0-f49f-4885-a336-2c0a29c99ccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python run_classifier.py \\\n",
        "--model_name 'experiment/CoLA' \\\n",
        "--task_name MRPC \\\n",
        "--do_train \\\n",
        "--do_eval \\\n",
        "--data_dir glue_data/MRPC \\\n",
        "--max_seq_length 128 \\\n",
        "--train_batch_size 32 \\\n",
        "--learning_rate 2e-5 \\\n",
        "--num_train_epochs 5 \\\n",
        "--output_dir experiment/MRPC"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "03/28/2020 21:28:00 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "03/28/2020 21:28:00 - INFO - pytorch_pretrained_bert.tokenization_openai -   loading special tokens file experiment/CoLA/special_tokens.txt\n",
            "03/28/2020 21:28:00 - INFO - pytorch_pretrained_bert.tokenization_openai -   loading vocabulary file experiment/CoLA/vocab.json\n",
            "03/28/2020 21:28:00 - INFO - pytorch_pretrained_bert.tokenization_openai -   loading merges file experiment/CoLA/merges.txt\n",
            "03/28/2020 21:28:00 - WARNING - pytorch_pretrained_bert.tokenization_openai -   ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n",
            "03/28/2020 21:28:00 - INFO - pytorch_pretrained_bert.tokenization_openai -   Special tokens {'_start_': 40478, '_delimiter_': 40479, '_classify_': 40480}\n",
            "03/28/2020 21:28:00 - INFO - pytorch_pretrained_bert.modeling_openai -   loading weights file experiment/CoLA/pytorch_model.bin\n",
            "03/28/2020 21:28:00 - INFO - pytorch_pretrained_bert.modeling_openai -   loading configuration file experiment/CoLA/config.json\n",
            "03/28/2020 21:28:00 - INFO - pytorch_pretrained_bert.modeling_openai -   Model config {\n",
            "  \"afn\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"OpenAIGPTLMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"n_ctx\": 512,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 512,\n",
            "  \"n_special\": 3,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"vocab_size\": 40478\n",
            "}\n",
            "\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   LOOKING AT glue_data/MRPC/train.tsv\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   Writing example 0 of 3668\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   guid: train-1\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   tokens: _start_ am ro zi</w> accused</w> his</w> brother</w> ,</w> whom</w> he</w> called</w> \"</w> the</w> witness</w> \"</w> ,</w> of</w> deliberately</w> dist orting</w> his</w> evidence</w> .</w> _delimiter_ referring</w> to</w> him</w> as</w> only</w> \"</w> the</w> witness</w> \"</w> ,</w> am ro zi</w> accused</w> his</w> brother</w> of</w> deliberately</w> dist orting</w> his</w> evidence</w> .</w> _classify_\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   input_ids: 40478 1574 506 10342 9009 524 1712 240 4261 487 1347 244 481 6603 244 240 498 7373 1649 14869 524 4208 239 40479 9650 485 575 557 808 244 481 6603 244 240 1574 506 10342 9009 524 1712 498 7373 1649 14869 524 4208 239 40480 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   label: 1 (id = 1)\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   guid: train-2\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   tokens: _start_ yu ca i pa</w> owned</w> dominick</w> '</w> s</w> before</w> selling</w> the</w> chain</w> to</w> safe way</w> in</w> 199 8</w> for</w> $</w> 2</w> .</w> 5</w> billion</w> .</w> _delimiter_ yu ca i pa</w> bought</w> dominick</w> '</w> s</w> in</w> 199 5</w> for</w> $</w> 6 93</w> million</w> and</w> sold</w> it</w> to</w> safe way</w> for</w> $</w> 1</w> .</w> 8</w> billion</w> in</w> 199 8</w> .</w> _classify_\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   input_ids: 40478 8450 578 11 4378 6254 28897 256 252 781 8172 481 4824 485 3756 638 500 12179 292 562 289 280 239 284 13160 239 40479 8450 578 11 4378 3828 28897 256 252 500 12179 284 562 289 49 32963 4322 488 5938 507 485 3756 638 562 289 277 239 292 13160 500 12179 292 239 40480 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   label: 0 (id = 0)\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   guid: train-3\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   tokens: _start_ they</w> had</w> published</w> an</w> advertisement</w> on</w> the</w> internet</w> on</w> june</w> 10</w> ,</w> offering</w> the</w> cargo</w> for</w> sale</w> ,</w> he</w> added</w> .</w> _delimiter_ on</w> june</w> 10</w> ,</w> the</w> ship</w> '</w> s</w> owners</w> had</w> published</w> an</w> advertisement</w> on</w> the</w> internet</w> ,</w> offering</w> the</w> explosives</w> for</w> sale</w> .</w> _classify_\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   input_ids: 40478 600 558 11229 531 30135 504 481 7722 504 8183 5895 240 5599 481 8790 562 9124 240 487 2318 239 40479 504 8183 5895 240 481 1546 256 252 11517 558 11229 531 30135 504 481 7722 240 5599 481 16904 562 9124 239 40480 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   label: 1 (id = 1)\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   guid: train-4\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   tokens: _start_ around</w> 0 3 35</w> g m t</w> ,</w> tab</w> shares</w> were</w> up</w> 19</w> cents</w> ,</w> or</w> 4</w> .</w> 4</w> %</w> ,</w> at</w> a</w> $</w> 4</w> .</w> 56</w> ,</w> having</w> earlier</w> set</w> a</w> record</w> high</w> of</w> a</w> $</w> 4</w> .</w> 57</w> .</w> _delimiter_ tab</w> shares</w> jumped</w> 20</w> cents</w> ,</w> or</w> 4</w> .</w> 6</w> %</w> ,</w> to</w> set</w> a</w> record</w> closing</w> high</w> at</w> a</w> $</w> 4</w> .</w> 57</w> .</w> _classify_\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   input_ids: 40478 785 48 43 14635 30 20 241 240 15812 17290 641 609 11252 20262 240 522 282 239 282 297 240 491 246 289 282 239 26836 240 1550 2625 1233 246 5319 1583 498 246 289 282 239 23339 239 40479 15812 17290 2702 7379 20262 240 522 282 239 287 297 240 485 1233 246 5319 3958 1583 491 246 289 282 239 23339 239 40480 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   label: 0 (id = 0)\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   guid: train-5\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   tokens: _start_ the</w> stock</w> rose</w> $</w> 2</w> .</w> 11</w> ,</w> or</w> about</w> 11</w> percent</w> ,</w> to</w> close</w> friday</w> at</w> $</w> 21</w> .</w> 51</w> on</w> the</w> new</w> york</w> stock</w> exchange</w> .</w> _delimiter_ p g</w> &</w> e</w> corp</w> .</w> shares</w> jumped</w> $</w> 1</w> .</w> 63</w> or</w> 8</w> percent</w> to</w> $</w> 21</w> .</w> 0 3</w> on</w> the</w> new</w> york</w> stock</w> exchange</w> on</w> friday</w> .</w> _classify_\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   input_ids: 40478 481 6382 1978 289 280 239 6682 240 522 670 6682 6708 240 485 1343 5513 491 289 11043 239 24040 504 481 783 4188 6382 6117 239 40479 24 268 296 243 31930 239 17290 2702 289 277 239 33154 522 292 6708 485 289 11043 239 48 281 504 481 783 4188 6382 6117 504 5513 239 40480 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:28:04 - INFO - run_classifier_dataset_utils -   label: 1 (id = 1)\n",
            "03/28/2020 21:28:07 - INFO - __main__ -     Saving train features into cached file glue_data/MRPC/train_CoLA_128_mrpc\n",
            "03/28/2020 21:28:07 - INFO - __main__ -   ***** Running training *****\n",
            "03/28/2020 21:28:07 - INFO - __main__ -     Num examples = 3668\n",
            "03/28/2020 21:28:07 - INFO - __main__ -     Batch size = 32\n",
            "03/28/2020 21:28:07 - INFO - __main__ -     Num steps = 575\n",
            "Iteration: 100% 115/115 [00:54<00:00,  2.11it/s]\n",
            "Iteration: 100% 115/115 [00:54<00:00,  2.11it/s]\n",
            "Iteration: 100% 115/115 [00:54<00:00,  2.11it/s]\n",
            "Iteration: 100% 115/115 [00:54<00:00,  2.11it/s]\n",
            "Iteration: 100% 115/115 [00:54<00:00,  2.11it/s]\n",
            "03/28/2020 21:32:40 - INFO - pytorch_pretrained_bert.modeling_openai -   loading weights file experiment/MRPC/pytorch_model.bin\n",
            "03/28/2020 21:32:40 - INFO - pytorch_pretrained_bert.modeling_openai -   loading configuration file experiment/MRPC/config.json\n",
            "03/28/2020 21:32:40 - INFO - pytorch_pretrained_bert.modeling_openai -   Model config {\n",
            "  \"afn\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"OpenAIGPTLMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"n_ctx\": 512,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 512,\n",
            "  \"n_special\": 3,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"vocab_size\": 40478\n",
            "}\n",
            "\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   Writing example 0 of 408\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   guid: dev-1\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   tokens: _start_ he</w> said</w> the</w> food service</w> pie</w> business</w> does n</w> '</w> t</w> fit</w> the</w> company</w> '</w> s</w> long</w> -</w> term</w> growth</w> strategy</w> .</w> _delimiter_ \"</w> the</w> food service</w> pie</w> business</w> does</w> not</w> fit</w> our</w> long</w> -</w> term</w> growth</w> strategy</w> .</w> _classify_\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   input_ids: 40478 487 603 481 36719 3960 7056 2006 28989 247 256 241 2665 481 2600 256 252 928 260 6110 9638 10154 239 40479 244 481 36719 3960 7056 2006 1056 595 2665 622 928 260 6110 9638 10154 239 40480 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   label: 1 (id = 1)\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   guid: dev-2\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   tokens: _start_ mag nar elli</w> said</w> rac ic ot</w> hated</w> the</w> ira qi</w> regime</w> and</w> looked</w> forward</w> to</w> using</w> his</w> long</w> years</w> of</w> training</w> in</w> the</w> war</w> .</w> _delimiter_ his</w> wife</w> said</w> he</w> was</w> \"</w> 100</w> percent</w> behind</w> george</w> bush</w> \"</w> and</w> looked</w> forward</w> to</w> using</w> his</w> years</w> of</w> training</w> in</w> the</w> war</w> .</w> _classify_\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   input_ids: 40478 1306 1912 15520 603 8238 572 1479 3075 481 14761 33003 26230 488 816 1522 485 2506 524 928 1218 498 3987 500 481 2557 239 40479 524 2093 603 487 509 244 11477 6708 1043 3878 7272 244 488 816 1522 485 2506 524 1218 498 3987 500 481 2557 239 40480 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   label: 0 (id = 0)\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   guid: dev-3\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   tokens: _start_ the</w> dollar</w> was</w> at</w> 1 16</w> .</w> 92</w> yen</w> against</w> the</w> yen</w> ,</w> flat</w> on</w> the</w> session</w> ,</w> and</w> at</w> 1</w> .</w> 28 91</w> against</w> the</w> swiss</w> fran c</w> ,</w> also</w> flat</w> .</w> _delimiter_ the</w> dollar</w> was</w> at</w> 1 16</w> .</w> 78</w> yen</w> j py</w> =</w> ,</w> virtually</w> flat</w> on</w> the</w> session</w> ,</w> and</w> at</w> 1</w> .</w> 28 71</w> against</w> the</w> swiss</w> fran c</w> ch f</w> =</w> ,</w> down</w> 0</w> .</w> 1</w> percent</w> .</w> _classify_\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   input_ids: 40478 481 7337 509 491 39 9509 239 32964 23125 1006 481 23125 240 3295 504 481 8968 240 488 491 277 239 27277 38794 1006 481 16771 4116 263 240 1359 3295 239 40479 481 7337 509 491 39 9509 239 24210 23125 28 3969 303 240 12341 3295 504 481 8968 240 488 491 277 239 27277 32965 1006 481 16771 4116 263 573 250 303 240 714 286 239 277 6708 239 40480 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   label: 0 (id = 0)\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   guid: dev-4\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   tokens: _start_ the</w> af l</w> -</w> cio</w> is</w> waiting</w> until</w> october</w> to</w> decide</w> if</w> it</w> will</w> endor se</w> a</w> candidate</w> .</w> _delimiter_ the</w> af l</w> -</w> cio</w> announced</w> wednesday</w> that</w> it</w> will</w> decide</w> in</w> october</w> whether</w> to</w> endor se</w> a</w> candidate</w> before</w> the</w> pri mar ies</w> .</w> _classify_\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   input_ids: 40478 481 752 264 260 20959 544 1644 1073 10800 485 3846 645 507 812 21705 546 246 14916 239 40479 481 752 264 260 20959 4771 9156 525 507 812 3846 500 10800 2587 485 21705 546 246 14916 781 481 941 831 1182 239 40480 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   label: 1 (id = 1)\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   guid: dev-5\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   tokens: _start_ no</w> dates</w> have</w> been</w> set</w> for</w> the</w> civil</w> or</w> the</w> criminal</w> trial</w> .</w> _delimiter_ no</w> dates</w> have</w> been</w> set</w> for</w> the</w> criminal</w> or</w> civil</w> cases</w> ,</w> but</w> shan ley</w> has</w> pleaded</w> not</w> guilty</w> .</w> _classify_\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   input_ids: 40478 664 7496 604 694 1233 562 481 10139 522 481 8169 6698 239 40479 664 7496 604 694 1233 562 481 8169 522 10139 5767 240 568 15995 1616 980 8463 595 4853 239 40480 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:32:41 - INFO - run_classifier_dataset_utils -   label: 0 (id = 0)\n",
            "03/28/2020 21:32:42 - INFO - __main__ -     Saving eval features into cached file glue_data/MRPC/dev_CoLA_128_mrpc\n",
            "03/28/2020 21:32:42 - INFO - __main__ -   ***** Running evaluation *****\n",
            "03/28/2020 21:32:42 - INFO - __main__ -     Num examples = 408\n",
            "03/28/2020 21:32:42 - INFO - __main__ -     Batch size = 8\n",
            "Evaluating: 100% 51/51 [00:02<00:00, 24.38it/s]\n",
            "03/28/2020 21:32:44 - INFO - __main__ -   ***** Eval results *****\n",
            "03/28/2020 21:32:44 - INFO - __main__ -     acc = 0.7377450980392157\n",
            "03/28/2020 21:32:44 - INFO - __main__ -     acc_and_f1 = 0.7818806791009087\n",
            "03/28/2020 21:32:44 - INFO - __main__ -     eval_loss = 0.9029659624485409\n",
            "03/28/2020 21:32:44 - INFO - __main__ -     f1 = 0.8260162601626017\n",
            "03/28/2020 21:32:44 - INFO - __main__ -     global_step = 575\n",
            "03/28/2020 21:32:44 - INFO - __main__ -     loss = 0.022882588379409003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUl39NYsRwXT",
        "colab_type": "code",
        "outputId": "5f307ff8-beca-4179-e6fc-a91a1d5c7ad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python run_classifier.py \\\n",
        "--model_name 'experiment/MRPC' \\\n",
        "--task_name CoLA \\\n",
        "--do_eval \\\n",
        "--data_dir glue_data/CoLA \\\n",
        "--max_seq_length 128 \\\n",
        "--output_dir experiment/MRPC"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "03/28/2020 21:35:10 - INFO - __main__ -   device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "03/28/2020 21:35:10 - INFO - pytorch_pretrained_bert.tokenization_openai -   loading special tokens file experiment/MRPC/special_tokens.txt\n",
            "03/28/2020 21:35:10 - INFO - pytorch_pretrained_bert.tokenization_openai -   loading vocabulary file experiment/MRPC/vocab.json\n",
            "03/28/2020 21:35:10 - INFO - pytorch_pretrained_bert.tokenization_openai -   loading merges file experiment/MRPC/merges.txt\n",
            "03/28/2020 21:35:10 - WARNING - pytorch_pretrained_bert.tokenization_openai -   ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\n",
            "03/28/2020 21:35:10 - INFO - pytorch_pretrained_bert.tokenization_openai -   Special tokens {'_start_': 40478, '_delimiter_': 40479, '_classify_': 40480}\n",
            "03/28/2020 21:35:10 - INFO - pytorch_pretrained_bert.modeling_openai -   loading weights file experiment/MRPC/pytorch_model.bin\n",
            "03/28/2020 21:35:10 - INFO - pytorch_pretrained_bert.modeling_openai -   loading configuration file experiment/MRPC/config.json\n",
            "03/28/2020 21:35:10 - INFO - pytorch_pretrained_bert.modeling_openai -   Model config {\n",
            "  \"afn\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"OpenAIGPTLMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"n_ctx\": 512,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 512,\n",
            "  \"n_special\": 3,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"vocab_size\": 40478\n",
            "}\n",
            "\n",
            "03/28/2020 21:35:14 - INFO - pytorch_pretrained_bert.modeling_openai -   loading weights file experiment/MRPC/pytorch_model.bin\n",
            "03/28/2020 21:35:14 - INFO - pytorch_pretrained_bert.modeling_openai -   loading configuration file experiment/MRPC/config.json\n",
            "03/28/2020 21:35:14 - INFO - pytorch_pretrained_bert.modeling_openai -   Model config {\n",
            "  \"afn\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"OpenAIGPTLMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"n_ctx\": 512,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 512,\n",
            "  \"n_special\": 3,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"vocab_size\": 40478\n",
            "}\n",
            "\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   Writing example 0 of 1043\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   guid: dev-0\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   tokens: _start_ the</w> sailors</w> rode</w> the</w> breeze</w> clear</w> of</w> the</w> rocks</w> .</w> _delimiter_\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   input_ids: 40478 481 13092 5135 481 4728 1949 498 481 4720 239 40479 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   label: 1 (id = 1)\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   guid: dev-1\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   tokens: _start_ the</w> weights</w> made</w> the</w> rope</w> stretch</w> over</w> the</w> pul ley</w> .</w> _delimiter_\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   input_ids: 40478 481 17422 885 481 4159 6253 715 481 967 1616 239 40479 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   label: 1 (id = 1)\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   guid: dev-2\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   tokens: _start_ the</w> mechanical</w> doll</w> wriggled</w> itself</w> loose</w> .</w> _delimiter_\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   input_ids: 40478 481 11617 7764 16777 2754 3644 239 40479 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   label: 1 (id = 1)\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   guid: dev-3\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   tokens: _start_ if</w> you</w> had</w> eaten</w> more</w> ,</w> you</w> would</w> want</w> less</w> .</w> _delimiter_\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   input_ids: 40478 645 512 558 5783 725 240 512 636 823 1101 239 40479 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   label: 1 (id = 1)\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   *** Example ***\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   guid: dev-4\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   tokens: _start_ as</w> you</w> eat</w> the</w> most</w> ,</w> you</w> want</w> the</w> least</w> .</w> _delimiter_\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   input_ids: 40478 557 512 2425 481 905 240 512 823 481 1423 239 40479 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "03/28/2020 21:35:16 - INFO - run_classifier_dataset_utils -   label: 0 (id = 0)\n",
            "03/28/2020 21:35:16 - INFO - __main__ -     Saving eval features into cached file glue_data/CoLA/dev_MRPC_128_cola\n",
            "03/28/2020 21:35:16 - INFO - __main__ -   ***** Running evaluation *****\n",
            "03/28/2020 21:35:16 - INFO - __main__ -     Num examples = 1043\n",
            "03/28/2020 21:35:16 - INFO - __main__ -     Batch size = 8\n",
            "Evaluating: 100% 131/131 [00:05<00:00, 24.68it/s]\n",
            "03/28/2020 21:35:21 - INFO - __main__ -   ***** Eval results *****\n",
            "03/28/2020 21:35:21 - INFO - __main__ -     eval_loss = 0.9963301358787158\n",
            "03/28/2020 21:35:21 - INFO - __main__ -     global_step = 0\n",
            "03/28/2020 21:35:21 - INFO - __main__ -     loss = None\n",
            "03/28/2020 21:35:21 - INFO - __main__ -     mcc = 0.3643959629852932\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v5rD050CyJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}